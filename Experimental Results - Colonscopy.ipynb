{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c180f19",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0282b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 105ms/step - loss: 0.6379 - accuracy: 0.6486 - binary_crossentropy: 0.6379 - precision: 0.6459 - recall: 0.6916 - auc: 0.7004\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 105ms/step - loss: 0.4930 - accuracy: 0.8715 - binary_crossentropy: 0.4930 - precision: 0.8759 - recall: 0.8723 - auc: 0.9505\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 105ms/step - loss: 0.4038 - accuracy: 0.9424 - binary_crossentropy: 0.4038 - precision: 0.9566 - recall: 0.9293 - auc: 0.9886\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 106ms/step - loss: 0.3393 - accuracy: 0.9597 - binary_crossentropy: 0.3393 - precision: 0.9708 - recall: 0.9497 - auc: 0.9949\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 106ms/step - loss: 0.2931 - accuracy: 0.9722 - binary_crossentropy: 0.2931 - precision: 0.9820 - recall: 0.9633 - auc: 0.9971\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 107ms/step - loss: 0.2596 - accuracy: 0.9771 - binary_crossentropy: 0.2596 - precision: 0.9875 - recall: 0.9674 - auc: 0.9979\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 107ms/step - loss: 0.2330 - accuracy: 0.9812 - binary_crossentropy: 0.2330 - precision: 0.9890 - recall: 0.9742 - auc: 0.9984\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.2114 - accuracy: 0.9840 - binary_crossentropy: 0.2114 - precision: 0.9904 - recall: 0.9783 - auc: 0.9985\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.1950 - accuracy: 0.9826 - binary_crossentropy: 0.1950 - precision: 0.9903 - recall: 0.9755 - auc: 0.9986\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.1798 - accuracy: 0.9868 - binary_crossentropy: 0.1798 - precision: 0.9904 - recall: 0.9837 - auc: 0.9987\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.1675 - accuracy: 0.9854 - binary_crossentropy: 0.1675 - precision: 0.9904 - recall: 0.9810 - auc: 0.9989\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.1566 - accuracy: 0.9882 - binary_crossentropy: 0.1566 - precision: 0.9891 - recall: 0.9878 - auc: 0.9989\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.1476 - accuracy: 0.9889 - binary_crossentropy: 0.1476 - precision: 0.9945 - recall: 0.9837 - auc: 0.9990\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.1395 - accuracy: 0.9896 - binary_crossentropy: 0.1395 - precision: 0.9932 - recall: 0.9864 - auc: 0.9991\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.1325 - accuracy: 0.9903 - binary_crossentropy: 0.1325 - precision: 0.9932 - recall: 0.9878 - auc: 0.9991\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 112ms/step - loss: 0.1262 - accuracy: 0.9903 - binary_crossentropy: 0.1262 - precision: 0.9918 - recall: 0.9891 - auc: 0.9992\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1206 - accuracy: 0.9917 - binary_crossentropy: 0.1206 - precision: 0.9945 - recall: 0.9891 - auc: 0.9992\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.1155 - accuracy: 0.9917 - binary_crossentropy: 0.1155 - precision: 0.9945 - recall: 0.9891 - auc: 0.9991\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.1108 - accuracy: 0.9910 - binary_crossentropy: 0.1108 - precision: 0.9945 - recall: 0.9878 - auc: 0.9991\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.1069 - accuracy: 0.9903 - binary_crossentropy: 0.1069 - precision: 0.9945 - recall: 0.9864 - auc: 0.9991\n",
      "Loss of Train ......................................\n",
      "[0.637915849685669, 0.4929799735546112, 0.40376582741737366, 0.3393111228942871, 0.29307815432548523, 0.2595839500427246, 0.23295578360557556, 0.21140681207180023, 0.19502872228622437, 0.17978833615779877, 0.167477086186409, 0.15657682716846466, 0.14761021733283997, 0.13949716091156006, 0.13248571753501892, 0.12620626389980316, 0.12064236402511597, 0.11547555774450302, 0.1108417809009552, 0.10688287019729614]\n",
      "Accuracy of Train ......................................\n",
      "[0.6486111283302307, 0.8715277910232544, 0.9423611164093018, 0.9597222208976746, 0.9722222089767456, 0.9770833253860474, 0.981249988079071, 0.9840278029441833, 0.9826388955116272, 0.9868055582046509, 0.9854166507720947, 0.988194465637207, 0.9888888597488403, 0.9895833134651184, 0.9902777671813965, 0.9902777671813965, 0.9916666746139526, 0.9916666746139526, 0.9909722208976746, 0.9902777671813965]\n",
      "Precision of Train ......................................\n",
      "[0.6459391117095947, 0.875852644443512, 0.9566433429718018, 0.9708333611488342, 0.9819944500923157, 0.9875173568725586, 0.9889655113220215, 0.9903714060783386, 0.9903448224067688, 0.9904240965843201, 0.9903978109359741, 0.9891156554222107, 0.9945054650306702, 0.9931600689888, 0.9931694269180298, 0.9918256402015686, 0.994535505771637, 0.994535505771637, 0.99452805519104, 0.9945205450057983]\n",
      "Recall of Train ......................................\n",
      "[0.6915760636329651, 0.8722826242446899, 0.929347813129425, 0.94972825050354, 0.9633151888847351, 0.967391312122345, 0.9741848111152649, 0.97826087474823, 0.9755434989929199, 0.9836956262588501, 0.98097825050354, 0.98777174949646, 0.9836956262588501, 0.9864130616188049, 0.98777174949646, 0.989130437374115, 0.989130437374115, 0.989130437374115, 0.98777174949646, 0.9864130616188049]\n",
      "AUC of Train ......................................\n",
      "[0.7004066705703735, 0.9504925012588501, 0.9886035919189453, 0.9948566555976868, 0.9971040487289429, 0.9978625774383545, 0.9984155297279358, 0.9985302686691284, 0.9986296892166138, 0.9987021088600159, 0.9989114999771118, 0.9988834857940674, 0.9989596605300903, 0.9990813732147217, 0.9990842342376709, 0.9991634488105774, 0.9991633892059326, 0.9990514516830444, 0.9991025328636169, 0.9990987181663513]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9601736098527909\n",
      " Loss:0.2284755188971758\n",
      " Precision:0.9654589891433716\n",
      " Recall:0.9576766312122345\n",
      " AUC:0.9807051718235016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 0.12384778261184692; accuracy of 0.9833333492279053%\n",
      "[[196   0]\n",
      " [  6 158]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 130.83106999999998 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:196,FN:6,TP:158,FP:0\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9833333333333333\n",
      " Loss:0.12384778261184692\n",
      " Precision:1.0\n",
      " Recall:0.9634146341463414\n",
      " AUC:0.9668558319246559\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 111ms/step - loss: 0.6725 - accuracy: 0.6187 - binary_crossentropy: 0.6725 - precision: 0.6089 - recall: 0.6522 - auc: 0.6506\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.5179 - accuracy: 0.8389 - binary_crossentropy: 0.5179 - precision: 0.8781 - recall: 0.7849 - auc: 0.9144\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.4288 - accuracy: 0.9104 - binary_crossentropy: 0.4288 - precision: 0.9608 - recall: 0.8547 - auc: 0.9730\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.3620 - accuracy: 0.9389 - binary_crossentropy: 0.3620 - precision: 0.9801 - recall: 0.8953 - auc: 0.9883\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.3159 - accuracy: 0.9535 - binary_crossentropy: 0.3159 - precision: 0.9865 - recall: 0.9190 - auc: 0.9932\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.2805 - accuracy: 0.9576 - binary_crossentropy: 0.2805 - precision: 0.9925 - recall: 0.9218 - auc: 0.9949\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.2522 - accuracy: 0.9674 - binary_crossentropy: 0.2522 - precision: 0.9941 - recall: 0.9399 - auc: 0.9966\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.2305 - accuracy: 0.9701 - binary_crossentropy: 0.2305 - precision: 0.9985 - recall: 0.9413 - auc: 0.9968\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2127 - accuracy: 0.9715 - binary_crossentropy: 0.2127 - precision: 0.9956 - recall: 0.9469 - auc: 0.9973\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.1966 - accuracy: 0.9750 - binary_crossentropy: 0.1966 - precision: 0.9956 - recall: 0.9539 - auc: 0.9978\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.1837 - accuracy: 0.9764 - binary_crossentropy: 0.1837 - precision: 0.9956 - recall: 0.9567 - auc: 0.9981\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.1726 - accuracy: 0.9792 - binary_crossentropy: 0.1726 - precision: 0.9957 - recall: 0.9623 - auc: 0.9979\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.1629 - accuracy: 0.9792 - binary_crossentropy: 0.1629 - precision: 0.9942 - recall: 0.9637 - auc: 0.9980\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.1536 - accuracy: 0.9812 - binary_crossentropy: 0.1536 - precision: 0.9971 - recall: 0.9651 - auc: 0.9984\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 111ms/step - loss: 0.1463 - accuracy: 0.9826 - binary_crossentropy: 0.1463 - precision: 0.9971 - recall: 0.9679 - auc: 0.9983\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.1394 - accuracy: 0.9833 - binary_crossentropy: 0.1394 - precision: 0.9957 - recall: 0.9707 - auc: 0.9987\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1330 - accuracy: 0.9861 - binary_crossentropy: 0.1330 - precision: 1.0000 - recall: 0.9721 - auc: 0.9986\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1276 - accuracy: 0.9868 - binary_crossentropy: 0.1276 - precision: 0.9971 - recall: 0.9763 - auc: 0.9988\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1230 - accuracy: 0.9854 - binary_crossentropy: 0.1230 - precision: 0.9971 - recall: 0.9735 - auc: 0.9988\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1175 - accuracy: 0.9882 - binary_crossentropy: 0.1175 - precision: 0.9972 - recall: 0.9791 - auc: 0.9990\n",
      "Loss of Train ......................................\n",
      "[0.6725226640701294, 0.5178663730621338, 0.4288109242916107, 0.3620185852050781, 0.31593039631843567, 0.28053441643714905, 0.25217288732528687, 0.23054800927639008, 0.21272914111614227, 0.1965782642364502, 0.1837022751569748, 0.17263852059841156, 0.16288235783576965, 0.15361139178276062, 0.14625480771064758, 0.1394408494234085, 0.13302171230316162, 0.1276048719882965, 0.12301643192768097, 0.11750638484954834]\n",
      "Accuracy of Train ......................................\n",
      "[0.6187499761581421, 0.8388888835906982, 0.9104166626930237, 0.9388889074325562, 0.9534721970558167, 0.9576388597488403, 0.9673610925674438, 0.9701389074325562, 0.9715277552604675, 0.9750000238418579, 0.9763888716697693, 0.9791666865348816, 0.9791666865348816, 0.981249988079071, 0.9826388955116272, 0.9833333492279053, 0.9861111044883728, 0.9868055582046509, 0.9854166507720947, 0.988194465637207]\n",
      "Precision of Train ......................................\n",
      "[0.6088657379150391, 0.878125011920929, 0.9607535600662231, 0.9801223278045654, 0.9865067601203918, 0.9924812316894531, 0.9940915703773499, 0.9985185265541077, 0.9955947399139404, 0.9956268072128296, 0.9956395626068115, 0.9956647157669067, 0.9942362904548645, 0.9971140027046204, 0.9971222877502441, 0.9957020282745361, 1.0, 0.9971469044685364, 0.9971387982368469, 0.9971550703048706]\n",
      "Recall of Train ......................................\n",
      "[0.6522346138954163, 0.7849162220954895, 0.8547486066818237, 0.8952513933181763, 0.9189944267272949, 0.9217877388000488, 0.9399441480636597, 0.9413408041000366, 0.9469273686408997, 0.9539105892181396, 0.9567039012908936, 0.9622905254364014, 0.9636871218681335, 0.9650837779045105, 0.9678770899772644, 0.9706704020500183, 0.9720670580863953, 0.9762569665908813, 0.9734637141227722, 0.9790502786636353]\n",
      "AUC of Train ......................................\n",
      "[0.6506382822990417, 0.9144197106361389, 0.9730103611946106, 0.9882625341415405, 0.9932029247283936, 0.9948552250862122, 0.9966309070587158, 0.9967581629753113, 0.9973012208938599, 0.9977719187736511, 0.9980555176734924, 0.9978529810905457, 0.9980428814888, 0.9984046220779419, 0.9983100891113281, 0.9986814856529236, 0.9986293911933899, 0.9987654089927673, 0.9987518787384033, 0.9990286827087402]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9465277761220932\n",
      " Loss:0.24646956324577332\n",
      " Precision:0.9678802967071534\n",
      " Recall:0.9248603373765946\n",
      " AUC:0.9743687093257904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 0.10256250202655792; accuracy of 1.0%\n",
      "[[176   0]\n",
      " [  0 184]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 239.6695905 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:176,FN:0,TP:184,FP:0\n",
      "Test of epochs .................................\n",
      " Accuracy:1.0\n",
      " Loss:0.10256250202655792\n",
      " Precision:1.0\n",
      " Recall:1.0\n",
      " AUC:1.0\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.6629 - accuracy: 0.6201 - binary_crossentropy: 0.6629 - precision: 0.6356 - recall: 0.5531 - auc: 0.6462\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.5074 - accuracy: 0.8674 - binary_crossentropy: 0.5074 - precision: 0.8995 - recall: 0.8254 - auc: 0.9359\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.4106 - accuracy: 0.9278 - binary_crossentropy: 0.4106 - precision: 0.9608 - recall: 0.8911 - auc: 0.9800\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.3477 - accuracy: 0.9535 - binary_crossentropy: 0.3477 - precision: 0.9865 - recall: 0.9190 - auc: 0.9904\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.3025 - accuracy: 0.9646 - binary_crossentropy: 0.3025 - precision: 1.0000 - recall: 0.9288 - auc: 0.9940\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.2695 - accuracy: 0.9701 - binary_crossentropy: 0.2695 - precision: 0.9956 - recall: 0.9441 - auc: 0.9955\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.2421 - accuracy: 0.9708 - binary_crossentropy: 0.2421 - precision: 0.9971 - recall: 0.9441 - auc: 0.9962\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.2206 - accuracy: 0.9729 - binary_crossentropy: 0.2206 - precision: 0.9985 - recall: 0.9469 - auc: 0.9972\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.2029 - accuracy: 0.9764 - binary_crossentropy: 0.2029 - precision: 0.9985 - recall: 0.9539 - auc: 0.9974\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1876 - accuracy: 0.9778 - binary_crossentropy: 0.1876 - precision: 1.0000 - recall: 0.9553 - auc: 0.9979\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.1758 - accuracy: 0.9785 - binary_crossentropy: 0.1758 - precision: 1.0000 - recall: 0.9567 - auc: 0.9980\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1653 - accuracy: 0.9799 - binary_crossentropy: 0.1653 - precision: 1.0000 - recall: 0.9595 - auc: 0.9982\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.1550 - accuracy: 0.9840 - binary_crossentropy: 0.1550 - precision: 1.0000 - recall: 0.9679 - auc: 0.9983\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1475 - accuracy: 0.9833 - binary_crossentropy: 0.1475 - precision: 1.0000 - recall: 0.9665 - auc: 0.9985\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1402 - accuracy: 0.9819 - binary_crossentropy: 0.1402 - precision: 0.9986 - recall: 0.9651 - auc: 0.9986\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1337 - accuracy: 0.9826 - binary_crossentropy: 0.1337 - precision: 1.0000 - recall: 0.9651 - auc: 0.9986\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1279 - accuracy: 0.9868 - binary_crossentropy: 0.1279 - precision: 1.0000 - recall: 0.9735 - auc: 0.9988\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.1224 - accuracy: 0.9847 - binary_crossentropy: 0.1224 - precision: 1.0000 - recall: 0.9693 - auc: 0.9989\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.1174 - accuracy: 0.9868 - binary_crossentropy: 0.1174 - precision: 1.0000 - recall: 0.9735 - auc: 0.9989\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.1131 - accuracy: 0.9896 - binary_crossentropy: 0.1131 - precision: 1.0000 - recall: 0.9791 - auc: 0.9990\n",
      "Loss of Train ......................................\n",
      "[0.6629202961921692, 0.5074498653411865, 0.4106275737285614, 0.3477199971675873, 0.3024596869945526, 0.26947084069252014, 0.24213197827339172, 0.2205929011106491, 0.20289191603660583, 0.1876092255115509, 0.175783172249794, 0.16526812314987183, 0.15496496856212616, 0.14748087525367737, 0.140235036611557, 0.1337248831987381, 0.1278763711452484, 0.12240419536828995, 0.11737863719463348, 0.11305572837591171]\n",
      "Accuracy of Train ......................................\n",
      "[0.6201388835906982, 0.8673611283302307, 0.9277777671813965, 0.9534721970558167, 0.9645833373069763, 0.9701389074325562, 0.9708333611488342, 0.9729166626930237, 0.9763888716697693, 0.9777777791023254, 0.9784722328186035, 0.9798611402511597, 0.9840278029441833, 0.9833333492279053, 0.9819444417953491, 0.9826388955116272, 0.9868055582046509, 0.9847221970558167, 0.9868055582046509, 0.9895833134651184]\n",
      "Precision of Train ......................................\n",
      "[0.6356340050697327, 0.8995434045791626, 0.9608433842658997, 0.9865067601203918, 1.0, 0.9955817461013794, 0.9970501661300659, 0.9985272288322449, 0.9985380172729492, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9985548853874207, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Recall of Train ......................................\n",
      "[0.5530726313591003, 0.825419008731842, 0.8910614252090454, 0.9189944267272949, 0.9287709593772888, 0.9441340565681458, 0.9441340565681458, 0.9469273686408997, 0.9539105892181396, 0.9553072452545166, 0.9567039012908936, 0.9594972133636475, 0.9678770899772644, 0.9664804339408875, 0.9650837779045105, 0.9650837779045105, 0.9734637141227722, 0.9692737460136414, 0.9734637141227722, 0.9790502786636353]\n",
      "AUC of Train ......................................\n",
      "[0.6461946964263916, 0.9359210729598999, 0.9800370335578918, 0.9903749227523804, 0.9939706325531006, 0.9955207109451294, 0.9961833357810974, 0.9971565008163452, 0.9973582029342651, 0.9979310631752014, 0.998019814491272, 0.9982146620750427, 0.998270571231842, 0.9985001683235168, 0.9985570311546326, 0.998574435710907, 0.9987567067146301, 0.998917818069458, 0.9989429116249084, 0.9990220069885254]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9519791692495346\n",
      " Loss:0.23760231360793113\n",
      " Precision:0.9735389798879623\n",
      " Recall:0.9268854707479477\n",
      " AUC:0.9758212149143219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 0.10625015944242477; accuracy of 0.9888888597488403%\n",
      "[[174   2]\n",
      " [  2 182]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 346.47368029999996 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:174,FN:2,TP:182,FP:2\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9888888888888889\n",
      " Loss:0.10625015944242477\n",
      " Precision:0.9891304347826086\n",
      " Recall:0.9891304347826086\n",
      " AUC:0.9888833992094861\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 109ms/step - loss: 0.6062 - accuracy: 0.7215 - binary_crossentropy: 0.6062 - precision: 0.7147 - recall: 0.7257 - auc: 0.7871\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.4619 - accuracy: 0.9076 - binary_crossentropy: 0.4619 - precision: 0.9326 - recall: 0.8762 - auc: 0.9626\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.3790 - accuracy: 0.9486 - binary_crossentropy: 0.3790 - precision: 0.9775 - recall: 0.9170 - auc: 0.9873\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.3207 - accuracy: 0.9667 - binary_crossentropy: 0.3207 - precision: 0.9868 - recall: 0.9451 - auc: 0.9942\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.2794 - accuracy: 0.9708 - binary_crossentropy: 0.2794 - precision: 0.9941 - recall: 0.9466 - auc: 0.9950\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.2476 - accuracy: 0.9736 - binary_crossentropy: 0.2476 - precision: 0.9927 - recall: 0.9536 - auc: 0.9960\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.2233 - accuracy: 0.9743 - binary_crossentropy: 0.2233 - precision: 0.9941 - recall: 0.9536 - auc: 0.9972\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.2034 - accuracy: 0.9764 - binary_crossentropy: 0.2034 - precision: 0.9956 - recall: 0.9564 - auc: 0.9977\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.1872 - accuracy: 0.9806 - binary_crossentropy: 0.1872 - precision: 0.9971 - recall: 0.9634 - auc: 0.9982\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.1736 - accuracy: 0.9799 - binary_crossentropy: 0.1736 - precision: 0.9956 - recall: 0.9634 - auc: 0.9981\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1625 - accuracy: 0.9812 - binary_crossentropy: 0.1625 - precision: 0.9957 - recall: 0.9662 - auc: 0.9984\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1524 - accuracy: 0.9833 - binary_crossentropy: 0.1524 - precision: 0.9957 - recall: 0.9705 - auc: 0.9985\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1439 - accuracy: 0.9819 - binary_crossentropy: 0.1439 - precision: 0.9928 - recall: 0.9705 - auc: 0.9986\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1364 - accuracy: 0.9826 - binary_crossentropy: 0.1364 - precision: 0.9957 - recall: 0.9691 - auc: 0.9988\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1292 - accuracy: 0.9826 - binary_crossentropy: 0.1292 - precision: 0.9957 - recall: 0.9691 - auc: 0.9988\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.1238 - accuracy: 0.9840 - binary_crossentropy: 0.1238 - precision: 0.9943 - recall: 0.9733 - auc: 0.9988\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1178 - accuracy: 0.9854 - binary_crossentropy: 0.1178 - precision: 0.9943 - recall: 0.9761 - auc: 0.9989\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1132 - accuracy: 0.9840 - binary_crossentropy: 0.1132 - precision: 0.9943 - recall: 0.9733 - auc: 0.9990\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1090 - accuracy: 0.9833 - binary_crossentropy: 0.1090 - precision: 0.9942 - recall: 0.9719 - auc: 0.9991\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1048 - accuracy: 0.9854 - binary_crossentropy: 0.1048 - precision: 0.9957 - recall: 0.9747 - auc: 0.9991\n",
      "Loss of Train ......................................\n",
      "[0.6061981916427612, 0.4618586599826813, 0.37898215651512146, 0.32068416476249695, 0.27939262986183167, 0.2476179599761963, 0.22327092289924622, 0.2034464031457901, 0.1871514469385147, 0.17363905906677246, 0.16253763437271118, 0.15236511826515198, 0.14394152164459229, 0.1363631933927536, 0.12923327088356018, 0.12379187345504761, 0.11777318269014359, 0.11322453618049622, 0.10904555767774582, 0.10481275618076324]\n",
      "Accuracy of Train ......................................\n",
      "[0.7215277552604675, 0.9076389074325562, 0.9486111402511597, 0.9666666388511658, 0.9708333611488342, 0.9736111164093018, 0.9743055701255798, 0.9763888716697693, 0.980555534362793, 0.9798611402511597, 0.981249988079071, 0.9833333492279053, 0.9819444417953491, 0.9826388955116272, 0.9826388955116272, 0.9840278029441833, 0.9854166507720947, 0.9840278029441833, 0.9833333492279053, 0.9854166507720947]\n",
      "Precision of Train ......................................\n",
      "[0.7146814465522766, 0.932634711265564, 0.9775112271308899, 0.9867841601371765, 0.9940915703773499, 0.9926793575286865, 0.9941349029541016, 0.9956076145172119, 0.9970887899398804, 0.9956395626068115, 0.9956521987915039, 0.9956709742546082, 0.9928057789802551, 0.9956647157669067, 0.9956647157669067, 0.9942528605461121, 0.9942693114280701, 0.9942528605461121, 0.9942445755004883, 0.9956896305084229]\n",
      "Recall of Train ......................................\n",
      "[0.7257384061813354, 0.8762306571006775, 0.9170182943344116, 0.945147693157196, 0.9465541243553162, 0.9535865187644958, 0.9535865187644958, 0.9563994407653809, 0.9634317755699158, 0.9634317755699158, 0.9662446975708008, 0.9704641103744507, 0.9704641103744507, 0.9690576791763306, 0.9690576791763306, 0.9732770919799805, 0.9760900139808655, 0.9732770919799805, 0.9718706011772156, 0.9746835231781006]\n",
      "AUC of Train ......................................\n",
      "[0.787138819694519, 0.9625684022903442, 0.9872848391532898, 0.9942169785499573, 0.9950252771377563, 0.9960073232650757, 0.9972199201583862, 0.9976809620857239, 0.9982463121414185, 0.9981294274330139, 0.9983571767807007, 0.9984594583511353, 0.998551070690155, 0.9987642765045166, 0.998838484287262, 0.9987604022026062, 0.9988781213760376, 0.9989542961120605, 0.9990537762641907, 0.99906325340271]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9617013931274414\n",
      " Loss:0.2187665119767189\n",
      " Precision:0.9764510482549668\n",
      " Recall:0.9457805901765823\n",
      " AUC:0.9850599288940429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 0.1199062168598175; accuracy of 0.980555534362793%\n",
      "[[171   0]\n",
      " [  7 182]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 454.5121746 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:171,FN:7,TP:182,FP:0\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9805555555555555\n",
      " Loss:0.1199062168598175\n",
      " Precision:1.0\n",
      " Recall:0.9629629629629629\n",
      " AUC:0.9618185601331668\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 112ms/step - loss: 0.6792 - accuracy: 0.5799 - binary_crossentropy: 0.6792 - precision: 0.5906 - recall: 0.5243 - auc: 0.6242\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.5047 - accuracy: 0.8465 - binary_crossentropy: 0.5047 - precision: 0.8541 - recall: 0.8363 - auc: 0.9314\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.4052 - accuracy: 0.9333 - binary_crossentropy: 0.4052 - precision: 0.9484 - recall: 0.9168 - auc: 0.9839\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.3389 - accuracy: 0.9549 - binary_crossentropy: 0.3389 - precision: 0.9633 - recall: 0.9459 - auc: 0.9930\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.2937 - accuracy: 0.9660 - binary_crossentropy: 0.2937 - precision: 0.9773 - recall: 0.9542 - auc: 0.9948\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.2583 - accuracy: 0.9722 - binary_crossentropy: 0.2583 - precision: 0.9789 - recall: 0.9653 - auc: 0.9960\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.2319 - accuracy: 0.9771 - binary_crossentropy: 0.2319 - precision: 0.9818 - recall: 0.9723 - auc: 0.9967\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.2114 - accuracy: 0.9771 - binary_crossentropy: 0.2114 - precision: 0.9804 - recall: 0.9736 - auc: 0.9974\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1941 - accuracy: 0.9771 - binary_crossentropy: 0.1941 - precision: 0.9818 - recall: 0.9723 - auc: 0.9977\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.1790 - accuracy: 0.9812 - binary_crossentropy: 0.1790 - precision: 0.9846 - recall: 0.9778 - auc: 0.9979\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.1669 - accuracy: 0.9812 - binary_crossentropy: 0.1669 - precision: 0.9846 - recall: 0.9778 - auc: 0.9981\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1566 - accuracy: 0.9847 - binary_crossentropy: 0.1566 - precision: 0.9916 - recall: 0.9778 - auc: 0.9982\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1472 - accuracy: 0.9826 - binary_crossentropy: 0.1472 - precision: 0.9901 - recall: 0.9750 - auc: 0.9983\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1404 - accuracy: 0.9826 - binary_crossentropy: 0.1404 - precision: 0.9888 - recall: 0.9764 - auc: 0.9982\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1329 - accuracy: 0.9847 - binary_crossentropy: 0.1329 - precision: 0.9916 - recall: 0.9778 - auc: 0.9985\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.1268 - accuracy: 0.9861 - binary_crossentropy: 0.1268 - precision: 0.9944 - recall: 0.9778 - auc: 0.9984\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1215 - accuracy: 0.9868 - binary_crossentropy: 0.1215 - precision: 0.9944 - recall: 0.9792 - auc: 0.9985\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1163 - accuracy: 0.9868 - binary_crossentropy: 0.1163 - precision: 0.9944 - recall: 0.9792 - auc: 0.9986\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.1120 - accuracy: 0.9875 - binary_crossentropy: 0.1120 - precision: 0.9944 - recall: 0.9806 - auc: 0.9986\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.1076 - accuracy: 0.9882 - binary_crossentropy: 0.1076 - precision: 0.9944 - recall: 0.9820 - auc: 0.9987\n",
      "Loss of Train ......................................\n",
      "[0.679245114326477, 0.5046676993370056, 0.40519315004348755, 0.3388526141643524, 0.293693870306015, 0.2583180069923401, 0.23185020685195923, 0.21141107380390167, 0.19407302141189575, 0.17898745834827423, 0.16694195568561554, 0.15664520859718323, 0.1472177654504776, 0.1403612494468689, 0.13292765617370605, 0.12684862315654755, 0.12148797512054443, 0.11629649251699448, 0.11197298765182495, 0.10759629309177399]\n",
      "Accuracy of Train ......................................\n",
      "[0.5798611044883728, 0.8465277552604675, 0.9333333373069763, 0.9548611044883728, 0.9659722447395325, 0.9722222089767456, 0.9770833253860474, 0.9770833253860474, 0.9770833253860474, 0.981249988079071, 0.981249988079071, 0.9847221970558167, 0.9826388955116272, 0.9826388955116272, 0.9847221970558167, 0.9861111044883728, 0.9868055582046509, 0.9868055582046509, 0.987500011920929, 0.988194465637207]\n",
      "Precision of Train ......................................\n",
      "[0.590624988079071, 0.854107677936554, 0.9483500719070435, 0.9632768630981445, 0.9772727489471436, 0.9789029359817505, 0.981792688369751, 0.9804469347000122, 0.981792688369751, 0.9846368432044983, 0.9846368432044983, 0.9915611743927002, 0.9901408553123474, 0.9887640476226807, 0.9915611743927002, 0.994358241558075, 0.9943661689758301, 0.9943661689758301, 0.9943740963935852, 0.9943820238113403]\n",
      "Recall of Train ......................................\n",
      "[0.5242718458175659, 0.8363384008407593, 0.9167822599411011, 0.9459084868431091, 0.9542302489280701, 0.9653259515762329, 0.9722607731819153, 0.9736477136611938, 0.9722607731819153, 0.9778085947036743, 0.9778085947036743, 0.9778085947036743, 0.9750346541404724, 0.9764216542243958, 0.9778085947036743, 0.9778085947036743, 0.9791955351829529, 0.9791955351829529, 0.9805825352668762, 0.9819694757461548]\n",
      "AUC of Train ......................................\n",
      "[0.6242045164108276, 0.9313645362854004, 0.983944833278656, 0.9929957985877991, 0.9948485493659973, 0.9960262775421143, 0.9967342019081116, 0.9974392056465149, 0.9976620078086853, 0.997948408126831, 0.9981056451797485, 0.998157799243927, 0.998252272605896, 0.9982466101646423, 0.9984692931175232, 0.9984336495399475, 0.9985059499740601, 0.9985657930374146, 0.9986333847045898, 0.9986535310745239]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9508333295583725\n",
      " Loss:0.23122942112386227\n",
      " Precision:0.9579857617616654\n",
      " Recall:0.941123440861702\n",
      " AUC:0.9748596131801606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 0.11657626926898956; accuracy of 0.9861111044883728%\n",
      "[[181   0]\n",
      " [  5 174]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 561.9457014999999 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:181,FN:5,TP:174,FP:0\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9861111111111112\n",
      " Loss:0.11657626926898956\n",
      " Precision:1.0\n",
      " Recall:0.9720670391061452\n",
      " AUC:0.9725926593380189\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9601736098527909 - Loss: 0.2284755188971758\n",
      "> Fold 1 - Precision: 0.9654589891433716\n",
      "> Fold 1 - Recall: 0.9576766312122345\n",
      "> Fold 1 - AUC: 0.9807051718235016\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9833333333333333 - Loss: 0.12384778261184692\n",
      "> Fold 1 - Precision: 1.0\n",
      "> Fold 1 - Recall: 0.9634146341463414\n",
      "> Fold 1 - AUC: 0.9668558319246559\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.9465277761220932 - Loss: 0.24646956324577332\n",
      "> Fold 2 - Precision: 0.9678802967071534\n",
      "> Fold 2 - Recall: 0.9248603373765946\n",
      "> Fold 2 - AUC: 0.9743687093257904\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 1.0 - Loss: 0.10256250202655792\n",
      "> Fold 2 - Precision: 1.0\n",
      "> Fold 2 - Recall: 1.0\n",
      "> Fold 2 - AUC: 1.0\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9519791692495346 - Loss: 0.23760231360793113\n",
      "> Fold 3 - Precision: 0.9735389798879623\n",
      "> Fold 3 - Recall: 0.9268854707479477\n",
      "> Fold 3 - AUC: 0.9758212149143219\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9888888888888889 - Loss: 0.10625015944242477\n",
      "> Fold 3 - Precision: 0.9891304347826086\n",
      "> Fold 3 - Recall: 0.9891304347826086\n",
      "> Fold 3 - AUC: 0.9888833992094861\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9617013931274414 - Loss: 0.2187665119767189\n",
      "> Fold 4 - Precision: 0.9764510482549668\n",
      "> Fold 4 - Recall: 0.9457805901765823\n",
      "> Fold 4 - AUC: 0.9850599288940429\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9805555555555555 - Loss: 0.1199062168598175\n",
      "> Fold 4 - Precision: 1.0\n",
      "> Fold 4 - Recall: 0.9629629629629629\n",
      "> Fold 4 - AUC: 0.9618185601331668\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9508333295583725 - Loss: 0.23122942112386227\n",
      "> Fold 5 - Precision: 0.9579857617616654\n",
      "> Fold 5 - Recall: 0.941123440861702\n",
      "> Fold 5 - AUC: 0.9748596131801606\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9861111111111112 - Loss: 0.11657626926898956\n",
      "> Fold 5 - Precision: 1.0\n",
      "> Fold 5 - Recall: 0.9720670391061452\n",
      "> Fold 5 - AUC: 0.9725926593380189\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9542430555820465 (+- 0.005780574762556458)\n",
      "> Loss: 0.2325086657702923 (+- 0.00924771796787238)\n",
      "> Precision: 0.9682630151510239 (+- 0.006457718831052221)\n",
      "> Recall: 0.9392652940750121 (+- 0.012211813387413823)\n",
      "> AUC: 0.9781629276275634 (+- 0.004118816075351929)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9877777777777779 (+- 0.006712803318663666)\n",
      "> Loss: 0.11382858604192733 (+- 0.008114540752833103)\n",
      "> Precision: 0.9978260869565216 (+- 0.004347826086956541)\n",
      "> Recall: 0.9775150141996116 (+- 0.01470208099027697)\n",
      "> AUC: 0.9780300901210655 (+- 0.014266847322140144)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 898 FN SUM: 20 TP SUM: 880 FP SUM: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  model = VGG16()\n",
    "  model_2 = Sequential()\n",
    "  for layer in model.layers[:-3]:\n",
    "    model_2.add(layer)\n",
    "\n",
    "  # Freeze the layers\n",
    "  for layer in model_2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(Dense(1,activation='sigmoid'))\n",
    "  model_2.summary()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f0f370",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584c547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 9s 108ms/step - loss: 0.6676 - accuracy: 0.5910 - binary_crossentropy: 0.6676 - precision: 0.5931 - recall: 0.5939 - auc: 0.6332\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 111ms/step - loss: 0.4985 - accuracy: 0.8903 - binary_crossentropy: 0.4985 - precision: 0.9090 - recall: 0.8688 - auc: 0.9505\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 112ms/step - loss: 0.3948 - accuracy: 0.9569 - binary_crossentropy: 0.3948 - precision: 0.9649 - recall: 0.9489 - auc: 0.9862\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.3323 - accuracy: 0.9563 - binary_crossentropy: 0.3323 - precision: 0.9675 - recall: 0.9448 - auc: 0.9898\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.2888 - accuracy: 0.9639 - binary_crossentropy: 0.2888 - precision: 0.9746 - recall: 0.9530 - auc: 0.9921\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.2564 - accuracy: 0.9667 - binary_crossentropy: 0.2564 - precision: 0.9801 - recall: 0.9530 - auc: 0.9928\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2306 - accuracy: 0.9681 - binary_crossentropy: 0.2306 - precision: 0.9815 - recall: 0.9544 - auc: 0.9946\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 124ms/step - loss: 0.2107 - accuracy: 0.9715 - binary_crossentropy: 0.2107 - precision: 0.9886 - recall: 0.9544 - auc: 0.9949\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 124ms/step - loss: 0.1966 - accuracy: 0.9722 - binary_crossentropy: 0.1966 - precision: 0.9858 - recall: 0.9586 - auc: 0.9954\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 125ms/step - loss: 0.1830 - accuracy: 0.9715 - binary_crossentropy: 0.1830 - precision: 0.9886 - recall: 0.9544 - auc: 0.9955\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 125ms/step - loss: 0.1720 - accuracy: 0.9743 - binary_crossentropy: 0.1720 - precision: 0.9900 - recall: 0.9586 - auc: 0.9956\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 126ms/step - loss: 0.1633 - accuracy: 0.9757 - binary_crossentropy: 0.1633 - precision: 0.9914 - recall: 0.9599 - auc: 0.9959\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 126ms/step - loss: 0.1542 - accuracy: 0.9771 - binary_crossentropy: 0.1542 - precision: 0.9915 - recall: 0.9627 - auc: 0.9961\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 126ms/step - loss: 0.1475 - accuracy: 0.9771 - binary_crossentropy: 0.1475 - precision: 0.9929 - recall: 0.9613 - auc: 0.9964\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 126ms/step - loss: 0.1410 - accuracy: 0.9771 - binary_crossentropy: 0.1410 - precision: 0.9915 - recall: 0.9627 - auc: 0.9963\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.1348 - accuracy: 0.9806 - binary_crossentropy: 0.1348 - precision: 0.9957 - recall: 0.9655 - auc: 0.9966\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.1295 - accuracy: 0.9792 - binary_crossentropy: 0.1295 - precision: 0.9915 - recall: 0.9669 - auc: 0.9969\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.1249 - accuracy: 0.9812 - binary_crossentropy: 0.1249 - precision: 0.9943 - recall: 0.9682 - auc: 0.9969\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.1206 - accuracy: 0.9812 - binary_crossentropy: 0.1206 - precision: 0.9929 - recall: 0.9696 - auc: 0.9972\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.1168 - accuracy: 0.9812 - binary_crossentropy: 0.1168 - precision: 0.9957 - recall: 0.9669 - auc: 0.9972\n",
      "Loss of Train ......................................\n",
      "[0.6676132678985596, 0.4984768331050873, 0.3948237895965576, 0.3323279619216919, 0.2887742221355438, 0.2563619911670685, 0.23057366907596588, 0.21070696413516998, 0.19660940766334534, 0.1829902082681656, 0.17195750772953033, 0.16334319114685059, 0.15416213870048523, 0.14751523733139038, 0.14099904894828796, 0.13477995991706848, 0.1295231133699417, 0.12490034848451614, 0.12058071792125702, 0.11681654304265976]\n",
      "Accuracy of Train ......................................\n",
      "[0.5909722447395325, 0.8902778029441833, 0.956944465637207, 0.956250011920929, 0.9638888835906982, 0.9666666388511658, 0.9680555462837219, 0.9715277552604675, 0.9722222089767456, 0.9715277552604675, 0.9743055701255798, 0.9756944179534912, 0.9770833253860474, 0.9770833253860474, 0.9770833253860474, 0.980555534362793, 0.9791666865348816, 0.981249988079071, 0.981249988079071, 0.981249988079071]\n",
      "Precision of Train ......................................\n",
      "[0.5931034684181213, 0.9089595079421997, 0.9648876190185547, 0.9674682021141052, 0.9745762944221497, 0.9801136255264282, 0.9815340638160706, 0.9885550737380981, 0.9857954382896423, 0.9885550737380981, 0.9900142550468445, 0.9914407730102539, 0.991465151309967, 0.9928673505783081, 0.991465151309967, 0.995726466178894, 0.9915013909339905, 0.9943262338638306, 0.9929278492927551, 0.9957325458526611]\n",
      "Recall of Train ......................................\n",
      "[0.5939226746559143, 0.8687845468521118, 0.9488950371742249, 0.9447513818740845, 0.9530386924743652, 0.9530386924743652, 0.9544199109077454, 0.9544199109077454, 0.958563506603241, 0.9544199109077454, 0.958563506603241, 0.9599447250366211, 0.9627071619033813, 0.9613259434700012, 0.9627071619033813, 0.9654695987701416, 0.9668508172035217, 0.9682320356369019, 0.969613254070282, 0.9668508172035217]\n",
      "AUC of Train ......................................\n",
      "[0.6332294344902039, 0.9504807591438293, 0.9861512184143066, 0.9897671937942505, 0.9920580387115479, 0.9928344488143921, 0.994626522064209, 0.9949226975440979, 0.9954213500022888, 0.9954887628555298, 0.9955727458000183, 0.9959083795547485, 0.9960878491401672, 0.9963723421096802, 0.9962537288665771, 0.9965875148773193, 0.9969202280044556, 0.9969173669815063, 0.9971507787704468, 0.9971710443496704]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9496527731418609\n",
      " Loss:0.23319180607795714\n",
      " Precision:0.963050776720047\n",
      " Recall:0.9363259643316268\n",
      " AUC:0.9744961202144623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 0.10781398415565491; accuracy of 0.9861111044883728%\n",
      "[[182   2]\n",
      " [  3 173]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 128.7567372 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:182,FN:3,TP:173,FP:2\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9861111111111112\n",
      " Loss:0.10781398415565491\n",
      " Precision:0.9885714285714285\n",
      " Recall:0.9829545454545454\n",
      " AUC:0.9833691646191647\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 126ms/step - loss: 0.5837 - accuracy: 0.7688 - binary_crossentropy: 0.5837 - precision: 0.7598 - recall: 0.7821 - auc: 0.8336\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.4498 - accuracy: 0.9208 - binary_crossentropy: 0.4498 - precision: 0.9413 - recall: 0.8966 - auc: 0.9711\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.3658 - accuracy: 0.9569 - binary_crossentropy: 0.3658 - precision: 0.9795 - recall: 0.9330 - auc: 0.9904\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.3121 - accuracy: 0.9688 - binary_crossentropy: 0.3121 - precision: 0.9884 - recall: 0.9483 - auc: 0.9932\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.2726 - accuracy: 0.9715 - binary_crossentropy: 0.2726 - precision: 0.9870 - recall: 0.9553 - auc: 0.9953\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.2439 - accuracy: 0.9819 - binary_crossentropy: 0.2439 - precision: 0.9971 - recall: 0.9665 - auc: 0.9956\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.2208 - accuracy: 0.9792 - binary_crossentropy: 0.2208 - precision: 0.9942 - recall: 0.9637 - auc: 0.9964\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.2022 - accuracy: 0.9792 - binary_crossentropy: 0.2022 - precision: 0.9914 - recall: 0.9665 - auc: 0.9965\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.1871 - accuracy: 0.9826 - binary_crossentropy: 0.1871 - precision: 0.9986 - recall: 0.9665 - auc: 0.9968\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.1746 - accuracy: 0.9833 - binary_crossentropy: 0.1746 - precision: 0.9971 - recall: 0.9693 - auc: 0.9965\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.1637 - accuracy: 0.9840 - binary_crossentropy: 0.1637 - precision: 0.9957 - recall: 0.9721 - auc: 0.9974\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.1546 - accuracy: 0.9840 - binary_crossentropy: 0.1546 - precision: 0.9957 - recall: 0.9721 - auc: 0.9973\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.1472 - accuracy: 0.9847 - binary_crossentropy: 0.1472 - precision: 0.9971 - recall: 0.9721 - auc: 0.9972\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.1395 - accuracy: 0.9847 - binary_crossentropy: 0.1395 - precision: 0.9957 - recall: 0.9735 - auc: 0.9975\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.1338 - accuracy: 0.9847 - binary_crossentropy: 0.1338 - precision: 0.9986 - recall: 0.9707 - auc: 0.9976\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.1281 - accuracy: 0.9854 - binary_crossentropy: 0.1281 - precision: 0.9971 - recall: 0.9735 - auc: 0.9977\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.1227 - accuracy: 0.9854 - binary_crossentropy: 0.1227 - precision: 0.9971 - recall: 0.9735 - auc: 0.9979\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.1183 - accuracy: 0.9875 - binary_crossentropy: 0.1183 - precision: 0.9972 - recall: 0.9777 - auc: 0.9978\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.1140 - accuracy: 0.9868 - binary_crossentropy: 0.1140 - precision: 0.9986 - recall: 0.9749 - auc: 0.9980\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.1106 - accuracy: 0.9861 - binary_crossentropy: 0.1106 - precision: 0.9957 - recall: 0.9763 - auc: 0.9979\n",
      "Loss of Train ......................................\n",
      "[0.5837489366531372, 0.4497661590576172, 0.36579054594039917, 0.31207799911499023, 0.2726348042488098, 0.24386025965213776, 0.2208472341299057, 0.20221444964408875, 0.18708840012550354, 0.17459940910339355, 0.16371487081050873, 0.15458601713180542, 0.14716604351997375, 0.13953764736652374, 0.13379891216754913, 0.12805891036987305, 0.1226792261004448, 0.11827642470598221, 0.11401499807834625, 0.11059167981147766]\n",
      "Accuracy of Train ......................................\n",
      "[0.768750011920929, 0.9208333492279053, 0.956944465637207, 0.96875, 0.9715277552604675, 0.9819444417953491, 0.9791666865348816, 0.9791666865348816, 0.9826388955116272, 0.9833333492279053, 0.9840278029441833, 0.9840278029441833, 0.9847221970558167, 0.9847221970558167, 0.9847221970558167, 0.9854166507720947, 0.9854166507720947, 0.987500011920929, 0.9868055582046509, 0.9861111044883728]\n",
      "Precision of Train ......................................\n",
      "[0.7598371505737305, 0.9413489699363708, 0.9794721603393555, 0.9883551597595215, 0.9870129823684692, 0.9971181750297546, 0.9942362904548645, 0.9914039969444275, 0.9985569715499878, 0.9971264600753784, 0.995708167552948, 0.995708167552948, 0.9971346855163574, 0.9957143068313599, 0.9985632300376892, 0.9971387982368469, 0.9971387982368469, 0.9971510171890259, 0.9985693693161011, 0.995726466178894]\n",
      "Recall of Train ......................................\n",
      "[0.7821229100227356, 0.8966480493545532, 0.9329608678817749, 0.9483240246772766, 0.9553072452545166, 0.9664804339408875, 0.9636871218681335, 0.9664804339408875, 0.9664804339408875, 0.9692737460136414, 0.9720670580863953, 0.9720670580863953, 0.9720670580863953, 0.9734637141227722, 0.9706704020500183, 0.9734637141227722, 0.9734637141227722, 0.9776536226272583, 0.9748603105545044, 0.9762569665908813]\n",
      "AUC of Train ......................................\n",
      "[0.8335973024368286, 0.971136212348938, 0.990373969078064, 0.9931576251983643, 0.995294988155365, 0.9955968856811523, 0.9964147806167603, 0.9964871406555176, 0.9968209266662598, 0.9964967966079712, 0.9973976612091064, 0.9973427653312683, 0.9972211122512817, 0.9974738359451294, 0.9976310729980469, 0.9977062940597534, 0.9978567957878113, 0.9977603554725647, 0.9980169534683228, 0.9978683590888977]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9673263907432557\n",
      " Loss:0.2172526463866234\n",
      " Precision:0.9801510661840439\n",
      " Recall:0.954189944267273\n",
      " AUC:0.9870825916528702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 0.1353737860918045; accuracy of 0.9750000238418579%\n",
      "[[176   0]\n",
      " [  9 175]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 255.069448 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:176,FN:9,TP:175,FP:0\n",
      "Test of epochs .................................\n",
      " Accuracy:0.975\n",
      " Loss:0.1353737860918045\n",
      " Precision:1.0\n",
      " Recall:0.9510869565217391\n",
      " AUC:0.9512191539365453\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 127ms/step - loss: 0.6619 - accuracy: 0.6201 - binary_crossentropy: 0.6619 - precision: 0.6351 - recall: 0.5673 - auc: 0.6479\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 129ms/step - loss: 0.4995 - accuracy: 0.8632 - binary_crossentropy: 0.4995 - precision: 0.8853 - recall: 0.8350 - auc: 0.9309\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4044 - accuracy: 0.9278 - binary_crossentropy: 0.4044 - precision: 0.9465 - recall: 0.9071 - auc: 0.9796\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.3415 - accuracy: 0.9493 - binary_crossentropy: 0.3415 - precision: 0.9629 - recall: 0.9348 - auc: 0.9877\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.2942 - accuracy: 0.9632 - binary_crossentropy: 0.2942 - precision: 0.9841 - recall: 0.9417 - auc: 0.9919\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.2623 - accuracy: 0.9660 - binary_crossentropy: 0.2623 - precision: 0.9870 - recall: 0.9445 - auc: 0.9928\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.2374 - accuracy: 0.9701 - binary_crossentropy: 0.2374 - precision: 0.9942 - recall: 0.9459 - auc: 0.9939\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.2152 - accuracy: 0.9743 - binary_crossentropy: 0.2152 - precision: 0.9942 - recall: 0.9542 - auc: 0.9953\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.1990 - accuracy: 0.9757 - binary_crossentropy: 0.1990 - precision: 1.0000 - recall: 0.9515 - auc: 0.9954\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.1850 - accuracy: 0.9764 - binary_crossentropy: 0.1850 - precision: 0.9985 - recall: 0.9542 - auc: 0.9960\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.1739 - accuracy: 0.9785 - binary_crossentropy: 0.1739 - precision: 0.9957 - recall: 0.9612 - auc: 0.9962\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.1632 - accuracy: 0.9792 - binary_crossentropy: 0.1632 - precision: 0.9986 - recall: 0.9598 - auc: 0.9964\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.1549 - accuracy: 0.9799 - binary_crossentropy: 0.1549 - precision: 0.9986 - recall: 0.9612 - auc: 0.9965\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.1468 - accuracy: 0.9819 - binary_crossentropy: 0.1468 - precision: 0.9971 - recall: 0.9667 - auc: 0.9971\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.1394 - accuracy: 0.9847 - binary_crossentropy: 0.1394 - precision: 1.0000 - recall: 0.9695 - auc: 0.9969\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1340 - accuracy: 0.9847 - binary_crossentropy: 0.1340 - precision: 1.0000 - recall: 0.9695 - auc: 0.9970\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1281 - accuracy: 0.9819 - binary_crossentropy: 0.1281 - precision: 0.9986 - recall: 0.9653 - auc: 0.9969\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1229 - accuracy: 0.9861 - binary_crossentropy: 0.1229 - precision: 1.0000 - recall: 0.9723 - auc: 0.9971\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1183 - accuracy: 0.9847 - binary_crossentropy: 0.1183 - precision: 0.9986 - recall: 0.9709 - auc: 0.9976\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1142 - accuracy: 0.9868 - binary_crossentropy: 0.1142 - precision: 1.0000 - recall: 0.9736 - auc: 0.9975\n",
      "Loss of Train ......................................\n",
      "[0.6619374752044678, 0.49949076771736145, 0.4044139087200165, 0.3415161073207855, 0.2942107617855072, 0.26233646273612976, 0.237397700548172, 0.21517206728458405, 0.19895394146442413, 0.18502527475357056, 0.17389684915542603, 0.16316138207912445, 0.1549435257911682, 0.14681091904640198, 0.13940255343914032, 0.13397519290447235, 0.12813833355903625, 0.12289012968540192, 0.11828216165304184, 0.11422836780548096]\n",
      "Accuracy of Train ......................................\n",
      "[0.6201388835906982, 0.863194465637207, 0.9277777671813965, 0.949305534362793, 0.9631944298744202, 0.9659722447395325, 0.9701389074325562, 0.9743055701255798, 0.9756944179534912, 0.9763888716697693, 0.9784722328186035, 0.9791666865348816, 0.9798611402511597, 0.9819444417953491, 0.9847221970558167, 0.9847221970558167, 0.9819444417953491, 0.9861111044883728, 0.9847221970558167, 0.9868055582046509]\n",
      "Precision of Train ......................................\n",
      "[0.6350931525230408, 0.8852941393852234, 0.9464544057846069, 0.9628571271896362, 0.9840579628944397, 0.9869565367698669, 0.9941691160202026, 0.9942196607589722, 1.0, 0.9985486268997192, 0.9956896305084229, 0.9985569715499878, 0.9985590577125549, 0.9971387982368469, 1.0, 1.0, 0.9985652565956116, 1.0, 0.9985734820365906, 1.0]\n",
      "Recall of Train ......................................\n",
      "[0.567267656326294, 0.8349514603614807, 0.9070734977722168, 0.9348127841949463, 0.9417475461959839, 0.9445214867591858, 0.9459084868431091, 0.9542302489280701, 0.9514563083648682, 0.9542302489280701, 0.9611650705337524, 0.9597780704498291, 0.9611650705337524, 0.9667128920555115, 0.9694868326187134, 0.9694868326187134, 0.9653259515762329, 0.9722607731819153, 0.9708737730979919, 0.9736477136611938]\n",
      "AUC of Train ......................................\n",
      "[0.6479246616363525, 0.9309354424476624, 0.9796199798583984, 0.9876764416694641, 0.9919472932815552, 0.9927585124969482, 0.9939476847648621, 0.995254635810852, 0.9953828454017639, 0.9959529042243958, 0.9961621761322021, 0.996420681476593, 0.9964939951896667, 0.9970727562904358, 0.9969454407691956, 0.9969916939735413, 0.9969300031661987, 0.9971276521682739, 0.9976022243499756, 0.9974970817565918]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9507291644811631\n",
      " Loss:0.23480919413268567\n",
      " Precision:0.9687366962432862\n",
      " Recall:0.9303051352500915\n",
      " AUC:0.9740322053432464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 0.11434374749660492; accuracy of 0.9777777791023254%\n",
      "[[179   2]\n",
      " [  6 173]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 383.37388020000003 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:179,FN:6,TP:173,FP:2\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9777777777777777\n",
      " Loss:0.11434374749660492\n",
      " Precision:0.9885714285714285\n",
      " Recall:0.9664804469273743\n",
      " AUC:0.967024007247471\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 132ms/step - loss: 0.6772 - accuracy: 0.5847 - binary_crossentropy: 0.6772 - precision: 0.5880 - recall: 0.5815 - auc: 0.6050\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.5026 - accuracy: 0.8743 - binary_crossentropy: 0.5026 - precision: 0.8975 - recall: 0.8467 - auc: 0.9437\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4027 - accuracy: 0.9465 - binary_crossentropy: 0.4027 - precision: 0.9668 - recall: 0.9254 - auc: 0.9875\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.3381 - accuracy: 0.9618 - binary_crossentropy: 0.3381 - precision: 0.9827 - recall: 0.9406 - auc: 0.9928\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.2913 - accuracy: 0.9681 - binary_crossentropy: 0.2913 - precision: 0.9927 - recall: 0.9434 - auc: 0.9946\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.2581 - accuracy: 0.9750 - binary_crossentropy: 0.2581 - precision: 0.9943 - recall: 0.9558 - auc: 0.9955\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.2333 - accuracy: 0.9743 - binary_crossentropy: 0.2333 - precision: 0.9928 - recall: 0.9558 - auc: 0.9954\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.2129 - accuracy: 0.9771 - binary_crossentropy: 0.2129 - precision: 0.9957 - recall: 0.9586 - auc: 0.9961\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.1963 - accuracy: 0.9750 - binary_crossentropy: 0.1963 - precision: 0.9971 - recall: 0.9530 - auc: 0.9967\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.1829 - accuracy: 0.9785 - binary_crossentropy: 0.1829 - precision: 0.9943 - recall: 0.9627 - auc: 0.9965\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1715 - accuracy: 0.9812 - binary_crossentropy: 0.1715 - precision: 0.9971 - recall: 0.9655 - auc: 0.9968\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.1617 - accuracy: 0.9799 - binary_crossentropy: 0.1617 - precision: 0.9971 - recall: 0.9627 - auc: 0.9966\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1538 - accuracy: 0.9819 - binary_crossentropy: 0.1538 - precision: 0.9986 - recall: 0.9655 - auc: 0.9971\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1461 - accuracy: 0.9826 - binary_crossentropy: 0.1461 - precision: 0.9986 - recall: 0.9669 - auc: 0.9973\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1394 - accuracy: 0.9806 - binary_crossentropy: 0.1394 - precision: 0.9971 - recall: 0.9641 - auc: 0.9976\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1338 - accuracy: 0.9819 - binary_crossentropy: 0.1338 - precision: 0.9972 - recall: 0.9669 - auc: 0.9975\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1274 - accuracy: 0.9833 - binary_crossentropy: 0.1274 - precision: 0.9972 - recall: 0.9696 - auc: 0.9977\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1235 - accuracy: 0.9819 - binary_crossentropy: 0.1235 - precision: 0.9972 - recall: 0.9669 - auc: 0.9977\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1193 - accuracy: 0.9819 - binary_crossentropy: 0.1193 - precision: 0.9972 - recall: 0.9669 - auc: 0.9977\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1152 - accuracy: 0.9840 - binary_crossentropy: 0.1152 - precision: 0.9972 - recall: 0.9710 - auc: 0.9981\n",
      "Loss of Train ......................................\n",
      "[0.6772229671478271, 0.5025762319564819, 0.4026701748371124, 0.3381427228450775, 0.29129281640052795, 0.25810039043426514, 0.23328062891960144, 0.2128549963235855, 0.1963050812482834, 0.18285369873046875, 0.17147444188594818, 0.16167879104614258, 0.15384195744991302, 0.1461016982793808, 0.13936445116996765, 0.13375140726566315, 0.1274009793996811, 0.12346497923135757, 0.11934574693441391, 0.11522211134433746]\n",
      "Accuracy of Train ......................................\n",
      "[0.5847222208976746, 0.8743055462837219, 0.9465277791023254, 0.9618055820465088, 0.9680555462837219, 0.9750000238418579, 0.9743055701255798, 0.9770833253860474, 0.9750000238418579, 0.9784722328186035, 0.981249988079071, 0.9798611402511597, 0.9819444417953491, 0.9826388955116272, 0.980555534362793, 0.9819444417953491, 0.9833333492279053, 0.9819444417953491, 0.9819444417953491, 0.9840278029441833]\n",
      "Precision of Train ......................................\n",
      "[0.5879888534545898, 0.8975110054016113, 0.966810941696167, 0.9826839566230774, 0.992732584476471, 0.9942528605461121, 0.9928264021873474, 0.9956958293914795, 0.9971098303794861, 0.9942938685417175, 0.9971469044685364, 0.9971387982368469, 0.9985714554786682, 0.9985734820365906, 0.9971428513526917, 0.9971510171890259, 0.9971590638160706, 0.9971510171890259, 0.9971510171890259, 0.9971631169319153]\n",
      "Recall of Train ......................................\n",
      "[0.5814917087554932, 0.8466851115226746, 0.9254143834114075, 0.9406077265739441, 0.9433701634407043, 0.9558011293411255, 0.9558011293411255, 0.958563506603241, 0.9530386924743652, 0.9627071619033813, 0.9654695987701416, 0.9627071619033813, 0.9654695987701416, 0.9668508172035217, 0.9640883803367615, 0.9668508172035217, 0.969613254070282, 0.9668508172035217, 0.9668508172035217, 0.9709944725036621]\n",
      "AUC of Train ......................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6049888134002686, 0.9436817765235901, 0.9874890446662903, 0.9928306341171265, 0.9946487545967102, 0.9954628348350525, 0.9953837394714355, 0.9961109757423401, 0.9967138171195984, 0.9965237975120544, 0.9968169927597046, 0.9965682029724121, 0.9971054196357727, 0.9973494410514832, 0.9975693821907043, 0.9975288510322571, 0.9977179765701294, 0.9976629614830017, 0.9976985454559326, 0.9980603456497192]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9517361164093018\n",
      " Loss:0.23434731364250183\n",
      " Precision:0.9688127428293228\n",
      " Recall:0.9344613224267959\n",
      " AUC:0.9738956153392792\n",
      "Score for fold 4: loss of 0.10500852018594742; accuracy of 0.9916666746139526%\n",
      "[[183   1]\n",
      " [  2 174]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 512.1977386 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:183,FN:2,TP:174,FP:1\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9916666666666667\n",
      " Loss:0.10500852018594742\n",
      " Precision:0.9942857142857143\n",
      " Recall:0.9886363636363636\n",
      " AUC:0.9889127764127764\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 133ms/step - loss: 0.6197 - accuracy: 0.6854 - binary_crossentropy: 0.6197 - precision: 0.7183 - recall: 0.6028 - auc: 0.7346\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.4744 - accuracy: 0.8674 - binary_crossentropy: 0.4744 - precision: 0.8922 - recall: 0.8336 - auc: 0.9459\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.3831 - accuracy: 0.9431 - binary_crossentropy: 0.3831 - precision: 0.9774 - recall: 0.9063 - auc: 0.9847\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.3231 - accuracy: 0.9569 - binary_crossentropy: 0.3231 - precision: 0.9823 - recall: 0.9301 - auc: 0.9909\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.2813 - accuracy: 0.9674 - binary_crossentropy: 0.2813 - precision: 0.9897 - recall: 0.9441 - auc: 0.9931\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.2502 - accuracy: 0.9701 - binary_crossentropy: 0.2502 - precision: 0.9884 - recall: 0.9510 - auc: 0.9937\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.2268 - accuracy: 0.9694 - binary_crossentropy: 0.2268 - precision: 0.9884 - recall: 0.9497 - auc: 0.9943\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.2071 - accuracy: 0.9757 - binary_crossentropy: 0.2071 - precision: 0.9899 - recall: 0.9608 - auc: 0.9951\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1913 - accuracy: 0.9771 - binary_crossentropy: 0.1913 - precision: 0.9899 - recall: 0.9636 - auc: 0.9955\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1794 - accuracy: 0.9785 - binary_crossentropy: 0.1794 - precision: 0.9914 - recall: 0.9650 - auc: 0.9953\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1675 - accuracy: 0.9826 - binary_crossentropy: 0.1675 - precision: 0.9943 - recall: 0.9706 - auc: 0.9959\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1584 - accuracy: 0.9826 - binary_crossentropy: 0.1584 - precision: 0.9929 - recall: 0.9720 - auc: 0.9967\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1508 - accuracy: 0.9812 - binary_crossentropy: 0.1508 - precision: 0.9914 - recall: 0.9706 - auc: 0.9964\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1437 - accuracy: 0.9826 - binary_crossentropy: 0.1437 - precision: 0.9929 - recall: 0.9720 - auc: 0.9966\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1362 - accuracy: 0.9833 - binary_crossentropy: 0.1362 - precision: 0.9943 - recall: 0.9720 - auc: 0.9970\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.1310 - accuracy: 0.9833 - binary_crossentropy: 0.1310 - precision: 0.9929 - recall: 0.9734 - auc: 0.9972\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1261 - accuracy: 0.9840 - binary_crossentropy: 0.1261 - precision: 0.9943 - recall: 0.9734 - auc: 0.9968\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1216 - accuracy: 0.9840 - binary_crossentropy: 0.1216 - precision: 0.9943 - recall: 0.9734 - auc: 0.9971\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.1170 - accuracy: 0.9847 - binary_crossentropy: 0.1170 - precision: 0.9943 - recall: 0.9748 - auc: 0.9971\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.1129 - accuracy: 0.9847 - binary_crossentropy: 0.1129 - precision: 0.9957 - recall: 0.9734 - auc: 0.9976\n",
      "Loss of Train ......................................\n",
      "[0.6197397708892822, 0.47444847226142883, 0.3830605447292328, 0.32313650846481323, 0.28128671646118164, 0.2502426505088806, 0.22679224610328674, 0.20712660253047943, 0.19130873680114746, 0.17943571507930756, 0.16750946640968323, 0.15838421881198883, 0.15081225335597992, 0.14370407164096832, 0.13615356385707855, 0.1309727281332016, 0.12607912719249725, 0.12158065289258957, 0.11701779812574387, 0.11291967332363129]\n",
      "Accuracy of Train ......................................\n",
      "[0.6854166388511658, 0.8673611283302307, 0.9430555701255798, 0.956944465637207, 0.9673610925674438, 0.9701389074325562, 0.9694444537162781, 0.9756944179534912, 0.9770833253860474, 0.9784722328186035, 0.9826388955116272, 0.9826388955116272, 0.981249988079071, 0.9826388955116272, 0.9833333492279053, 0.9833333492279053, 0.9840278029441833, 0.9840278029441833, 0.9847221970558167, 0.9847221970558167]\n",
      "Precision of Train ......................................\n",
      "[0.7183333039283752, 0.8922155499458313, 0.9773755669593811, 0.9822747707366943, 0.9897360801696777, 0.9883720874786377, 0.9883551597595215, 0.9899135231971741, 0.9899425506591797, 0.9913793206214905, 0.9942693114280701, 0.9928571581840515, 0.991428554058075, 0.9928571581840515, 0.9942775368690491, 0.9928673505783081, 0.9942857027053833, 0.9942857027053833, 0.9942938685417175, 0.995708167552948]\n",
      "Recall of Train ......................................\n",
      "[0.6027972102165222, 0.833566427230835, 0.9062936902046204, 0.9300699234008789, 0.9440559148788452, 0.9510489702224731, 0.9496503472328186, 0.9608391523361206, 0.9636363387107849, 0.9650349617004395, 0.9706293940544128, 0.9720279574394226, 0.9706293940544128, 0.9720279574394226, 0.9720279574394226, 0.9734265804290771, 0.9734265804290771, 0.9734265804290771, 0.9748252034187317, 0.9734265804290771]\n",
      "AUC of Train ......................................\n",
      "[0.7345898151397705, 0.9459272623062134, 0.9847069978713989, 0.9908868670463562, 0.9931429624557495, 0.9937449097633362, 0.9943486452102661, 0.9951483011245728, 0.995500385761261, 0.9953238368034363, 0.9958524107933044, 0.996663510799408, 0.9963800311088562, 0.9966278672218323, 0.9969549179077148, 0.9971700310707092, 0.996777355670929, 0.9970986247062683, 0.9971458911895752, 0.99761563539505]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9562152802944184\n",
      " Loss:0.22508557587862016\n",
      " Precision:0.97225142121315\n",
      " Recall:0.9366433560848236\n",
      " AUC:0.9795803129673004\n",
      "Score for fold 5: loss of 0.11433297395706177; accuracy of 0.9833333492279053%\n",
      "[[175   0]\n",
      " [  6 179]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 641.9553204 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:175,FN:6,TP:179,FP:0\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9833333333333333\n",
      " Loss:0.11433297395706177\n",
      " Precision:1.0\n",
      " Recall:0.9675675675675676\n",
      " AUC:0.9672091981484247\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9496527731418609 - Loss: 0.23319180607795714\n",
      "> Fold 1 - Precision: 0.963050776720047\n",
      "> Fold 1 - Recall: 0.9363259643316268\n",
      "> Fold 1 - AUC: 0.9744961202144623\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9861111111111112 - Loss: 0.10781398415565491\n",
      "> Fold 1 - Precision: 0.9885714285714285\n",
      "> Fold 1 - Recall: 0.9829545454545454\n",
      "> Fold 1 - AUC: 0.9833691646191647\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.9673263907432557 - Loss: 0.2172526463866234\n",
      "> Fold 2 - Precision: 0.9801510661840439\n",
      "> Fold 2 - Recall: 0.954189944267273\n",
      "> Fold 2 - AUC: 0.9870825916528702\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.975 - Loss: 0.1353737860918045\n",
      "> Fold 2 - Precision: 1.0\n",
      "> Fold 2 - Recall: 0.9510869565217391\n",
      "> Fold 2 - AUC: 0.9512191539365453\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9507291644811631 - Loss: 0.23480919413268567\n",
      "> Fold 3 - Precision: 0.9687366962432862\n",
      "> Fold 3 - Recall: 0.9303051352500915\n",
      "> Fold 3 - AUC: 0.9740322053432464\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9777777777777777 - Loss: 0.11434374749660492\n",
      "> Fold 3 - Precision: 0.9885714285714285\n",
      "> Fold 3 - Recall: 0.9664804469273743\n",
      "> Fold 3 - AUC: 0.967024007247471\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9517361164093018 - Loss: 0.23434731364250183\n",
      "> Fold 4 - Precision: 0.9688127428293228\n",
      "> Fold 4 - Recall: 0.9344613224267959\n",
      "> Fold 4 - AUC: 0.9738956153392792\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9916666666666667 - Loss: 0.10500852018594742\n",
      "> Fold 4 - Precision: 0.9942857142857143\n",
      "> Fold 4 - Recall: 0.9886363636363636\n",
      "> Fold 4 - AUC: 0.9889127764127764\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9562152802944184 - Loss: 0.22508557587862016\n",
      "> Fold 5 - Precision: 0.97225142121315\n",
      "> Fold 5 - Recall: 0.9366433560848236\n",
      "> Fold 5 - AUC: 0.9795803129673004\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9833333333333333 - Loss: 0.11433297395706177\n",
      "> Fold 5 - Precision: 1.0\n",
      "> Fold 5 - Recall: 0.9675675675675676\n",
      "> Fold 5 - AUC: 0.9672091981484247\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9551319450139999 (+- 0.006493313094419756)\n",
      "> Loss: 0.22893730722367764 (+- 0.0068295698115833315)\n",
      "> Precision: 0.9706005406379699 (+- 0.005614392523297362)\n",
      "> Recall: 0.9383851444721223 (+- 0.00821886457697688)\n",
      "> AUC: 0.9778173691034319 (+- 0.005092948682606577)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9827777777777778 (+- 0.005931710140017419)\n",
      "> Loss: 0.1153746023774147 (+- 0.010646441740682678)\n",
      "> Precision: 0.9942857142857143 (+- 0.005111012519999531)\n",
      "> Recall: 0.971345176021518 (+- 0.01328227390062627)\n",
      "> AUC: 0.9715468600728764 (+- 0.01337033343283363)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 895 FN SUM: 26 TP SUM: 874 FP SUM: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  model = VGG19()\n",
    "  model_2 = Sequential()\n",
    "  for layer in model.layers[:-3]:\n",
    "    model_2.add(layer)\n",
    "\n",
    "  # Freeze the layers\n",
    "  for layer in model_2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(Dense(1,activation='sigmoid'))\n",
    "  model_2.summary()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049c47ee",
   "metadata": {},
   "source": [
    "# ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d92bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 32s 429ms/step - loss: 0.7186 - accuracy: 0.5417 - binary_crossentropy: 0.7186 - precision: 0.6684 - recall: 0.1729 - auc: 0.6222\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.6528 - accuracy: 0.5951 - binary_crossentropy: 0.6528 - precision: 0.7941 - recall: 0.2614 - auc: 0.7297\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.6085 - accuracy: 0.6472 - binary_crossentropy: 0.6085 - precision: 0.8391 - recall: 0.3679 - auc: 0.7904\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.5571 - accuracy: 0.7083 - binary_crossentropy: 0.5571 - precision: 0.8704 - recall: 0.4924 - auc: 0.8567\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.5188 - accuracy: 0.7569 - binary_crossentropy: 0.5188 - precision: 0.9011 - recall: 0.5795 - auc: 0.8998\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.4888 - accuracy: 0.7896 - binary_crossentropy: 0.4888 - precision: 0.9118 - recall: 0.6432 - auc: 0.9219\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.4530 - accuracy: 0.8417 - binary_crossentropy: 0.4530 - precision: 0.9396 - recall: 0.7317 - auc: 0.9494\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.4301 - accuracy: 0.8785 - binary_crossentropy: 0.4301 - precision: 0.9463 - recall: 0.8036 - auc: 0.9646\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.4024 - accuracy: 0.8910 - binary_crossentropy: 0.4024 - precision: 0.9464 - recall: 0.8299 - auc: 0.9745\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.3838 - accuracy: 0.9111 - binary_crossentropy: 0.3838 - precision: 0.9514 - recall: 0.8672 - auc: 0.9786\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.3684 - accuracy: 0.9264 - binary_crossentropy: 0.3684 - precision: 0.9530 - recall: 0.8976 - auc: 0.9818\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.3554 - accuracy: 0.9243 - binary_crossentropy: 0.3554 - precision: 0.9555 - recall: 0.8907 - auc: 0.9833\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.3290 - accuracy: 0.9486 - binary_crossentropy: 0.3290 - precision: 0.9642 - recall: 0.9322 - auc: 0.9910\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.3203 - accuracy: 0.9507 - binary_crossentropy: 0.3203 - precision: 0.9684 - recall: 0.9322 - auc: 0.9918\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.3008 - accuracy: 0.9646 - binary_crossentropy: 0.3008 - precision: 0.9746 - recall: 0.9544 - auc: 0.9950\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.2968 - accuracy: 0.9597 - binary_crossentropy: 0.2968 - precision: 0.9743 - recall: 0.9447 - auc: 0.9951\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.2779 - accuracy: 0.9639 - binary_crossentropy: 0.2779 - precision: 0.9759 - recall: 0.9516 - auc: 0.9960\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.2810 - accuracy: 0.9646 - binary_crossentropy: 0.2810 - precision: 0.9773 - recall: 0.9516 - auc: 0.9951\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.2579 - accuracy: 0.9736 - binary_crossentropy: 0.2579 - precision: 0.9790 - recall: 0.9682 - auc: 0.9970\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.2438 - accuracy: 0.9785 - binary_crossentropy: 0.2438 - precision: 0.9779 - recall: 0.9793 - auc: 0.9984\n",
      "Loss of Train ......................................\n",
      "[0.718603789806366, 0.6527889966964722, 0.6084913015365601, 0.5570724606513977, 0.5188405513763428, 0.4887562096118927, 0.4530494809150696, 0.4301018714904785, 0.40235185623168945, 0.3838043510913849, 0.36841681599617004, 0.3554040491580963, 0.328985333442688, 0.32025498151779175, 0.30077382922172546, 0.2967623472213745, 0.2779015898704529, 0.28104367852211, 0.2579377591609955, 0.24375087022781372]\n",
      "Accuracy of Train ......................................\n",
      "[0.5416666865348816, 0.5951389074325562, 0.6472222208976746, 0.7083333134651184, 0.7569444179534912, 0.7895833253860474, 0.8416666388511658, 0.8784722089767456, 0.8909721970558167, 0.9111111164093018, 0.9263888597488403, 0.9243055582046509, 0.9486111402511597, 0.9506944417953491, 0.9645833373069763, 0.9597222208976746, 0.9638888835906982, 0.9645833373069763, 0.9736111164093018, 0.9784722328186035]\n",
      "Precision of Train ......................................\n",
      "[0.6684492230415344, 0.7941176295280457, 0.8391166925430298, 0.8704156279563904, 0.9010752439498901, 0.9117646813392639, 0.9396092295646667, 0.9462540745735168, 0.9463722109794617, 0.9514415860176086, 0.9530102610588074, 0.9554896354675293, 0.9642346501350403, 0.9683908224105835, 0.9745762944221497, 0.9743223786354065, 0.9758865237236023, 0.9772727489471436, 0.9790209531784058, 0.9779005646705627]\n",
      "Recall of Train ......................................\n",
      "[0.17289073765277863, 0.26141080260276794, 0.3679114878177643, 0.49239280819892883, 0.5795297622680664, 0.6431535482406616, 0.7316735982894897, 0.8035961389541626, 0.8298755288124084, 0.8672199249267578, 0.8976486921310425, 0.8907330632209778, 0.932226836681366, 0.932226836681366, 0.954356849193573, 0.9446749687194824, 0.9515905976295471, 0.9515905976295471, 0.9681881070137024, 0.9792531132698059]\n",
      "AUC of Train ......................................\n",
      "[0.6221761107444763, 0.7297387719154358, 0.7904400825500488, 0.8566853404045105, 0.8997802734375, 0.9219488501548767, 0.9494001269340515, 0.9646280407905579, 0.9745365977287292, 0.9786174893379211, 0.9817947149276733, 0.9832636117935181, 0.9910106062889099, 0.9917793273925781, 0.9950346350669861, 0.9951098561286926, 0.9960309267044067, 0.995127260684967, 0.9969839453697205, 0.9984422922134399]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8557986080646515\n",
      " Loss:0.4122546061873436\n",
      " Precision:0.9234360516071319\n",
      " Recall:0.7576071999967098\n",
      " AUC:0.93062644302845\n",
      "Score for fold 1: loss of 0.27646133303642273; accuracy of 0.9638888835906982%\n",
      "[[177   6]\n",
      " [  7 170]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 434.0711222 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:177,FN:7,TP:170,FP:6\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9638888888888889\n",
      " Loss:0.27646133303642273\n",
      " Precision:0.9659090909090909\n",
      " Recall:0.96045197740113\n",
      " AUC:0.9612042495701303\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 2049      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 28s 439ms/step - loss: 0.7739 - accuracy: 0.5069 - binary_crossentropy: 0.7739 - precision: 0.5595 - recall: 0.1288 - auc: 0.5190\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.7060 - accuracy: 0.5521 - binary_crossentropy: 0.7060 - precision: 0.7053 - recall: 0.2000 - auc: 0.6344\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.6522 - accuracy: 0.6042 - binary_crossentropy: 0.6522 - precision: 0.7817 - recall: 0.3041 - auc: 0.7329\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.6042 - accuracy: 0.6604 - binary_crossentropy: 0.6042 - precision: 0.8394 - recall: 0.4082 - auc: 0.8034\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.5622 - accuracy: 0.7069 - binary_crossentropy: 0.5622 - precision: 0.8632 - recall: 0.5014 - auc: 0.8646\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.5183 - accuracy: 0.7667 - binary_crossentropy: 0.5183 - precision: 0.9070 - recall: 0.6014 - auc: 0.9098\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.4921 - accuracy: 0.8188 - binary_crossentropy: 0.4921 - precision: 0.9303 - recall: 0.6945 - auc: 0.9332\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.4573 - accuracy: 0.8535 - binary_crossentropy: 0.4573 - precision: 0.9451 - recall: 0.7548 - auc: 0.9550\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.4342 - accuracy: 0.8847 - binary_crossentropy: 0.4342 - precision: 0.9593 - recall: 0.8068 - auc: 0.9699\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.4097 - accuracy: 0.9069 - binary_crossentropy: 0.4097 - precision: 0.9529 - recall: 0.8589 - auc: 0.9790\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.3876 - accuracy: 0.9187 - binary_crossentropy: 0.3876 - precision: 0.9527 - recall: 0.8836 - auc: 0.9818\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.3700 - accuracy: 0.9319 - binary_crossentropy: 0.3700 - precision: 0.9675 - recall: 0.8959 - auc: 0.9856\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.3511 - accuracy: 0.9424 - binary_crossentropy: 0.3511 - precision: 0.9709 - recall: 0.9137 - auc: 0.9899\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.3382 - accuracy: 0.9500 - binary_crossentropy: 0.3382 - precision: 0.9754 - recall: 0.9247 - auc: 0.9944\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.3217 - accuracy: 0.9590 - binary_crossentropy: 0.3217 - precision: 0.9786 - recall: 0.9397 - auc: 0.9951\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.3109 - accuracy: 0.9646 - binary_crossentropy: 0.3109 - precision: 0.9722 - recall: 0.9575 - auc: 0.9946\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.2965 - accuracy: 0.9729 - binary_crossentropy: 0.2965 - precision: 0.9805 - recall: 0.9658 - auc: 0.9969\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.2830 - accuracy: 0.9715 - binary_crossentropy: 0.2830 - precision: 0.9805 - recall: 0.9630 - auc: 0.9975\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.2710 - accuracy: 0.9785 - binary_crossentropy: 0.2710 - precision: 0.9861 - recall: 0.9712 - auc: 0.9980\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.2611 - accuracy: 0.9792 - binary_crossentropy: 0.2611 - precision: 0.9902 - recall: 0.9685 - auc: 0.9981\n",
      "Loss of Train ......................................\n",
      "[0.773865282535553, 0.7060074806213379, 0.6522250175476074, 0.6041982173919678, 0.5622446537017822, 0.5183250904083252, 0.49209311604499817, 0.45726045966148376, 0.4342137277126312, 0.40972742438316345, 0.3875788450241089, 0.3699970543384552, 0.35110923647880554, 0.3381636440753937, 0.32165956497192383, 0.3108702003955841, 0.29645225405693054, 0.28295961022377014, 0.27096885442733765, 0.26114436984062195]\n",
      "Accuracy of Train ......................................\n",
      "[0.5069444179534912, 0.5520833134651184, 0.6041666865348816, 0.6604166626930237, 0.706944465637207, 0.7666666507720947, 0.8187500238418579, 0.8534722328186035, 0.8847222328186035, 0.9069444537162781, 0.918749988079071, 0.9319444298744202, 0.9423611164093018, 0.949999988079071, 0.9590277671813965, 0.9645833373069763, 0.9729166626930237, 0.9715277552604675, 0.9784722328186035, 0.9791666865348816]\n",
      "Precision of Train ......................................\n",
      "[0.5595238208770752, 0.7053139805793762, 0.7816901206970215, 0.8394365906715393, 0.8632075190544128, 0.9070248007774353, 0.9302752017974854, 0.9451115131378174, 0.9592834115028381, 0.9528875350952148, 0.9527326226234436, 0.9674556255340576, 0.9708878993988037, 0.9754335284233093, 0.9786019921302795, 0.9721835851669312, 0.9805285334587097, 0.9804741740226746, 0.9860917925834656, 0.9901960492134094]\n",
      "Recall of Train ......................................\n",
      "[0.12876711785793304, 0.20000000298023224, 0.3041096031665802, 0.40821918845176697, 0.501369833946228, 0.6013698577880859, 0.6945205330848694, 0.7547945380210876, 0.8068493008613586, 0.8589041233062744, 0.8835616707801819, 0.8958904147148132, 0.9136986136436462, 0.9246575236320496, 0.9397260546684265, 0.9575342535972595, 0.965753436088562, 0.9630137085914612, 0.9712328910827637, 0.9684931635856628]\n",
      "AUC of Train ......................................\n",
      "[0.5189707279205322, 0.6343710422515869, 0.7329278588294983, 0.8033542633056641, 0.8646478652954102, 0.9097607135772705, 0.9331651329994202, 0.9549652338027954, 0.9698958396911621, 0.9789523482322693, 0.9817682504653931, 0.9856395721435547, 0.9899179935455322, 0.9944115281105042, 0.9950993657112122, 0.9946362972259521, 0.9969081878662109, 0.9975072741508484, 0.9980050325393677, 0.9980870485305786]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8414930552244186\n",
      " Loss:0.44005320519208907\n",
      " Precision:0.9099170148372651\n",
      " Recall:0.7321232914924621\n",
      " AUC:0.9116495788097382\n",
      "Score for fold 2: loss of 0.27203047275543213; accuracy of 0.9750000238418579%\n",
      "[[186   4]\n",
      " [  5 165]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 849.1974054 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:186,FN:5,TP:165,FP:4\n",
      "Test of epochs .................................\n",
      " Accuracy:0.975\n",
      " Loss:0.27203047275543213\n",
      " Precision:0.9763313609467456\n",
      " Recall:0.9705882352941176\n",
      " AUC:0.9722051124114568\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 29s 435ms/step - loss: 0.7710 - accuracy: 0.4576 - binary_crossentropy: 0.7710 - precision: 0.4522 - recall: 0.4075 - auc: 0.4241\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.7105 - accuracy: 0.5250 - binary_crossentropy: 0.7105 - precision: 0.5273 - recall: 0.4701 - auc: 0.5404\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.6594 - accuracy: 0.6132 - binary_crossentropy: 0.6594 - precision: 0.6319 - recall: 0.5396 - auc: 0.6473\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.6170 - accuracy: 0.6840 - binary_crossentropy: 0.6170 - precision: 0.7136 - recall: 0.6134 - auc: 0.7346\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.5708 - accuracy: 0.7382 - binary_crossentropy: 0.5708 - precision: 0.7714 - recall: 0.6759 - auc: 0.8225\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.5317 - accuracy: 0.7875 - binary_crossentropy: 0.5317 - precision: 0.8293 - recall: 0.7232 - auc: 0.8819\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.4969 - accuracy: 0.8333 - binary_crossentropy: 0.4969 - precision: 0.8713 - recall: 0.7816 - auc: 0.9154\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.4641 - accuracy: 0.8694 - binary_crossentropy: 0.4641 - precision: 0.8933 - recall: 0.8387 - auc: 0.9460\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.4381 - accuracy: 0.8972 - binary_crossentropy: 0.4381 - precision: 0.9192 - recall: 0.8707 - auc: 0.9635\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.4149 - accuracy: 0.9083 - binary_crossentropy: 0.4149 - precision: 0.9323 - recall: 0.8804 - auc: 0.9745\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.3950 - accuracy: 0.9243 - binary_crossentropy: 0.3950 - precision: 0.9433 - recall: 0.9026 - auc: 0.9796\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.3784 - accuracy: 0.9271 - binary_crossentropy: 0.3784 - precision: 0.9462 - recall: 0.9054 - auc: 0.9819\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.3548 - accuracy: 0.9493 - binary_crossentropy: 0.3548 - precision: 0.9614 - recall: 0.9360 - auc: 0.9889\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.3459 - accuracy: 0.9549 - binary_crossentropy: 0.3459 - precision: 0.9739 - recall: 0.9346 - auc: 0.9913\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.3298 - accuracy: 0.9618 - binary_crossentropy: 0.3298 - precision: 0.9729 - recall: 0.9499 - auc: 0.9939\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.3095 - accuracy: 0.9688 - binary_crossentropy: 0.3095 - precision: 0.9760 - recall: 0.9611 - auc: 0.9967\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.2947 - accuracy: 0.9764 - binary_crossentropy: 0.2947 - precision: 0.9886 - recall: 0.9638 - auc: 0.9978\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.2862 - accuracy: 0.9757 - binary_crossentropy: 0.2862 - precision: 0.9858 - recall: 0.9652 - auc: 0.9977\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.2728 - accuracy: 0.9812 - binary_crossentropy: 0.2728 - precision: 0.9915 - recall: 0.9708 - auc: 0.9989\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.2631 - accuracy: 0.9792 - binary_crossentropy: 0.2631 - precision: 0.9832 - recall: 0.9750 - auc: 0.9984\n",
      "Loss of Train ......................................\n",
      "[0.7710440158843994, 0.7104686498641968, 0.6593923568725586, 0.6169923543930054, 0.5708291530609131, 0.531745433807373, 0.496944397687912, 0.4641099274158478, 0.4380638599395752, 0.4149220287799835, 0.39499595761299133, 0.3784172534942627, 0.35482361912727356, 0.34585216641426086, 0.3298164904117584, 0.30954840779304504, 0.2947257459163666, 0.2862456738948822, 0.2728256583213806, 0.2630979120731354]\n",
      "Accuracy of Train ......................................\n",
      "[0.4576388895511627, 0.5249999761581421, 0.613194465637207, 0.6840277910232544, 0.738194465637207, 0.7875000238418579, 0.8333333134651184, 0.8694444298744202, 0.8972222208976746, 0.9083333611488342, 0.9243055582046509, 0.9270833134651184, 0.949305534362793, 0.9548611044883728, 0.9618055820465088, 0.96875, 0.9763888716697693, 0.9756944179534912, 0.981249988079071, 0.9791666865348816]\n",
      "Precision of Train ......................................\n",
      "[0.452160507440567, 0.5273010730743408, 0.6319218277931213, 0.7135922312736511, 0.7714285850524902, 0.8293461203575134, 0.8713178038597107, 0.8933333158493042, 0.919236421585083, 0.9322533011436462, 0.9433139562606812, 0.9462209343910217, 0.9614285826683044, 0.9739130139350891, 0.9729344844818115, 0.9759886860847473, 0.9885877370834351, 0.9857954382896423, 0.9914772510528564, 0.9831697344779968]\n",
      "Recall of Train ......................................\n",
      "[0.4075104296207428, 0.4700973629951477, 0.5396384000778198, 0.6133518815040588, 0.6759387850761414, 0.7232267260551453, 0.7816411852836609, 0.8386648297309875, 0.8706536889076233, 0.8803894519805908, 0.902642548084259, 0.905424177646637, 0.9360222816467285, 0.9346314072608948, 0.9499304294586182, 0.9610570073127747, 0.9638386368751526, 0.9652295112609863, 0.9707927703857422, 0.9749652147293091]\n",
      "AUC of Train ......................................\n",
      "[0.4241096079349518, 0.5403887033462524, 0.647343099117279, 0.7346300482749939, 0.8224919438362122, 0.8818843960762024, 0.9154464602470398, 0.9459769129753113, 0.9634845852851868, 0.9744656085968018, 0.9796479344367981, 0.9818826913833618, 0.9889004230499268, 0.9913145899772644, 0.9938782453536987, 0.9966840147972107, 0.9977922439575195, 0.9976919293403625, 0.9988753795623779, 0.9983545541763306]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8456249997019768\n",
      " Loss:0.4452430531382561\n",
      " Precision:0.8632360503077507\n",
      " Recall:0.8132823362946511\n",
      " AUC:0.8887621685862541\n",
      "Score for fold 3: loss of 0.28539615869522095; accuracy of 0.9611111283302307%\n",
      "[[177   2]\n",
      " [ 12 169]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1245.8920454000001 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:177,FN:12,TP:169,FP:2\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9611111111111111\n",
      " Loss:0.28539615869522095\n",
      " Precision:0.9883040935672515\n",
      " Recall:0.9337016574585635\n",
      " AUC:0.93510479698325\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 25s 412ms/step - loss: 0.7621 - accuracy: 0.4597 - binary_crossentropy: 0.7621 - precision: 0.4421 - recall: 0.3478 - auc: 0.4453\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.7070 - accuracy: 0.5236 - binary_crossentropy: 0.7070 - precision: 0.5247 - recall: 0.4025 - auc: 0.5471\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.6548 - accuracy: 0.5979 - binary_crossentropy: 0.6548 - precision: 0.6232 - recall: 0.4755 - auc: 0.6528\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.5968 - accuracy: 0.6840 - binary_crossentropy: 0.5968 - precision: 0.7295 - recall: 0.5750 - auc: 0.7648\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 431ms/step - loss: 0.5574 - accuracy: 0.7417 - binary_crossentropy: 0.5574 - precision: 0.7986 - recall: 0.6396 - auc: 0.8315\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.5206 - accuracy: 0.7993 - binary_crossentropy: 0.5206 - precision: 0.8510 - recall: 0.7209 - auc: 0.8823\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.4884 - accuracy: 0.8347 - binary_crossentropy: 0.4884 - precision: 0.8764 - recall: 0.7756 - auc: 0.9189\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.4568 - accuracy: 0.8639 - binary_crossentropy: 0.4568 - precision: 0.9008 - recall: 0.8149 - auc: 0.9466\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.4343 - accuracy: 0.8889 - binary_crossentropy: 0.4343 - precision: 0.9247 - recall: 0.8443 - auc: 0.9599\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.4131 - accuracy: 0.9021 - binary_crossentropy: 0.4131 - precision: 0.9281 - recall: 0.8696 - auc: 0.9694\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.3861 - accuracy: 0.9174 - binary_crossentropy: 0.3861 - precision: 0.9420 - recall: 0.8878 - auc: 0.9805\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.3633 - accuracy: 0.9382 - binary_crossentropy: 0.3633 - precision: 0.9535 - recall: 0.9201 - auc: 0.9870\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.3549 - accuracy: 0.9382 - binary_crossentropy: 0.3549 - precision: 0.9548 - recall: 0.9187 - auc: 0.9851\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.3297 - accuracy: 0.9542 - binary_crossentropy: 0.3297 - precision: 0.9682 - recall: 0.9383 - auc: 0.9925\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.3208 - accuracy: 0.9507 - binary_crossentropy: 0.3208 - precision: 0.9652 - recall: 0.9341 - auc: 0.9923\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.3028 - accuracy: 0.9681 - binary_crossentropy: 0.3028 - precision: 0.9691 - recall: 0.9663 - auc: 0.9946\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2882 - accuracy: 0.9688 - binary_crossentropy: 0.2882 - precision: 0.9758 - recall: 0.9607 - auc: 0.9958\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.2787 - accuracy: 0.9757 - binary_crossentropy: 0.2787 - precision: 0.9829 - recall: 0.9677 - auc: 0.9954\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.2690 - accuracy: 0.9750 - binary_crossentropy: 0.2690 - precision: 0.9774 - recall: 0.9719 - auc: 0.9954\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.2581 - accuracy: 0.9715 - binary_crossentropy: 0.2581 - precision: 0.9828 - recall: 0.9593 - auc: 0.9964\n",
      "Loss of Train ......................................\n",
      "[0.7620853781700134, 0.7069936990737915, 0.6548379063606262, 0.5968040227890015, 0.5573540925979614, 0.5205729603767395, 0.4884127676486969, 0.45683753490448, 0.43432509899139404, 0.41305088996887207, 0.3861018419265747, 0.3633407950401306, 0.3549259305000305, 0.329654723405838, 0.3207853436470032, 0.30275994539260864, 0.2881527245044708, 0.27872511744499207, 0.2690490186214447, 0.25809866189956665]\n",
      "Accuracy of Train ......................................\n",
      "[0.45972222089767456, 0.5236111283302307, 0.5979166626930237, 0.6840277910232544, 0.7416666746139526, 0.7993055582046509, 0.8347222208976746, 0.8638888597488403, 0.8888888955116272, 0.9020833373069763, 0.9173611402511597, 0.9381944537162781, 0.9381944537162781, 0.9541666507720947, 0.9506944417953491, 0.9680555462837219, 0.96875, 0.9756944179534912, 0.9750000238418579, 0.9715277552604675]\n",
      "Precision of Train ......................................\n",
      "[0.4420677423477173, 0.5246800780296326, 0.623161792755127, 0.7295373678207397, 0.7985989451408386, 0.8509933948516846, 0.8763867020606995, 0.9007751941680908, 0.9247311949729919, 0.9281437397003174, 0.9419642686843872, 0.9534883499145508, 0.9548105001449585, 0.9681620597839355, 0.9652174115180969, 0.9690576791763306, 0.9757834672927856, 0.9829059839248657, 0.9774330258369446, 0.982758641242981]\n",
      "Recall of Train ......................................\n",
      "[0.3478260934352875, 0.40252453088760376, 0.4754558205604553, 0.575035035610199, 0.6395511627197266, 0.7208976149559021, 0.7755960822105408, 0.8148667812347412, 0.844319760799408, 0.8695651888847351, 0.887798011302948, 0.9200561046600342, 0.9186535477638245, 0.9382889270782471, 0.9340813755989075, 0.9663394093513489, 0.9607293009757996, 0.9677419066429138, 0.9719495177268982, 0.9593268036842346]\n",
      "AUC of Train ......................................\n",
      "[0.4452812671661377, 0.5470907092094421, 0.6528192162513733, 0.7647597789764404, 0.8314520716667175, 0.8822631239891052, 0.9188523292541504, 0.9466037750244141, 0.9598563313484192, 0.9694213271141052, 0.9804794788360596, 0.987026035785675, 0.9851065874099731, 0.9925002455711365, 0.9923015236854553, 0.9945876598358154, 0.9958463907241821, 0.9954336285591125, 0.9954288005828857, 0.9964136481285095]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8426736116409301\n",
      " Loss:0.4371434226632118\n",
      " Precision:0.8635328769683838\n",
      " Recall:0.7945301488041878\n",
      " AUC:0.8916761964559555\n",
      "Score for fold 4: loss of 0.2702736258506775; accuracy of 0.9611111283302307%\n",
      "[[169   4]\n",
      " [ 10 177]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1645.6813379 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:169,FN:10,TP:177,FP:4\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9611111111111111\n",
      " Loss:0.2702736258506775\n",
      " Precision:0.9779005524861878\n",
      " Recall:0.946524064171123\n",
      " AUC:0.9453290711917067\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 31s 454ms/step - loss: 0.6656 - accuracy: 0.6021 - binary_crossentropy: 0.6656 - precision: 0.6050 - recall: 0.5720 - auc: 0.6366\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.6188 - accuracy: 0.6667 - binary_crossentropy: 0.6188 - precision: 0.6783 - recall: 0.6252 - auc: 0.7312\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.5844 - accuracy: 0.7264 - binary_crossentropy: 0.5844 - precision: 0.7364 - recall: 0.6993 - auc: 0.7915\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.5456 - accuracy: 0.7778 - binary_crossentropy: 0.5456 - precision: 0.7979 - recall: 0.7399 - auc: 0.8511\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.5108 - accuracy: 0.8076 - binary_crossentropy: 0.5108 - precision: 0.8230 - recall: 0.7804 - auc: 0.8955\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.4803 - accuracy: 0.8507 - binary_crossentropy: 0.4803 - precision: 0.8644 - recall: 0.8294 - auc: 0.9291\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.4569 - accuracy: 0.8687 - binary_crossentropy: 0.4569 - precision: 0.8768 - recall: 0.8559 - auc: 0.9415\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.4293 - accuracy: 0.8931 - binary_crossentropy: 0.4293 - precision: 0.9059 - recall: 0.8755 - auc: 0.9613\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 21s 476ms/step - loss: 0.4027 - accuracy: 0.9097 - binary_crossentropy: 0.4027 - precision: 0.9258 - recall: 0.8895 - auc: 0.9735\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.3861 - accuracy: 0.9215 - binary_crossentropy: 0.3861 - precision: 0.9312 - recall: 0.9091 - auc: 0.9807\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.3706 - accuracy: 0.9361 - binary_crossentropy: 0.3706 - precision: 0.9456 - recall: 0.9245 - auc: 0.9830\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.3498 - accuracy: 0.9514 - binary_crossentropy: 0.3498 - precision: 0.9667 - recall: 0.9343 - auc: 0.9889\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.3371 - accuracy: 0.9486 - binary_crossentropy: 0.3371 - precision: 0.9625 - recall: 0.9329 - auc: 0.9894\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.3169 - accuracy: 0.9625 - binary_crossentropy: 0.3169 - precision: 0.9688 - recall: 0.9552 - auc: 0.9933\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.3109 - accuracy: 0.9590 - binary_crossentropy: 0.3109 - precision: 0.9633 - recall: 0.9538 - auc: 0.9935\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.2955 - accuracy: 0.9646 - binary_crossentropy: 0.2955 - precision: 0.9663 - recall: 0.9622 - auc: 0.9949\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.2802 - accuracy: 0.9743 - binary_crossentropy: 0.2802 - precision: 0.9815 - recall: 0.9664 - auc: 0.9967\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.2738 - accuracy: 0.9736 - binary_crossentropy: 0.2738 - precision: 0.9788 - recall: 0.9678 - auc: 0.9969\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.2608 - accuracy: 0.9778 - binary_crossentropy: 0.2608 - precision: 0.9858 - recall: 0.9692 - auc: 0.9976\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.2485 - accuracy: 0.9806 - binary_crossentropy: 0.2485 - precision: 0.9886 - recall: 0.9720 - auc: 0.9982\n",
      "Loss of Train ......................................\n",
      "[0.6656355857849121, 0.6187998652458191, 0.5843585729598999, 0.5456454157829285, 0.5108104944229126, 0.4802684783935547, 0.4568537473678589, 0.4293452501296997, 0.40266790986061096, 0.3861209750175476, 0.37062063813209534, 0.34976306557655334, 0.3371334671974182, 0.316871702671051, 0.3109474778175354, 0.2955145537853241, 0.2801887094974518, 0.27377763390541077, 0.2607940137386322, 0.2485375702381134]\n",
      "Accuracy of Train ......................................\n",
      "[0.6020833253860474, 0.6666666865348816, 0.7263888716697693, 0.7777777910232544, 0.8076388835906982, 0.8506944179534912, 0.8687499761581421, 0.8930555582046509, 0.9097222089767456, 0.9215278029441833, 0.9361110925674438, 0.9513888955116272, 0.9486111402511597, 0.9624999761581421, 0.9590277671813965, 0.9645833373069763, 0.9743055701255798, 0.9736111164093018, 0.9777777791023254, 0.980555534362793]\n",
      "Precision of Train ......................................\n",
      "[0.6050295829772949, 0.6783004403114319, 0.7363770008087158, 0.7978883981704712, 0.8230088353157043, 0.8644315004348755, 0.8767908215522766, 0.9059334397315979, 0.9257642030715942, 0.9312320947647095, 0.9456366300582886, 0.9667149186134338, 0.9624819755554199, 0.9687943458557129, 0.9632768630981445, 0.966292142868042, 0.9815340638160706, 0.9787836074829102, 0.9857752323150635, 0.9886202216148376]\n",
      "Recall of Train ......................................\n",
      "[0.5720279812812805, 0.6251748204231262, 0.6993007063865662, 0.7398601174354553, 0.7804195880889893, 0.8293706178665161, 0.855944037437439, 0.8755244612693787, 0.8895105123519897, 0.9090909361839294, 0.9244755506515503, 0.9342657327651978, 0.9328671097755432, 0.955244779586792, 0.9538461565971375, 0.9622377753257751, 0.966433584690094, 0.9678321480751038, 0.9692307710647583, 0.9720279574394226]\n",
      "AUC of Train ......................................\n",
      "[0.6365894079208374, 0.7312380075454712, 0.7915118932723999, 0.8511483073234558, 0.8955109715461731, 0.9290803670883179, 0.9414651393890381, 0.9612568616867065, 0.9735037684440613, 0.9806703925132751, 0.9830065369606018, 0.9888815879821777, 0.9893639087677002, 0.993295431137085, 0.993511438369751, 0.9949012994766235, 0.9966790080070496, 0.9968768358230591, 0.9975712299346924, 0.9981635212898254]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8826388865709305\n",
      " Loss:0.4062327563762665\n",
      " Precision:0.8926333159208297\n",
      " Recall:0.8657342672348023\n",
      " AUC:0.9312112957239151\n",
      "Score for fold 5: loss of 0.26625901460647583; accuracy of 0.9611111283302307%\n",
      "[[172   3]\n",
      " [ 11 174]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 2081.6351258 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:172,FN:11,TP:174,FP:3\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9611111111111111\n",
      " Loss:0.26625901460647583\n",
      " Precision:0.9830508474576272\n",
      " Recall:0.9405405405405406\n",
      " AUC:0.9402156254615271\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.8557986080646515 - Loss: 0.4122546061873436\n",
      "> Fold 1 - Precision: 0.9234360516071319\n",
      "> Fold 1 - Recall: 0.7576071999967098\n",
      "> Fold 1 - AUC: 0.93062644302845\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9638888888888889 - Loss: 0.27646133303642273\n",
      "> Fold 1 - Precision: 0.9659090909090909\n",
      "> Fold 1 - Recall: 0.96045197740113\n",
      "> Fold 1 - AUC: 0.9612042495701303\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8414930552244186 - Loss: 0.44005320519208907\n",
      "> Fold 2 - Precision: 0.9099170148372651\n",
      "> Fold 2 - Recall: 0.7321232914924621\n",
      "> Fold 2 - AUC: 0.9116495788097382\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.975 - Loss: 0.27203047275543213\n",
      "> Fold 2 - Precision: 0.9763313609467456\n",
      "> Fold 2 - Recall: 0.9705882352941176\n",
      "> Fold 2 - AUC: 0.9722051124114568\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.8456249997019768 - Loss: 0.4452430531382561\n",
      "> Fold 3 - Precision: 0.8632360503077507\n",
      "> Fold 3 - Recall: 0.8132823362946511\n",
      "> Fold 3 - AUC: 0.8887621685862541\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9611111111111111 - Loss: 0.28539615869522095\n",
      "> Fold 3 - Precision: 0.9883040935672515\n",
      "> Fold 3 - Recall: 0.9337016574585635\n",
      "> Fold 3 - AUC: 0.93510479698325\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.8426736116409301 - Loss: 0.4371434226632118\n",
      "> Fold 4 - Precision: 0.8635328769683838\n",
      "> Fold 4 - Recall: 0.7945301488041878\n",
      "> Fold 4 - AUC: 0.8916761964559555\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9611111111111111 - Loss: 0.2702736258506775\n",
      "> Fold 4 - Precision: 0.9779005524861878\n",
      "> Fold 4 - Recall: 0.946524064171123\n",
      "> Fold 4 - AUC: 0.9453290711917067\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.8826388865709305 - Loss: 0.4062327563762665\n",
      "> Fold 5 - Precision: 0.8926333159208297\n",
      "> Fold 5 - Recall: 0.8657342672348023\n",
      "> Fold 5 - AUC: 0.9312112957239151\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9611111111111111 - Loss: 0.26625901460647583\n",
      "> Fold 5 - Precision: 0.9830508474576272\n",
      "> Fold 5 - Recall: 0.9405405405405406\n",
      "> Fold 5 - AUC: 0.9402156254615271\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.8536458322405815 (+- 0.015346954172444758)\n",
      "> Loss: 0.42818540871143346 (+- 0.0157972355446685)\n",
      "> Precision: 0.8905510619282723 (+- 0.024235885122262508)\n",
      "> Recall: 0.7926554487645625 (+- 0.04617795687150166)\n",
      "> AUC: 0.9107851365208626 (+- 0.018230827689604653)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9644444444444444 (+- 0.005386310952684791)\n",
      "> Loss: 0.2740841209888458 (+- 0.0065357932701335135)\n",
      "> Precision: 0.9782991890733805 (+- 0.007486282956413241)\n",
      "> Recall: 0.9503612949730949 (+- 0.013413918641332151)\n",
      "> AUC: 0.9508117711236143 (+- 0.013818292208525528)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 881 FN SUM: 45 TP SUM: 855 FP SUM: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(ResNet152V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a67fc7",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e51d917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 23s 348ms/step - loss: 0.7153 - accuracy: 0.3979 - binary_crossentropy: 0.7153 - precision: 0.3952 - recall: 0.3664 - auc: 0.3832\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.7100 - accuracy: 0.4313 - binary_crossentropy: 0.7100 - precision: 0.4327 - recall: 0.4118 - auc: 0.4152\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 15s 344ms/step - loss: 0.7087 - accuracy: 0.4313 - binary_crossentropy: 0.7087 - precision: 0.4299 - recall: 0.3926 - auc: 0.4241\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.7059 - accuracy: 0.4451 - binary_crossentropy: 0.7059 - precision: 0.4448 - recall: 0.4050 - auc: 0.4383\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.7009 - accuracy: 0.4646 - binary_crossentropy: 0.7009 - precision: 0.4670 - recall: 0.4380 - auc: 0.4679\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6968 - accuracy: 0.4868 - binary_crossentropy: 0.6968 - precision: 0.4903 - recall: 0.4545 - auc: 0.4955\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6928 - accuracy: 0.5125 - binary_crossentropy: 0.6928 - precision: 0.5178 - recall: 0.4821 - auc: 0.5266\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.6907 - accuracy: 0.5153 - binary_crossentropy: 0.6907 - precision: 0.5212 - recall: 0.4738 - auc: 0.5341\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.6869 - accuracy: 0.5201 - binary_crossentropy: 0.6869 - precision: 0.5264 - recall: 0.4807 - auc: 0.5544\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6831 - accuracy: 0.5562 - binary_crossentropy: 0.6831 - precision: 0.5666 - recall: 0.5096 - auc: 0.5868\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.6806 - accuracy: 0.5556 - binary_crossentropy: 0.6806 - precision: 0.5650 - recall: 0.5152 - auc: 0.5948\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6786 - accuracy: 0.5819 - binary_crossentropy: 0.6786 - precision: 0.5912 - recall: 0.5537 - auc: 0.6148\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6745 - accuracy: 0.5819 - binary_crossentropy: 0.6745 - precision: 0.5951 - recall: 0.5344 - auc: 0.6341\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6698 - accuracy: 0.6153 - binary_crossentropy: 0.6698 - precision: 0.6284 - recall: 0.5799 - auc: 0.6624\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.6671 - accuracy: 0.6243 - binary_crossentropy: 0.6671 - precision: 0.6425 - recall: 0.5744 - auc: 0.6736\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6649 - accuracy: 0.6340 - binary_crossentropy: 0.6649 - precision: 0.6487 - recall: 0.5978 - auc: 0.6874\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.6624 - accuracy: 0.6410 - binary_crossentropy: 0.6624 - precision: 0.6605 - recall: 0.5923 - auc: 0.6986\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.6616 - accuracy: 0.6507 - binary_crossentropy: 0.6616 - precision: 0.6708 - recall: 0.6033 - auc: 0.7049\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 16s 360ms/step - loss: 0.6540 - accuracy: 0.6708 - binary_crossentropy: 0.6540 - precision: 0.6933 - recall: 0.6226 - auc: 0.7483\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6518 - accuracy: 0.6785 - binary_crossentropy: 0.6518 - precision: 0.7032 - recall: 0.6267 - auc: 0.7586\n",
      "Loss of Train ......................................\n",
      "[0.71531742811203, 0.7100176215171814, 0.7087247967720032, 0.7059497833251953, 0.7008800506591797, 0.6967794895172119, 0.6928456425666809, 0.6906953454017639, 0.6869332790374756, 0.6830647587776184, 0.680583655834198, 0.6785919666290283, 0.6745087504386902, 0.6698163747787476, 0.6671228408813477, 0.6648918986320496, 0.6623634696006775, 0.6615527272224426, 0.6540082097053528, 0.6518110632896423]\n",
      "Accuracy of Train ......................................\n",
      "[0.39791667461395264, 0.4312500059604645, 0.4312500059604645, 0.4451389014720917, 0.4645833373069763, 0.4868055582046509, 0.512499988079071, 0.5152778029441833, 0.5201388597488403, 0.5562499761581421, 0.5555555820465088, 0.581944465637207, 0.581944465637207, 0.6152777671813965, 0.6243055462837219, 0.6340277791023254, 0.6409721970558167, 0.6506944298744202, 0.6708333492279053, 0.6784722208976746]\n",
      "Precision of Train ......................................\n",
      "[0.39524516463279724, 0.43270623683929443, 0.4298642575740814, 0.4447806477546692, 0.4669603407382965, 0.49034175276756287, 0.5177514553070068, 0.521212100982666, 0.5263952016830444, 0.566615641117096, 0.5649546980857849, 0.591176450252533, 0.5950919985771179, 0.6283581852912903, 0.6425269842147827, 0.6487294435501099, 0.6605222821235657, 0.6707503795623779, 0.6932515501976013, 0.7032457590103149]\n",
      "Recall of Train ......................................\n",
      "[0.3663911819458008, 0.41184574365615845, 0.39256197214126587, 0.40495866537094116, 0.43801653385162354, 0.4545454680919647, 0.4820936620235443, 0.4738292098045349, 0.4807162582874298, 0.5096418857574463, 0.5151515007019043, 0.5537189841270447, 0.5344352722167969, 0.5798898339271545, 0.5743801593780518, 0.5977961421012878, 0.5922865271568298, 0.6033057570457458, 0.6225895285606384, 0.6267217397689819]\n",
      "AUC of Train ......................................\n",
      "[0.3832114338874817, 0.41520920395851135, 0.4240871071815491, 0.4383367896080017, 0.46794626116752625, 0.4955272674560547, 0.5265604853630066, 0.5341362953186035, 0.5543681383132935, 0.5868115425109863, 0.5948213934898376, 0.6147736310958862, 0.6340698599815369, 0.6623579263687134, 0.6735711097717285, 0.6873847246170044, 0.6986036896705627, 0.704936146736145, 0.7482686042785645, 0.7585943341255188]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.549756945669651\n",
      " Loss:0.6828229576349258\n",
      " Precision:0.5595240265130996\n",
      " Recall:0.5107438012957572\n",
      " AUC:0.5801787972450256\n",
      "Score for fold 1: loss of 0.6625610589981079; accuracy of 0.6416666507720947%\n",
      "[[131  55]\n",
      " [ 74 100]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 340.1641183 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:131,FN:74,TP:100,FP:55\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6416666666666667\n",
      " Loss:0.6625610589981079\n",
      " Precision:0.6451612903225806\n",
      " Recall:0.5747126436781609\n",
      " AUC:0.6068685169610317\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 2049      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 19s 362ms/step - loss: 0.7233 - accuracy: 0.4833 - binary_crossentropy: 0.7233 - precision: 0.5123 - recall: 0.1110 - auc: 0.4674\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 351ms/step - loss: 0.7202 - accuracy: 0.4819 - binary_crossentropy: 0.7202 - precision: 0.5061 - recall: 0.1110 - auc: 0.4640\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.7140 - accuracy: 0.4826 - binary_crossentropy: 0.7140 - precision: 0.5090 - recall: 0.1136 - auc: 0.4966\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.7091 - accuracy: 0.5118 - binary_crossentropy: 0.7091 - precision: 0.6154 - recall: 0.1604 - auc: 0.5199\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.7055 - accuracy: 0.5063 - binary_crossentropy: 0.7055 - precision: 0.5894 - recall: 0.1631 - auc: 0.5284\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.7013 - accuracy: 0.5160 - binary_crossentropy: 0.7013 - precision: 0.6220 - recall: 0.1738 - auc: 0.5476\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6943 - accuracy: 0.5306 - binary_crossentropy: 0.6943 - precision: 0.6622 - recall: 0.1965 - auc: 0.5808\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.6920 - accuracy: 0.5340 - binary_crossentropy: 0.6920 - precision: 0.6638 - recall: 0.2086 - auc: 0.5926\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.6878 - accuracy: 0.5458 - binary_crossentropy: 0.6878 - precision: 0.6850 - recall: 0.2326 - auc: 0.6103\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6855 - accuracy: 0.5646 - binary_crossentropy: 0.6855 - precision: 0.7266 - recall: 0.2594 - auc: 0.6190\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.6799 - accuracy: 0.5743 - binary_crossentropy: 0.6799 - precision: 0.7336 - recall: 0.2834 - auc: 0.6463\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6780 - accuracy: 0.5813 - binary_crossentropy: 0.6780 - precision: 0.7441 - recall: 0.2955 - auc: 0.6535\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.6722 - accuracy: 0.5931 - binary_crossentropy: 0.6722 - precision: 0.7563 - recall: 0.3195 - auc: 0.6838\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6719 - accuracy: 0.5951 - binary_crossentropy: 0.6719 - precision: 0.7636 - recall: 0.3195 - auc: 0.6851\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6669 - accuracy: 0.6090 - binary_crossentropy: 0.6669 - precision: 0.7548 - recall: 0.3663 - auc: 0.7024\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.6614 - accuracy: 0.6333 - binary_crossentropy: 0.6614 - precision: 0.7989 - recall: 0.3930 - auc: 0.7304\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 16s 350ms/step - loss: 0.6587 - accuracy: 0.6500 - binary_crossentropy: 0.6587 - precision: 0.8280 - recall: 0.4118 - auc: 0.7418\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 16s 350ms/step - loss: 0.6553 - accuracy: 0.6417 - binary_crossentropy: 0.6553 - precision: 0.8021 - recall: 0.4118 - auc: 0.7558\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 16s 351ms/step - loss: 0.6505 - accuracy: 0.6639 - binary_crossentropy: 0.6505 - precision: 0.8333 - recall: 0.4412 - auc: 0.7847\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 16s 350ms/step - loss: 0.6484 - accuracy: 0.6785 - binary_crossentropy: 0.6484 - precision: 0.8536 - recall: 0.4599 - auc: 0.7834\n",
      "Loss of Train ......................................\n",
      "[0.7233218550682068, 0.7202011346817017, 0.7140165567398071, 0.709073007106781, 0.7054736018180847, 0.7012556195259094, 0.6943098902702332, 0.6919612288475037, 0.6877685785293579, 0.6855451464653015, 0.679939866065979, 0.678034782409668, 0.6721559166908264, 0.6719318628311157, 0.6669434905052185, 0.661364734172821, 0.6586594581604004, 0.6553239822387695, 0.6504514217376709, 0.6484304070472717]\n",
      "Accuracy of Train ......................................\n",
      "[0.4833333194255829, 0.4819444417953491, 0.4826388955116272, 0.511805534362793, 0.5062500238418579, 0.5159721970558167, 0.5305555462837219, 0.5340277552604675, 0.5458333492279053, 0.5645833611488342, 0.574305534362793, 0.581250011920929, 0.5930555462837219, 0.5951389074325562, 0.6090278029441833, 0.6333333253860474, 0.6499999761581421, 0.6416666507720947, 0.6638888716697693, 0.6784722208976746]\n",
      "Precision of Train ......................................\n",
      "[0.5123456716537476, 0.5060975551605225, 0.5089820623397827, 0.6153846383094788, 0.5893719792366028, 0.6220095753669739, 0.662162184715271, 0.6638298034667969, 0.6850393414497375, 0.7265917658805847, 0.733564019203186, 0.744107723236084, 0.7563291192054749, 0.7635782957077026, 0.7548209428787231, 0.7989130616188049, 0.8279569745063782, 0.8020833134651184, 0.8333333134651184, 0.8535979986190796]\n",
      "Recall of Train ......................................\n",
      "[0.11096256971359253, 0.11096256971359253, 0.11363636702299118, 0.16042780876159668, 0.16310159862041473, 0.17379678785800934, 0.19652406871318817, 0.2085561454296112, 0.23262031376361847, 0.259358286857605, 0.28342247009277344, 0.2954545319080353, 0.31951871514320374, 0.31951871514320374, 0.36631014943122864, 0.39304813742637634, 0.4117647111415863, 0.4117647111415863, 0.44117647409439087, 0.45989304780960083]\n",
      "AUC of Train ......................................\n",
      "[0.4673735201358795, 0.46401578187942505, 0.4966200888156891, 0.5198718905448914, 0.5284361243247986, 0.5475903153419495, 0.580784797668457, 0.5925898551940918, 0.6103182435035706, 0.6190111041069031, 0.6463237404823303, 0.6535143852233887, 0.6838486790657043, 0.6851112246513367, 0.7024309635162354, 0.730408251285553, 0.7418124675750732, 0.7558334469795227, 0.7846869230270386, 0.7833771109580994]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.5688541635870934\n",
      " Loss:0.6838081270456314\n",
      " Precision:0.6980049669742584\n",
      " Recall:0.27159090898931026\n",
      " AUC:0.6296979457139968\n",
      "Score for fold 2: loss of 0.6348063945770264; accuracy of 0.7277777791023254%\n",
      "[[187  21]\n",
      " [ 77  75]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 667.3155131999999 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:187,FN:77,TP:75,FP:21\n",
      "Test of epochs .................................\n",
      " Accuracy:0.7277777777777777\n",
      " Loss:0.6348063945770264\n",
      " Precision:0.78125\n",
      " Recall:0.4934210526315789\n",
      " AUC:0.6008771929824561\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 19s 349ms/step - loss: 0.7084 - accuracy: 0.4451 - binary_crossentropy: 0.7084 - precision: 0.4652 - recall: 0.7535 - auc: 0.4547\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 352ms/step - loss: 0.7049 - accuracy: 0.4521 - binary_crossentropy: 0.7049 - precision: 0.4692 - recall: 0.7521 - auc: 0.4658\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 16s 350ms/step - loss: 0.7011 - accuracy: 0.4708 - binary_crossentropy: 0.7011 - precision: 0.4805 - recall: 0.7563 - auc: 0.4848\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 16s 351ms/step - loss: 0.6981 - accuracy: 0.4750 - binary_crossentropy: 0.6981 - precision: 0.4830 - recall: 0.7507 - auc: 0.5050\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.6967 - accuracy: 0.4875 - binary_crossentropy: 0.6967 - precision: 0.4908 - recall: 0.7396 - auc: 0.5177\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 16s 351ms/step - loss: 0.6900 - accuracy: 0.5028 - binary_crossentropy: 0.6900 - precision: 0.5009 - recall: 0.7604 - auc: 0.5521\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 16s 351ms/step - loss: 0.6879 - accuracy: 0.5229 - binary_crossentropy: 0.6879 - precision: 0.5146 - recall: 0.7632 - auc: 0.5617\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6839 - accuracy: 0.5458 - binary_crossentropy: 0.6839 - precision: 0.5310 - recall: 0.7632 - auc: 0.5828\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6815 - accuracy: 0.5528 - binary_crossentropy: 0.6815 - precision: 0.5358 - recall: 0.7716 - auc: 0.6017\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.6788 - accuracy: 0.5542 - binary_crossentropy: 0.6788 - precision: 0.5380 - recall: 0.7493 - auc: 0.6070\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.6726 - accuracy: 0.5715 - binary_crossentropy: 0.6726 - precision: 0.5516 - recall: 0.7521 - auc: 0.6449\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 16s 351ms/step - loss: 0.6706 - accuracy: 0.5792 - binary_crossentropy: 0.6706 - precision: 0.5568 - recall: 0.7646 - auc: 0.6533\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.6669 - accuracy: 0.6000 - binary_crossentropy: 0.6669 - precision: 0.5737 - recall: 0.7702 - auc: 0.6793\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6641 - accuracy: 0.6076 - binary_crossentropy: 0.6641 - precision: 0.5818 - recall: 0.7577 - auc: 0.6892\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6599 - accuracy: 0.6271 - binary_crossentropy: 0.6599 - precision: 0.5974 - recall: 0.7730 - auc: 0.7088\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6615 - accuracy: 0.6313 - binary_crossentropy: 0.6615 - precision: 0.6035 - recall: 0.7591 - auc: 0.7039\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6553 - accuracy: 0.6549 - binary_crossentropy: 0.6553 - precision: 0.6205 - recall: 0.7925 - auc: 0.7396\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6515 - accuracy: 0.6681 - binary_crossentropy: 0.6515 - precision: 0.6367 - recall: 0.7786 - auc: 0.7518\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6490 - accuracy: 0.6604 - binary_crossentropy: 0.6490 - precision: 0.6291 - recall: 0.7772 - auc: 0.7630\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6454 - accuracy: 0.6986 - binary_crossentropy: 0.6454 - precision: 0.6644 - recall: 0.7994 - auc: 0.7744\n",
      "Loss of Train ......................................\n",
      "[0.7083588242530823, 0.7048599720001221, 0.7011283040046692, 0.6981334090232849, 0.6966724991798401, 0.6900469660758972, 0.6879463791847229, 0.6838781833648682, 0.6814826726913452, 0.6788329482078552, 0.6725679039955139, 0.6706481575965881, 0.6669235825538635, 0.6640859842300415, 0.6599350571632385, 0.6614598631858826, 0.6552764177322388, 0.6515346169471741, 0.6489516496658325, 0.645425021648407]\n",
      "Accuracy of Train ......................................\n",
      "[0.4451389014720917, 0.4520833194255829, 0.47083333134651184, 0.4749999940395355, 0.48750001192092896, 0.5027777552604675, 0.5229166746139526, 0.5458333492279053, 0.5527777671813965, 0.5541666746139526, 0.5715277791023254, 0.5791666507720947, 0.6000000238418579, 0.6076388955116272, 0.6270833611488342, 0.6312500238418579, 0.6548610925674438, 0.668055534362793, 0.6604166626930237, 0.6986111402511597]\n",
      "Precision of Train ......................................\n",
      "[0.4651762545108795, 0.46915724873542786, 0.4805309772491455, 0.48297491669654846, 0.49075785279273987, 0.5009174346923828, 0.514553964138031, 0.5310077667236328, 0.5357833504676819, 0.5379999876022339, 0.5515832304954529, 0.5567951202392578, 0.5736514329910278, 0.581818163394928, 0.5974165797233582, 0.603543758392334, 0.6205016374588013, 0.6366742849349976, 0.6290867924690247, 0.6643518805503845]\n",
      "Recall of Train ......................................\n",
      "[0.7534818649291992, 0.7520891427993774, 0.7562674283981323, 0.7506963610649109, 0.7395543456077576, 0.7604456543922424, 0.7632312178611755, 0.7632312178611755, 0.7715877294540405, 0.7493036389350891, 0.7520891427993774, 0.7646239399909973, 0.7701950073242188, 0.7576601505279541, 0.7729805111885071, 0.7590529322624207, 0.7924790978431702, 0.7785515189170837, 0.777158796787262, 0.7994428873062134]\n",
      "AUC of Train ......................................\n",
      "[0.4546833038330078, 0.4658243656158447, 0.4848252832889557, 0.5050463676452637, 0.5176612138748169, 0.5521097779273987, 0.5617250204086304, 0.5828015208244324, 0.6017156839370728, 0.60699063539505, 0.644881546497345, 0.6532843112945557, 0.6792548894882202, 0.6892452836036682, 0.7088374495506287, 0.7038981914520264, 0.7395533323287964, 0.7517515420913696, 0.7630103826522827, 0.7743664979934692]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.5653819471597672\n",
      " Loss:0.6764074206352234\n",
      " Precision:0.5512141317129136\n",
      " Recall:0.7642061293125153\n",
      " AUC:0.6220733299851418\n",
      "Score for fold 3: loss of 0.6390984654426575; accuracy of 0.7111111283302307%\n",
      "[[108  70]\n",
      " [ 34 148]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 993.9452133 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:108,FN:34,TP:148,FP:70\n",
      "Test of epochs .................................\n",
      " Accuracy:0.7111111111111111\n",
      " Loss:0.6390984654426575\n",
      " Precision:0.6788990825688074\n",
      " Recall:0.8131868131868132\n",
      " AUC:0.7868750967342517\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 19s 351ms/step - loss: 0.7086 - accuracy: 0.5014 - binary_crossentropy: 0.7086 - precision: 0.4587 - recall: 0.1429 - auc: 0.4649\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.7073 - accuracy: 0.5056 - binary_crossentropy: 0.7073 - precision: 0.4709 - recall: 0.1386 - auc: 0.4734\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.7019 - accuracy: 0.5069 - binary_crossentropy: 0.7019 - precision: 0.4771 - recall: 0.1486 - auc: 0.4993\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.7000 - accuracy: 0.5278 - binary_crossentropy: 0.7000 - precision: 0.5442 - recall: 0.1757 - auc: 0.5086\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 16s 355ms/step - loss: 0.6949 - accuracy: 0.5361 - binary_crossentropy: 0.6949 - precision: 0.5667 - recall: 0.1943 - auc: 0.5313\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6913 - accuracy: 0.5361 - binary_crossentropy: 0.6913 - precision: 0.5702 - recall: 0.1857 - auc: 0.5492\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6877 - accuracy: 0.5486 - binary_crossentropy: 0.6877 - precision: 0.6068 - recall: 0.2029 - auc: 0.5718\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6842 - accuracy: 0.5549 - binary_crossentropy: 0.6842 - precision: 0.6214 - recall: 0.2157 - auc: 0.5855\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6790 - accuracy: 0.5771 - binary_crossentropy: 0.6790 - precision: 0.6655 - recall: 0.2614 - auc: 0.6088\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6759 - accuracy: 0.5868 - binary_crossentropy: 0.6759 - precision: 0.6966 - recall: 0.2657 - auc: 0.6310\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6718 - accuracy: 0.6076 - binary_crossentropy: 0.6718 - precision: 0.7528 - recall: 0.2871 - auc: 0.6544\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6707 - accuracy: 0.5951 - binary_crossentropy: 0.6707 - precision: 0.7067 - recall: 0.2857 - auc: 0.6566\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6674 - accuracy: 0.6062 - binary_crossentropy: 0.6674 - precision: 0.7301 - recall: 0.3014 - auc: 0.6752\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.6615 - accuracy: 0.6250 - binary_crossentropy: 0.6615 - precision: 0.7597 - recall: 0.3343 - auc: 0.7019\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.6623 - accuracy: 0.6285 - binary_crossentropy: 0.6623 - precision: 0.7705 - recall: 0.3357 - auc: 0.6978\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.6582 - accuracy: 0.6271 - binary_crossentropy: 0.6582 - precision: 0.7801 - recall: 0.3243 - auc: 0.7192\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6547 - accuracy: 0.6410 - binary_crossentropy: 0.6547 - precision: 0.7942 - recall: 0.3529 - auc: 0.7355\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.6503 - accuracy: 0.6556 - binary_crossentropy: 0.6503 - precision: 0.8129 - recall: 0.3786 - auc: 0.7558\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.6469 - accuracy: 0.6646 - binary_crossentropy: 0.6469 - precision: 0.8423 - recall: 0.3814 - auc: 0.7740\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.6428 - accuracy: 0.6743 - binary_crossentropy: 0.6428 - precision: 0.8576 - recall: 0.3957 - auc: 0.7887\n",
      "Loss of Train ......................................\n",
      "[0.708643913269043, 0.7072741389274597, 0.701850950717926, 0.6999596357345581, 0.6949479579925537, 0.6913432478904724, 0.6877079010009766, 0.6842169165611267, 0.6790239810943604, 0.6759259700775146, 0.6718229651451111, 0.6706598997116089, 0.6673688292503357, 0.6614516377449036, 0.6622767448425293, 0.6581893563270569, 0.654693067073822, 0.6502805352210999, 0.6469144821166992, 0.6427654027938843]\n",
      "Accuracy of Train ......................................\n",
      "[0.5013889074325562, 0.5055555701255798, 0.5069444179534912, 0.5277777910232544, 0.5361111164093018, 0.5361111164093018, 0.5486111044883728, 0.5548611283302307, 0.5770833492279053, 0.5868055820465088, 0.6076388955116272, 0.5951389074325562, 0.606249988079071, 0.625, 0.6284722089767456, 0.6270833611488342, 0.6409721970558167, 0.6555555462837219, 0.6645833253860474, 0.6743055582046509]\n",
      "Precision of Train ......................................\n",
      "[0.4587155878543854, 0.47087377309799194, 0.47706422209739685, 0.5442478060722351, 0.5666666626930237, 0.5701754093170166, 0.6068376302719116, 0.6213991641998291, 0.6654545664787292, 0.6966292262077332, 0.7528089880943298, 0.7067137956619263, 0.7301037907600403, 0.7597402334213257, 0.7704917788505554, 0.7800687551498413, 0.7942122220993042, 0.8128834366798401, 0.8422712683677673, 0.8575851321220398]\n",
      "Recall of Train ......................................\n",
      "[0.1428571492433548, 0.13857142627239227, 0.1485714316368103, 0.17571428418159485, 0.19428572058677673, 0.18571428954601288, 0.2028571367263794, 0.21571429073810577, 0.261428564786911, 0.26571428775787354, 0.2871428430080414, 0.2857142984867096, 0.30142858624458313, 0.334285706281662, 0.33571428060531616, 0.32428571581840515, 0.35285714268684387, 0.37857142090797424, 0.3814285695552826, 0.39571428298950195]\n",
      "AUC of Train ......................................\n",
      "[0.4648725688457489, 0.47344788908958435, 0.4992673397064209, 0.5086342096328735, 0.5312538743019104, 0.5492229461669922, 0.5717693567276001, 0.5855047702789307, 0.6088243126869202, 0.6309623718261719, 0.6544382572174072, 0.6565907001495361, 0.6751920580863953, 0.7018822431564331, 0.697758674621582, 0.7192104458808899, 0.7354865074157715, 0.7558175921440125, 0.7739700675010681, 0.7887104153633118]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.5853125035762787\n",
      " Loss:0.6758658766746521\n",
      " Precision:0.6742471724748611\n",
      " Recall:0.26542857140302656\n",
      " AUC:0.629140830039978\n",
      "Score for fold 4: loss of 0.6468449234962463; accuracy of 0.6472222208976746%\n",
      "[[152   8]\n",
      " [119  81]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1323.1867439 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:152,FN:119,TP:81,FP:8\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6472222222222223\n",
      " Loss:0.6468449234962463\n",
      " Precision:0.9101123595505618\n",
      " Recall:0.405\n",
      " AUC:0.48294280442804427\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 20s 363ms/step - loss: 0.7155 - accuracy: 0.4174 - binary_crossentropy: 0.7155 - precision: 0.4027 - recall: 0.3828 - auc: 0.3979\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.7119 - accuracy: 0.4389 - binary_crossentropy: 0.7119 - precision: 0.4242 - recall: 0.3955 - auc: 0.4172\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.7081 - accuracy: 0.4535 - binary_crossentropy: 0.7081 - precision: 0.4399 - recall: 0.4082 - auc: 0.4390\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.7043 - accuracy: 0.4681 - binary_crossentropy: 0.7043 - precision: 0.4551 - recall: 0.4153 - auc: 0.4555\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6999 - accuracy: 0.4743 - binary_crossentropy: 0.6999 - precision: 0.4615 - recall: 0.4153 - auc: 0.4773\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.6965 - accuracy: 0.5035 - binary_crossentropy: 0.6965 - precision: 0.4945 - recall: 0.4421 - auc: 0.5001\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.6930 - accuracy: 0.5111 - binary_crossentropy: 0.6930 - precision: 0.5031 - recall: 0.4548 - auc: 0.5216\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.6901 - accuracy: 0.5424 - binary_crossentropy: 0.6901 - precision: 0.5386 - recall: 0.4831 - auc: 0.5426\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6876 - accuracy: 0.5396 - binary_crossentropy: 0.6876 - precision: 0.5366 - recall: 0.4661 - auc: 0.5532\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 16s 360ms/step - loss: 0.6823 - accuracy: 0.5549 - binary_crossentropy: 0.6823 - precision: 0.5556 - recall: 0.4732 - auc: 0.5835\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6792 - accuracy: 0.5729 - binary_crossentropy: 0.6792 - precision: 0.5766 - recall: 0.4944 - auc: 0.6026\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6753 - accuracy: 0.5882 - binary_crossentropy: 0.6753 - precision: 0.5935 - recall: 0.5155 - auc: 0.6212\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6723 - accuracy: 0.6021 - binary_crossentropy: 0.6723 - precision: 0.6127 - recall: 0.5184 - auc: 0.6430\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6721 - accuracy: 0.6014 - binary_crossentropy: 0.6721 - precision: 0.6098 - recall: 0.5254 - auc: 0.6447\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.6669 - accuracy: 0.6153 - binary_crossentropy: 0.6669 - precision: 0.6275 - recall: 0.5353 - auc: 0.6706\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.6643 - accuracy: 0.6368 - binary_crossentropy: 0.6643 - precision: 0.6534 - recall: 0.5565 - auc: 0.6820\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6616 - accuracy: 0.6375 - binary_crossentropy: 0.6616 - precision: 0.6566 - recall: 0.5508 - auc: 0.6934\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.6565 - accuracy: 0.6653 - binary_crossentropy: 0.6565 - precision: 0.6834 - recall: 0.5946 - auc: 0.7252\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6518 - accuracy: 0.6750 - binary_crossentropy: 0.6518 - precision: 0.6935 - recall: 0.6073 - auc: 0.7448\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.6517 - accuracy: 0.6757 - binary_crossentropy: 0.6517 - precision: 0.7012 - recall: 0.5932 - auc: 0.7424\n",
      "Loss of Train ......................................\n",
      "[0.7155476212501526, 0.7118614315986633, 0.7080718278884888, 0.704337477684021, 0.6999425888061523, 0.6965198516845703, 0.6929808855056763, 0.6900840997695923, 0.6876300573348999, 0.6823037266731262, 0.6791542768478394, 0.6753175258636475, 0.6723077297210693, 0.6720728278160095, 0.6669067144393921, 0.6642672419548035, 0.661638617515564, 0.6564671993255615, 0.6517861485481262, 0.6517243981361389]\n",
      "Accuracy of Train ......................................\n",
      "[0.4173611104488373, 0.43888887763023376, 0.45347222685813904, 0.4680555462837219, 0.47430557012557983, 0.5034722089767456, 0.5111111402511597, 0.5423611402511597, 0.5395833253860474, 0.5548611283302307, 0.5729166865348816, 0.5881944298744202, 0.6020833253860474, 0.6013888716697693, 0.6152777671813965, 0.636805534362793, 0.637499988079071, 0.6652777791023254, 0.675000011920929, 0.675694465637207]\n",
      "Precision of Train ......................................\n",
      "[0.4026745855808258, 0.42424243688583374, 0.4398782253265381, 0.4551083445549011, 0.4615384638309479, 0.4944707751274109, 0.503125011920929, 0.5385826826095581, 0.5365853905677795, 0.5555555820465088, 0.576606273651123, 0.5934959053993225, 0.6126878261566162, 0.6098360419273376, 0.6274834275245667, 0.653399646282196, 0.6565656661987305, 0.6834415793418884, 0.6935483813285828, 0.7011685967445374]\n",
      "Recall of Train ......................................\n",
      "[0.3827683627605438, 0.395480215549469, 0.40819209814071655, 0.41525423526763916, 0.41525423526763916, 0.44209039211273193, 0.4548022747039795, 0.4830508530139923, 0.4661017060279846, 0.4731638431549072, 0.49435028433799744, 0.5155367255210876, 0.5183615684509277, 0.5254237055778503, 0.5353107452392578, 0.5564971566200256, 0.5508474707603455, 0.5946327447891235, 0.6073446273803711, 0.5932203531265259]\n",
      "AUC of Train ......................................\n",
      "[0.3978651165962219, 0.4171760678291321, 0.4389915466308594, 0.45545828342437744, 0.47727668285369873, 0.500116765499115, 0.5216417908668518, 0.5425580739974976, 0.5532265901565552, 0.5834655165672302, 0.6026046872138977, 0.6211515069007874, 0.6430355310440063, 0.6447325348854065, 0.6706029176712036, 0.6820113658905029, 0.6934179067611694, 0.7251647710800171, 0.7447988390922546, 0.7423917651176453]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.5586805567145348\n",
      " Loss:0.6820461124181747\n",
      " Precision:0.5609997421503067\n",
      " Recall:0.4913841798901558\n",
      " AUC:0.5828844130039215\n",
      "Score for fold 5: loss of 0.649182915687561; accuracy of 0.6972222328186035%\n",
      "[[124  44]\n",
      " [ 65 127]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1657.9489054 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:124,FN:65,TP:127,FP:44\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6972222222222222\n",
      " Loss:0.649182915687561\n",
      " Precision:0.7426900584795322\n",
      " Recall:0.6614583333333334\n",
      " AUC:0.6587714947089947\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.549756945669651 - Loss: 0.6828229576349258\n",
      "> Fold 1 - Precision: 0.5595240265130996\n",
      "> Fold 1 - Recall: 0.5107438012957572\n",
      "> Fold 1 - AUC: 0.5801787972450256\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.6416666666666667 - Loss: 0.6625610589981079\n",
      "> Fold 1 - Precision: 0.6451612903225806\n",
      "> Fold 1 - Recall: 0.5747126436781609\n",
      "> Fold 1 - AUC: 0.6068685169610317\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.5688541635870934 - Loss: 0.6838081270456314\n",
      "> Fold 2 - Precision: 0.6980049669742584\n",
      "> Fold 2 - Recall: 0.27159090898931026\n",
      "> Fold 2 - AUC: 0.6296979457139968\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.7277777777777777 - Loss: 0.6348063945770264\n",
      "> Fold 2 - Precision: 0.78125\n",
      "> Fold 2 - Recall: 0.4934210526315789\n",
      "> Fold 2 - AUC: 0.6008771929824561\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.5653819471597672 - Loss: 0.6764074206352234\n",
      "> Fold 3 - Precision: 0.5512141317129136\n",
      "> Fold 3 - Recall: 0.7642061293125153\n",
      "> Fold 3 - AUC: 0.6220733299851418\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.7111111111111111 - Loss: 0.6390984654426575\n",
      "> Fold 3 - Precision: 0.6788990825688074\n",
      "> Fold 3 - Recall: 0.8131868131868132\n",
      "> Fold 3 - AUC: 0.7868750967342517\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.5853125035762787 - Loss: 0.6758658766746521\n",
      "> Fold 4 - Precision: 0.6742471724748611\n",
      "> Fold 4 - Recall: 0.26542857140302656\n",
      "> Fold 4 - AUC: 0.629140830039978\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.6472222222222223 - Loss: 0.6468449234962463\n",
      "> Fold 4 - Precision: 0.9101123595505618\n",
      "> Fold 4 - Recall: 0.405\n",
      "> Fold 4 - AUC: 0.48294280442804427\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.5586805567145348 - Loss: 0.6820461124181747\n",
      "> Fold 5 - Precision: 0.5609997421503067\n",
      "> Fold 5 - Recall: 0.4913841798901558\n",
      "> Fold 5 - AUC: 0.5828844130039215\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.6972222222222222 - Loss: 0.649182915687561\n",
      "> Fold 5 - Precision: 0.7426900584795322\n",
      "> Fold 5 - Recall: 0.6614583333333334\n",
      "> Fold 5 - AUC: 0.6587714947089947\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.565597223341465 (+- 0.011816098783299802)\n",
      "> Loss: 0.6801900988817214 (+- 0.003360785969659756)\n",
      "> Precision: 0.6087980079650879 (+- 0.0636709932982803)\n",
      "> Recall: 0.460670718178153 (+- 0.18409510928647327)\n",
      "> AUC: 0.6087950631976128 (+- 0.022438563079250292)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.6849999999999999 (+- 0.03454287012602178)\n",
      "> Loss: 0.6464987516403198 (+- 0.009558218858608037)\n",
      "> Precision: 0.7516225581842964 (+- 0.09241136018580984)\n",
      "> Recall: 0.5895557685659774 (+- 0.140501855228699)\n",
      "> AUC: 0.6272670211629556 (+- 0.09839641373770032)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 702 FN SUM: 369 TP SUM: 531 FP SUM: 198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(Xception(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc1320",
   "metadata": {},
   "source": [
    "# MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8728dca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 13s 155ms/step - loss: 0.7026 - accuracy: 0.5681 - binary_crossentropy: 0.7026 - precision: 0.5396 - recall: 0.9264 - auc: 0.6725\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 153ms/step - loss: 0.6198 - accuracy: 0.6486 - binary_crossentropy: 0.6198 - precision: 0.5971 - recall: 0.9139 - auc: 0.7762\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 154ms/step - loss: 0.5516 - accuracy: 0.7194 - binary_crossentropy: 0.5516 - precision: 0.6561 - recall: 0.9222 - auc: 0.8525\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.5022 - accuracy: 0.7757 - binary_crossentropy: 0.5022 - precision: 0.7160 - recall: 0.9139 - auc: 0.8938\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.4518 - accuracy: 0.8361 - binary_crossentropy: 0.4518 - precision: 0.7782 - recall: 0.9403 - auc: 0.9336\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.4161 - accuracy: 0.8646 - binary_crossentropy: 0.4161 - precision: 0.8190 - recall: 0.9361 - auc: 0.9512\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.3779 - accuracy: 0.8993 - binary_crossentropy: 0.3779 - precision: 0.8653 - recall: 0.9458 - auc: 0.9668\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.3533 - accuracy: 0.9076 - binary_crossentropy: 0.3533 - precision: 0.8787 - recall: 0.9458 - auc: 0.9769\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.3280 - accuracy: 0.9299 - binary_crossentropy: 0.3280 - precision: 0.9110 - recall: 0.9528 - auc: 0.9827\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.3066 - accuracy: 0.9451 - binary_crossentropy: 0.3066 - precision: 0.9325 - recall: 0.9597 - auc: 0.9864\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.2910 - accuracy: 0.9542 - binary_crossentropy: 0.2910 - precision: 0.9431 - recall: 0.9667 - auc: 0.9895\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.2785 - accuracy: 0.9556 - binary_crossentropy: 0.2785 - precision: 0.9518 - recall: 0.9597 - auc: 0.9889\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.2576 - accuracy: 0.9632 - binary_crossentropy: 0.2576 - precision: 0.9575 - recall: 0.9694 - auc: 0.9922\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.2411 - accuracy: 0.9674 - binary_crossentropy: 0.2411 - precision: 0.9654 - recall: 0.9694 - auc: 0.9951\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.2343 - accuracy: 0.9681 - binary_crossentropy: 0.2343 - precision: 0.9746 - recall: 0.9611 - auc: 0.9929\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.2130 - accuracy: 0.9750 - binary_crossentropy: 0.2130 - precision: 0.9777 - recall: 0.9722 - auc: 0.9962\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.2124 - accuracy: 0.9694 - binary_crossentropy: 0.2124 - precision: 0.9656 - recall: 0.9736 - auc: 0.9943\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.1981 - accuracy: 0.9757 - binary_crossentropy: 0.1981 - precision: 0.9804 - recall: 0.9708 - auc: 0.9969\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.1841 - accuracy: 0.9826 - binary_crossentropy: 0.1841 - precision: 0.9874 - recall: 0.9778 - auc: 0.9976\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.1825 - accuracy: 0.9785 - binary_crossentropy: 0.1825 - precision: 0.9845 - recall: 0.9722 - auc: 0.9968\n",
      "Loss of Train ......................................\n",
      "[0.7025645971298218, 0.6197542548179626, 0.5515986680984497, 0.5021673440933228, 0.45179688930511475, 0.4160885214805603, 0.3779386878013611, 0.35333484411239624, 0.3280473053455353, 0.3066036105155945, 0.2909598648548126, 0.27851608395576477, 0.2575816810131073, 0.24113014340400696, 0.23426799476146698, 0.21299609541893005, 0.2123834192752838, 0.1980539709329605, 0.18414711952209473, 0.1824609488248825]\n",
      "Accuracy of Train ......................................\n",
      "[0.5680555701255798, 0.6486111283302307, 0.7194444537162781, 0.7756944298744202, 0.8361111283302307, 0.8645833134651184, 0.8993055820465088, 0.9076389074325562, 0.9298611283302307, 0.9451388716697693, 0.9541666507720947, 0.9555555582046509, 0.9631944298744202, 0.9673610925674438, 0.9680555462837219, 0.9750000238418579, 0.9694444537162781, 0.9756944179534912, 0.9826388955116272, 0.9784722328186035]\n",
      "Precision of Train ......................................\n",
      "[0.5396440029144287, 0.5970962047576904, 0.6561264991760254, 0.7159956693649292, 0.7781609296798706, 0.8189550638198853, 0.865311324596405, 0.8787096738815308, 0.9110226035118103, 0.9325236082077026, 0.9430894255638123, 0.9517906308174133, 0.957476019859314, 0.9654218554496765, 0.9746478796005249, 0.9776536226272583, 0.9655647277832031, 0.9803646802902222, 0.9873772859573364, 0.9845288395881653]\n",
      "Recall of Train ......................................\n",
      "[0.9263888597488403, 0.9138888716697693, 0.9222221970558167, 0.9138888716697693, 0.9402777552604675, 0.9361110925674438, 0.9458333253860474, 0.9458333253860474, 0.9527778029441833, 0.9597222208976746, 0.9666666388511658, 0.9597222208976746, 0.9694444537162781, 0.9694444537162781, 0.9611111283302307, 0.9722222089767456, 0.9736111164093018, 0.9708333611488342, 0.9777777791023254, 0.9722222089767456]\n",
      "AUC of Train ......................................\n",
      "[0.6724507808685303, 0.7762008309364319, 0.8524652719497681, 0.8938242793083191, 0.9335762858390808, 0.9512355327606201, 0.9667901396751404, 0.976895272731781, 0.9826542735099792, 0.986436128616333, 0.9894617795944214, 0.9888551235198975, 0.9922009706497192, 0.9951273202896118, 0.9929069876670837, 0.9961785674095154, 0.9943248629570007, 0.9969424605369568, 0.997610867023468, 0.9968094229698181]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8892013907432557\n",
      " Loss:0.34511960223317145\n",
      " Precision:0.8690730273723603\n",
      " Recall:0.952499994635582\n",
      " AUC:0.9466473579406738\n",
      "Score for fold 1: loss of 0.2307630479335785; accuracy of 0.9361110925674438%\n",
      "[[178   2]\n",
      " [ 21 159]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 163.13089240000002 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:178,FN:21,TP:159,FP:2\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9361111111111111\n",
      " Loss:0.2307630479335785\n",
      " Precision:0.9875776397515528\n",
      " Recall:0.8833333333333333\n",
      " AUC:0.8889028475711893\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 158ms/step - loss: 0.7580 - accuracy: 0.5139 - binary_crossentropy: 0.7580 - precision: 0.5070 - recall: 0.8087 - auc: 0.5124\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.6728 - accuracy: 0.6062 - binary_crossentropy: 0.6728 - precision: 0.5690 - recall: 0.8575 - auc: 0.6591\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.6021 - accuracy: 0.6778 - binary_crossentropy: 0.6021 - precision: 0.6248 - recall: 0.8813 - auc: 0.7731\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.5408 - accuracy: 0.7493 - binary_crossentropy: 0.5408 - precision: 0.6940 - recall: 0.8869 - auc: 0.8577\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.4921 - accuracy: 0.8090 - binary_crossentropy: 0.4921 - precision: 0.7561 - recall: 0.9092 - auc: 0.9119\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.4509 - accuracy: 0.8556 - binary_crossentropy: 0.4509 - precision: 0.8075 - recall: 0.9316 - auc: 0.9417\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.4147 - accuracy: 0.9000 - binary_crossentropy: 0.4147 - precision: 0.8657 - recall: 0.9455 - auc: 0.9630\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.3858 - accuracy: 0.9174 - binary_crossentropy: 0.3858 - precision: 0.8892 - recall: 0.9525 - auc: 0.9751\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.3549 - accuracy: 0.9306 - binary_crossentropy: 0.3549 - precision: 0.9063 - recall: 0.9595 - auc: 0.9839\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.3284 - accuracy: 0.9417 - binary_crossentropy: 0.3284 - precision: 0.9213 - recall: 0.9651 - auc: 0.9898\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.3030 - accuracy: 0.9542 - binary_crossentropy: 0.3030 - precision: 0.9489 - recall: 0.9595 - auc: 0.9923\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.2801 - accuracy: 0.9681 - binary_crossentropy: 0.2801 - precision: 0.9602 - recall: 0.9763 - auc: 0.9956\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.2696 - accuracy: 0.9632 - binary_crossentropy: 0.2696 - precision: 0.9611 - recall: 0.9651 - auc: 0.9946\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.2556 - accuracy: 0.9722 - binary_crossentropy: 0.2556 - precision: 0.9708 - recall: 0.9735 - auc: 0.9964\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.2397 - accuracy: 0.9757 - binary_crossentropy: 0.2397 - precision: 0.9762 - recall: 0.9749 - auc: 0.9970\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.2221 - accuracy: 0.9847 - binary_crossentropy: 0.2221 - precision: 0.9846 - recall: 0.9846 - auc: 0.9977\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.2186 - accuracy: 0.9778 - binary_crossentropy: 0.2186 - precision: 0.9844 - recall: 0.9707 - auc: 0.9969\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.2003 - accuracy: 0.9861 - binary_crossentropy: 0.2003 - precision: 0.9929 - recall: 0.9791 - auc: 0.9982\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.1979 - accuracy: 0.9840 - binary_crossentropy: 0.1979 - precision: 0.9860 - recall: 0.9818 - auc: 0.9977\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.1813 - accuracy: 0.9882 - binary_crossentropy: 0.1813 - precision: 0.9916 - recall: 0.9846 - auc: 0.9984\n",
      "Loss of Train ......................................\n",
      "[0.7579777836799622, 0.6728086471557617, 0.6020706295967102, 0.5407652258872986, 0.4921165406703949, 0.45092660188674927, 0.41474422812461853, 0.3857800364494324, 0.35491320490837097, 0.32842129468917847, 0.30296117067337036, 0.2801489233970642, 0.26962974667549133, 0.25561845302581787, 0.2397472858428955, 0.22207938134670258, 0.21857964992523193, 0.20026764273643494, 0.19791480898857117, 0.18127864599227905]\n",
      "Accuracy of Train ......................................\n",
      "[0.5138888955116272, 0.606249988079071, 0.6777777671813965, 0.7493055462837219, 0.8090277910232544, 0.855555534362793, 0.8999999761581421, 0.9173611402511597, 0.9305555820465088, 0.9416666626930237, 0.9541666507720947, 0.9680555462837219, 0.9631944298744202, 0.9722222089767456, 0.9756944179534912, 0.9847221970558167, 0.9777777791023254, 0.9861111044883728, 0.9840278029441833, 0.988194465637207]\n",
      "Precision of Train ......................................\n",
      "[0.5070052742958069, 0.5690454244613647, 0.6247524619102478, 0.693989098072052, 0.7560975551605225, 0.8075060248374939, 0.8657289147377014, 0.8891786336898804, 0.9063324332237244, 0.9213333129882812, 0.9488950371742249, 0.9601648449897766, 0.9610570073127747, 0.9707520604133606, 0.9762237668037415, 0.9846368432044983, 0.9844192862510681, 0.9929178357124329, 0.9859747290611267, 0.9915611743927002]\n",
      "Recall of Train ......................................\n",
      "[0.8086591958999634, 0.8575419187545776, 0.8812848925590515, 0.8868715167045593, 0.909217894077301, 0.9315642714500427, 0.9455307126045227, 0.9525139927864075, 0.9594972133636475, 0.9650837779045105, 0.9594972133636475, 0.9762569665908813, 0.9650837779045105, 0.9734637141227722, 0.9748603105545044, 0.9846368432044983, 0.9706704020500183, 0.9790502786636353, 0.9818435907363892, 0.9846368432044983]\n",
      "AUC of Train ......................................\n",
      "[0.5124270915985107, 0.6591011881828308, 0.7731236815452576, 0.8576778769493103, 0.9118838310241699, 0.9416860938072205, 0.9630361795425415, 0.9751052856445312, 0.9839355945587158, 0.9898183345794678, 0.9923068284988403, 0.9956402778625488, 0.9946092367172241, 0.9963781237602234, 0.9970484972000122, 0.9976725578308105, 0.9969048500061035, 0.9982329607009888, 0.9976695775985718, 0.9984201192855835]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8827777743339539\n",
      " Loss:0.3684374950826168\n",
      " Precision:0.864878585934639\n",
      " Recall:0.942388266324997\n",
      " AUC:0.9266339093446732\n",
      "Score for fold 2: loss of 0.23313301801681519; accuracy of 0.9666666388511658%\n",
      "[[174   2]\n",
      " [ 10 174]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 319.10067810000004 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:174,FN:10,TP:174,FP:2\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9666666666666667\n",
      " Loss:0.23313301801681519\n",
      " Precision:0.9886363636363636\n",
      " Recall:0.9456521739130435\n",
      " AUC:0.9456521739130435\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 157ms/step - loss: 0.7860 - accuracy: 0.4722 - binary_crossentropy: 0.7860 - precision: 0.4454 - recall: 0.2264 - auc: 0.4599\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.6772 - accuracy: 0.5736 - binary_crossentropy: 0.6772 - precision: 0.6216 - recall: 0.3764 - auc: 0.6399\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.5923 - accuracy: 0.6993 - binary_crossentropy: 0.5923 - precision: 0.7744 - recall: 0.5625 - auc: 0.7756\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.5318 - accuracy: 0.7625 - binary_crossentropy: 0.5318 - precision: 0.8270 - recall: 0.6639 - auc: 0.8559\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.4705 - accuracy: 0.8396 - binary_crossentropy: 0.4705 - precision: 0.8838 - recall: 0.7819 - auc: 0.9154\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.4265 - accuracy: 0.8687 - binary_crossentropy: 0.4265 - precision: 0.9053 - recall: 0.8236 - auc: 0.9476\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.3876 - accuracy: 0.9049 - binary_crossentropy: 0.3876 - precision: 0.9268 - recall: 0.8792 - auc: 0.9641\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.3538 - accuracy: 0.9299 - binary_crossentropy: 0.3538 - precision: 0.9453 - recall: 0.9125 - auc: 0.9758\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.3223 - accuracy: 0.9361 - binary_crossentropy: 0.3223 - precision: 0.9511 - recall: 0.9194 - auc: 0.9850\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.2969 - accuracy: 0.9576 - binary_crossentropy: 0.2969 - precision: 0.9700 - recall: 0.9444 - auc: 0.9882\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.2835 - accuracy: 0.9493 - binary_crossentropy: 0.2835 - precision: 0.9615 - recall: 0.9361 - auc: 0.9892\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.2644 - accuracy: 0.9590 - binary_crossentropy: 0.2644 - precision: 0.9701 - recall: 0.9472 - auc: 0.9917\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.2409 - accuracy: 0.9729 - binary_crossentropy: 0.2409 - precision: 0.9830 - recall: 0.9625 - auc: 0.9950\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.2328 - accuracy: 0.9688 - binary_crossentropy: 0.2328 - precision: 0.9720 - recall: 0.9653 - auc: 0.9943\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.2181 - accuracy: 0.9743 - binary_crossentropy: 0.2181 - precision: 0.9830 - recall: 0.9653 - auc: 0.9959\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.2069 - accuracy: 0.9736 - binary_crossentropy: 0.2069 - precision: 0.9803 - recall: 0.9667 - auc: 0.9958\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.1949 - accuracy: 0.9771 - binary_crossentropy: 0.1949 - precision: 0.9845 - recall: 0.9694 - auc: 0.9970\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.1871 - accuracy: 0.9743 - binary_crossentropy: 0.1871 - precision: 0.9830 - recall: 0.9653 - auc: 0.9966\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.1797 - accuracy: 0.9764 - binary_crossentropy: 0.1797 - precision: 0.9831 - recall: 0.9694 - auc: 0.9964\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.1665 - accuracy: 0.9847 - binary_crossentropy: 0.1665 - precision: 0.9957 - recall: 0.9736 - auc: 0.9985\n",
      "Loss of Train ......................................\n",
      "[0.7859663367271423, 0.6771958470344543, 0.5923258066177368, 0.5317859053611755, 0.4704912006855011, 0.4264843761920929, 0.3876001238822937, 0.3537605404853821, 0.32227182388305664, 0.29693588614463806, 0.283509224653244, 0.2643902599811554, 0.24088504910469055, 0.23283731937408447, 0.2180929332971573, 0.20689521729946136, 0.19493624567985535, 0.18708766996860504, 0.17970064282417297, 0.1665107160806656]\n",
      "Accuracy of Train ......................................\n",
      "[0.4722222089767456, 0.5736111402511597, 0.699305534362793, 0.762499988079071, 0.8395833373069763, 0.8687499761581421, 0.9048610925674438, 0.9298611283302307, 0.9361110925674438, 0.9576388597488403, 0.949305534362793, 0.9590277671813965, 0.9729166626930237, 0.96875, 0.9743055701255798, 0.9736111164093018, 0.9770833253860474, 0.9743055701255798, 0.9763888716697693, 0.9847221970558167]\n",
      "Precision of Train ......................................\n",
      "[0.4453551769256592, 0.6215596199035645, 0.7743785977363586, 0.8269895911216736, 0.8838304281234741, 0.9053435325622559, 0.9267935752868652, 0.9453237652778625, 0.9511494040489197, 0.9700428247451782, 0.9614835977554321, 0.9701279997825623, 0.9829787015914917, 0.9720279574394226, 0.9830268621444702, 0.9802817106246948, 0.9844852089881897, 0.9830268621444702, 0.983098566532135, 0.9957386255264282]\n",
      "Recall of Train ......................................\n",
      "[0.22638888657093048, 0.37638887763023376, 0.5625, 0.6638888716697693, 0.7819444537162781, 0.8236111402511597, 0.8791666626930237, 0.9125000238418579, 0.9194444417953491, 0.9444444179534912, 0.9361110925674438, 0.9472222328186035, 0.9624999761581421, 0.9652777910232544, 0.9652777910232544, 0.9666666388511658, 0.9694444537162781, 0.9652777910232544, 0.9694444537162781, 0.9736111164093018]\n",
      "AUC of Train ......................................\n",
      "[0.4598563015460968, 0.6399102807044983, 0.7756211757659912, 0.8558738827705383, 0.9153761863708496, 0.9476109147071838, 0.9641271233558655, 0.9757745862007141, 0.9849836230278015, 0.9882407188415527, 0.9891985058784485, 0.9917216300964355, 0.9949826598167419, 0.9943305850028992, 0.9958969950675964, 0.9957532286643982, 0.9970081448554993, 0.9965924620628357, 0.9963647723197937, 0.9984722137451172]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8827430486679078\n",
      " Loss:0.35098315626382826\n",
      " Precision:0.9023521304130554\n",
      " Recall:0.8355555556714535\n",
      " AUC:0.9228847995400429\n",
      "Score for fold 3: loss of 0.23406656086444855; accuracy of 0.9444444179534912%\n",
      "[[179   1]\n",
      " [ 19 161]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 476.0086524 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:179,FN:19,TP:161,FP:1\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9444444444444444\n",
      " Loss:0.23406656086444855\n",
      " Precision:0.9938271604938271\n",
      " Recall:0.8944444444444445\n",
      " AUC:0.8992424242424243\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 155ms/step - loss: 0.6087 - accuracy: 0.6722 - binary_crossentropy: 0.6087 - precision: 0.6449 - recall: 0.7584 - auc: 0.7396\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 152ms/step - loss: 0.5525 - accuracy: 0.7361 - binary_crossentropy: 0.5525 - precision: 0.7095 - recall: 0.7947 - auc: 0.8254\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.4963 - accuracy: 0.8104 - binary_crossentropy: 0.4963 - precision: 0.7911 - recall: 0.8408 - auc: 0.9002\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 7s 162ms/step - loss: 0.4564 - accuracy: 0.8472 - binary_crossentropy: 0.4564 - precision: 0.8307 - recall: 0.8701 - auc: 0.9325\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.4164 - accuracy: 0.8965 - binary_crossentropy: 0.4164 - precision: 0.8836 - recall: 0.9120 - auc: 0.9616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.3945 - accuracy: 0.8986 - binary_crossentropy: 0.3945 - precision: 0.8893 - recall: 0.9092 - auc: 0.9666\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 7s 167ms/step - loss: 0.3672 - accuracy: 0.9257 - binary_crossentropy: 0.3672 - precision: 0.9200 - recall: 0.9316 - auc: 0.9779\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.3338 - accuracy: 0.9458 - binary_crossentropy: 0.3338 - precision: 0.9358 - recall: 0.9567 - auc: 0.9880\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.3149 - accuracy: 0.9542 - binary_crossentropy: 0.3149 - precision: 0.9526 - recall: 0.9553 - auc: 0.9916\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.2920 - accuracy: 0.9590 - binary_crossentropy: 0.2920 - precision: 0.9594 - recall: 0.9581 - auc: 0.9933\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.2801 - accuracy: 0.9646 - binary_crossentropy: 0.2801 - precision: 0.9637 - recall: 0.9651 - auc: 0.9944\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.2583 - accuracy: 0.9715 - binary_crossentropy: 0.2583 - precision: 0.9681 - recall: 0.9749 - auc: 0.9959\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.2548 - accuracy: 0.9708 - binary_crossentropy: 0.2548 - precision: 0.9720 - recall: 0.9693 - auc: 0.9956\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.2412 - accuracy: 0.9757 - binary_crossentropy: 0.2412 - precision: 0.9723 - recall: 0.9791 - auc: 0.9956\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.2200 - accuracy: 0.9792 - binary_crossentropy: 0.2200 - precision: 0.9791 - recall: 0.9791 - auc: 0.9975\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.2218 - accuracy: 0.9694 - binary_crossentropy: 0.2218 - precision: 0.9667 - recall: 0.9721 - auc: 0.9966\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.2023 - accuracy: 0.9812 - binary_crossentropy: 0.2023 - precision: 0.9805 - recall: 0.9818 - auc: 0.9985\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.1906 - accuracy: 0.9889 - binary_crossentropy: 0.1906 - precision: 0.9902 - recall: 0.9874 - auc: 0.9988\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.1867 - accuracy: 0.9799 - binary_crossentropy: 0.1867 - precision: 0.9845 - recall: 0.9749 - auc: 0.9981\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.1822 - accuracy: 0.9806 - binary_crossentropy: 0.1822 - precision: 0.9791 - recall: 0.9818 - auc: 0.9985\n",
      "Loss of Train ......................................\n",
      "[0.6086952686309814, 0.5525152683258057, 0.49630409479141235, 0.4564492404460907, 0.41638848185539246, 0.3944817781448364, 0.3671984076499939, 0.3337794542312622, 0.3149104118347168, 0.2919972538948059, 0.2801467180252075, 0.258290559053421, 0.2547954022884369, 0.24121008813381195, 0.22002778947353363, 0.22177451848983765, 0.2023090422153473, 0.19055813550949097, 0.1867264211177826, 0.18217669427394867]\n",
      "Accuracy of Train ......................................\n",
      "[0.6722221970558167, 0.7361111044883728, 0.8104166388511658, 0.8472222089767456, 0.8965277671813965, 0.8986111283302307, 0.925694465637207, 0.9458333253860474, 0.9541666507720947, 0.9590277671813965, 0.9645833373069763, 0.9715277552604675, 0.9708333611488342, 0.9756944179534912, 0.9791666865348816, 0.9694444537162781, 0.981249988079071, 0.9888888597488403, 0.9798611402511597, 0.980555534362793]\n",
      "Precision of Train ......................................\n",
      "[0.6448931097984314, 0.7094762921333313, 0.7910643815994263, 0.8306666612625122, 0.8836265206336975, 0.8893442749977112, 0.9200000166893005, 0.9357923269271851, 0.9526462554931641, 0.9594405889511108, 0.9637377858161926, 0.96809983253479, 0.9719887971878052, 0.9722607731819153, 0.9790502786636353, 0.9666666388511658, 0.9804741740226746, 0.9901960492134094, 0.9844852089881897, 0.9791086316108704]\n",
      "Recall of Train ......................................\n",
      "[0.7583798766136169, 0.7946927547454834, 0.840782105922699, 0.8701117038726807, 0.9120111465454102, 0.909217894077301, 0.9315642714500427, 0.9567039012908936, 0.9553072452545166, 0.9581005573272705, 0.9650837779045105, 0.9748603105545044, 0.9692737460136414, 0.9790502786636353, 0.9790502786636353, 0.9720670580863953, 0.9818435907363892, 0.9874301552772522, 0.9748603105545044, 0.9818435907363892]\n",
      "AUC of Train ......................................\n",
      "[0.7395724654197693, 0.8254112601280212, 0.9001617431640625, 0.932483434677124, 0.9616461992263794, 0.9665971398353577, 0.9778522253036499, 0.9880176186561584, 0.9916423559188843, 0.9933282732963562, 0.9943776726722717, 0.9959402680397034, 0.9955834150314331, 0.9956431984901428, 0.997486412525177, 0.9965605139732361, 0.9984538555145264, 0.9988464117050171, 0.998054563999176, 0.9984683394432068]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9203819394111633\n",
      " Loss:0.3235367514193058\n",
      " Precision:0.9136509299278259\n",
      " Recall:0.9326117277145386\n",
      " AUC:0.9623063683509827\n",
      "Score for fold 4: loss of 0.2329099029302597; accuracy of 0.9722222089767456%\n",
      "[[176   0]\n",
      " [ 10 174]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 633.2763574999999 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:176,FN:10,TP:174,FP:0\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9722222222222222\n",
      " Loss:0.2329099029302597\n",
      " Precision:1.0\n",
      " Recall:0.9456521739130435\n",
      " AUC:0.9459443665264142\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 153ms/step - loss: 0.8318 - accuracy: 0.4306 - binary_crossentropy: 0.8318 - precision: 0.3571 - recall: 0.1580 - auc: 0.4137\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 153ms/step - loss: 0.7380 - accuracy: 0.5174 - binary_crossentropy: 0.7380 - precision: 0.5426 - recall: 0.2885 - auc: 0.5553\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.6514 - accuracy: 0.6299 - binary_crossentropy: 0.6514 - precision: 0.7010 - recall: 0.4670 - auc: 0.6889\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.5831 - accuracy: 0.6896 - binary_crossentropy: 0.5831 - precision: 0.7587 - recall: 0.5659 - auc: 0.7894\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.5364 - accuracy: 0.7535 - binary_crossentropy: 0.5364 - precision: 0.8062 - recall: 0.6745 - auc: 0.8459\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.4855 - accuracy: 0.8111 - binary_crossentropy: 0.4855 - precision: 0.8455 - recall: 0.7665 - auc: 0.8983\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.4429 - accuracy: 0.8493 - binary_crossentropy: 0.4429 - precision: 0.8774 - recall: 0.8159 - auc: 0.9325\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.4067 - accuracy: 0.8833 - binary_crossentropy: 0.4067 - precision: 0.9023 - recall: 0.8626 - auc: 0.9520\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.3785 - accuracy: 0.9083 - binary_crossentropy: 0.3785 - precision: 0.9185 - recall: 0.8984 - auc: 0.9645\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.3523 - accuracy: 0.9181 - binary_crossentropy: 0.3523 - precision: 0.9236 - recall: 0.9135 - auc: 0.9743\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.3280 - accuracy: 0.9292 - binary_crossentropy: 0.3280 - precision: 0.9359 - recall: 0.9231 - auc: 0.9802\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.3097 - accuracy: 0.9361 - binary_crossentropy: 0.3097 - precision: 0.9356 - recall: 0.9382 - auc: 0.9852\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.2898 - accuracy: 0.9451 - binary_crossentropy: 0.2898 - precision: 0.9513 - recall: 0.9396 - auc: 0.9869\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.2714 - accuracy: 0.9576 - binary_crossentropy: 0.2714 - precision: 0.9587 - recall: 0.9574 - auc: 0.9917\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.2513 - accuracy: 0.9639 - binary_crossentropy: 0.2513 - precision: 0.9669 - recall: 0.9615 - auc: 0.9944\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 173ms/step - loss: 0.2403 - accuracy: 0.9646 - binary_crossentropy: 0.2403 - precision: 0.9656 - recall: 0.9643 - auc: 0.9935\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.2303 - accuracy: 0.9653 - binary_crossentropy: 0.2303 - precision: 0.9682 - recall: 0.9629 - auc: 0.9950\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.2192 - accuracy: 0.9688 - binary_crossentropy: 0.2192 - precision: 0.9684 - recall: 0.9698 - auc: 0.9953\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.2083 - accuracy: 0.9667 - binary_crossentropy: 0.2083 - precision: 0.9632 - recall: 0.9712 - auc: 0.9961\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.1891 - accuracy: 0.9792 - binary_crossentropy: 0.1891 - precision: 0.9834 - recall: 0.9753 - auc: 0.9981\n",
      "Loss of Train ......................................\n",
      "[0.8318296074867249, 0.7379523515701294, 0.65142422914505, 0.58307945728302, 0.5363847613334656, 0.4854651689529419, 0.44286105036735535, 0.40670186281204224, 0.37848180532455444, 0.35225337743759155, 0.3280101418495178, 0.3096633553504944, 0.28977710008621216, 0.27138158679008484, 0.25125038623809814, 0.24030500650405884, 0.23034442961215973, 0.21916139125823975, 0.20827323198318481, 0.18905514478683472]\n",
      "Accuracy of Train ......................................\n",
      "[0.4305555522441864, 0.5173611044883728, 0.6298611164093018, 0.6895833611488342, 0.7534722089767456, 0.8111110925674438, 0.8493055701255798, 0.8833333253860474, 0.9083333611488342, 0.918055534362793, 0.9291666746139526, 0.9361110925674438, 0.9451388716697693, 0.9576388597488403, 0.9638888835906982, 0.9645833373069763, 0.9652777910232544, 0.96875, 0.9666666388511658, 0.9791666865348816]\n",
      "Precision of Train ......................................\n",
      "[0.3571428656578064, 0.5426356792449951, 0.7010309100151062, 0.7587476968765259, 0.8062397241592407, 0.8454545736312866, 0.877400279045105, 0.9022988677024841, 0.9185393452644348, 0.9236111044883728, 0.9359331727027893, 0.9356164336204529, 0.9513213038444519, 0.9587345123291016, 0.9668508172035217, 0.9656121134757996, 0.9682320356369019, 0.9684499502182007, 0.9632152318954468, 0.9833794832229614]\n",
      "Recall of Train ......................................\n",
      "[0.15796703100204468, 0.2884615361690521, 0.4670329689979553, 0.5659340620040894, 0.6744505763053894, 0.7664835453033447, 0.8159340620040894, 0.8626373410224915, 0.8983516693115234, 0.9134615659713745, 0.9230769276618958, 0.9381868243217468, 0.9395604133605957, 0.9574176073074341, 0.9615384340286255, 0.9642857313156128, 0.9629120826721191, 0.9697802066802979, 0.9711538553237915, 0.9752747416496277]\n",
      "AUC of Train ......................................\n",
      "[0.4137345254421234, 0.5552778244018555, 0.6889286041259766, 0.7893654108047485, 0.8458943367004395, 0.8983322978019714, 0.9325215220451355, 0.9519731998443604, 0.9645278453826904, 0.9742956757545471, 0.9802029728889465, 0.9852267503738403, 0.9868752360343933, 0.9917032122612, 0.9943926334381104, 0.9934762716293335, 0.9950476288795471, 0.9952636957168579, 0.9960923194885254, 0.9981228113174438]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.848368053138256\n",
      " Loss:0.397182772308588\n",
      " Precision:0.8615223050117493\n",
      " Recall:0.7986950591206551\n",
      " AUC:0.8965627387166023\n",
      "Score for fold 5: loss of 0.29616737365722656; accuracy of 0.9055555462837219%\n",
      "[[187   1]\n",
      " [ 33 139]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 791.1177875 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:187,FN:33,TP:139,FP:1\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9055555555555556\n",
      " Loss:0.29616737365722656\n",
      " Precision:0.9928571428571429\n",
      " Recall:0.8081395348837209\n",
      " AUC:0.8290697674418605\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.8892013907432557 - Loss: 0.34511960223317145\n",
      "> Fold 1 - Precision: 0.8690730273723603\n",
      "> Fold 1 - Recall: 0.952499994635582\n",
      "> Fold 1 - AUC: 0.9466473579406738\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9361111111111111 - Loss: 0.2307630479335785\n",
      "> Fold 1 - Precision: 0.9875776397515528\n",
      "> Fold 1 - Recall: 0.8833333333333333\n",
      "> Fold 1 - AUC: 0.8889028475711893\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8827777743339539 - Loss: 0.3684374950826168\n",
      "> Fold 2 - Precision: 0.864878585934639\n",
      "> Fold 2 - Recall: 0.942388266324997\n",
      "> Fold 2 - AUC: 0.9266339093446732\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.9666666666666667 - Loss: 0.23313301801681519\n",
      "> Fold 2 - Precision: 0.9886363636363636\n",
      "> Fold 2 - Recall: 0.9456521739130435\n",
      "> Fold 2 - AUC: 0.9456521739130435\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.8827430486679078 - Loss: 0.35098315626382826\n",
      "> Fold 3 - Precision: 0.9023521304130554\n",
      "> Fold 3 - Recall: 0.8355555556714535\n",
      "> Fold 3 - AUC: 0.9228847995400429\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9444444444444444 - Loss: 0.23406656086444855\n",
      "> Fold 3 - Precision: 0.9938271604938271\n",
      "> Fold 3 - Recall: 0.8944444444444445\n",
      "> Fold 3 - AUC: 0.8992424242424243\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9203819394111633 - Loss: 0.3235367514193058\n",
      "> Fold 4 - Precision: 0.9136509299278259\n",
      "> Fold 4 - Recall: 0.9326117277145386\n",
      "> Fold 4 - AUC: 0.9623063683509827\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9722222222222222 - Loss: 0.2329099029302597\n",
      "> Fold 4 - Precision: 1.0\n",
      "> Fold 4 - Recall: 0.9456521739130435\n",
      "> Fold 4 - AUC: 0.9459443665264142\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.848368053138256 - Loss: 0.397182772308588\n",
      "> Fold 5 - Precision: 0.8615223050117493\n",
      "> Fold 5 - Recall: 0.7986950591206551\n",
      "> Fold 5 - AUC: 0.8965627387166023\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9055555555555556 - Loss: 0.29616737365722656\n",
      "> Fold 5 - Precision: 0.9928571428571429\n",
      "> Fold 5 - Recall: 0.8081395348837209\n",
      "> Fold 5 - AUC: 0.8290697674418605\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.8846944412589073 (+- 0.022895406251295724)\n",
      "> Loss: 0.35705195546150204 (+- 0.024668170797753596)\n",
      "> Precision: 0.8822953957319261 (+- 0.021424937420674434)\n",
      "> Recall: 0.8923501206934452 (+- 0.06283265636221445)\n",
      "> AUC: 0.9310070347785949 (+- 0.022341765611639794)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9450000000000001 (+- 0.023856567281759875)\n",
      "> Loss: 0.2454079806804657 (+- 0.02540273406473187)\n",
      "> Precision: 0.9925796613477772 (+- 0.004410544018849417)\n",
      "> Recall: 0.8954443320975172 (+- 0.050619084232081356)\n",
      "> AUC: 0.9017623159389864 (+- 0.0432071651811704)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 894 FN SUM: 93 TP SUM: 807 FP SUM: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b6ceac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1920)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 41s 368ms/step - loss: 0.7422 - accuracy: 0.4826 - binary_crossentropy: 0.7422 - precision: 0.4793 - recall: 0.5014 - auc: 0.4587\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.6475 - accuracy: 0.6069 - binary_crossentropy: 0.6475 - precision: 0.6088 - recall: 0.5798 - auc: 0.6658\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.5690 - accuracy: 0.7431 - binary_crossentropy: 0.5690 - precision: 0.7552 - recall: 0.7129 - auc: 0.8267\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.5042 - accuracy: 0.8417 - binary_crossentropy: 0.5042 - precision: 0.8762 - recall: 0.7927 - auc: 0.9182\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.4487 - accuracy: 0.9021 - binary_crossentropy: 0.4487 - precision: 0.9270 - recall: 0.8711 - auc: 0.9641\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.4042 - accuracy: 0.9382 - binary_crossentropy: 0.4042 - precision: 0.9630 - recall: 0.9104 - auc: 0.9836\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.3682 - accuracy: 0.9507 - binary_crossentropy: 0.3682 - precision: 0.9763 - recall: 0.9230 - auc: 0.9898\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.3370 - accuracy: 0.9618 - binary_crossentropy: 0.3370 - precision: 0.9796 - recall: 0.9426 - auc: 0.9948\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.3096 - accuracy: 0.9729 - binary_crossentropy: 0.3096 - precision: 0.9884 - recall: 0.9566 - auc: 0.9965\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2829 - accuracy: 0.9764 - binary_crossentropy: 0.2829 - precision: 0.9913 - recall: 0.9608 - auc: 0.9977\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2676 - accuracy: 0.9819 - binary_crossentropy: 0.2676 - precision: 0.9943 - recall: 0.9692 - auc: 0.9981\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2421 - accuracy: 0.9903 - binary_crossentropy: 0.2421 - precision: 0.9986 - recall: 0.9818 - auc: 0.9988\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2398 - accuracy: 0.9826 - binary_crossentropy: 0.2398 - precision: 0.9914 - recall: 0.9734 - auc: 0.9972\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.2165 - accuracy: 0.9917 - binary_crossentropy: 0.2165 - precision: 0.9986 - recall: 0.9846 - auc: 0.9991\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2029 - accuracy: 0.9896 - binary_crossentropy: 0.2029 - precision: 0.9986 - recall: 0.9804 - auc: 0.9993\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1956 - accuracy: 0.9896 - binary_crossentropy: 0.1956 - precision: 1.0000 - recall: 0.9790 - auc: 0.9994\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.1937 - accuracy: 0.9875 - binary_crossentropy: 0.1937 - precision: 0.9971 - recall: 0.9776 - auc: 0.9983\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.1741 - accuracy: 0.9903 - binary_crossentropy: 0.1741 - precision: 0.9944 - recall: 0.9860 - auc: 0.9997\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1673 - accuracy: 0.9903 - binary_crossentropy: 0.1673 - precision: 1.0000 - recall: 0.9804 - auc: 0.9994\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1643 - accuracy: 0.9931 - binary_crossentropy: 0.1643 - precision: 0.9986 - recall: 0.9874 - auc: 0.9993\n",
      "Loss of Train ......................................\n",
      "[0.7421990036964417, 0.6475058794021606, 0.5689520835876465, 0.5041751861572266, 0.44866037368774414, 0.40423423051834106, 0.368219256401062, 0.3369606137275696, 0.30964863300323486, 0.2829122543334961, 0.2675668001174927, 0.24211357533931732, 0.2398187220096588, 0.2164837270975113, 0.20292483270168304, 0.1956300139427185, 0.19369563460350037, 0.17413082718849182, 0.1673118621110916, 0.1642720252275467]\n",
      "Accuracy of Train ......................................\n",
      "[0.4826388955116272, 0.6069444417953491, 0.7430555820465088, 0.8416666388511658, 0.9020833373069763, 0.9381944537162781, 0.9506944417953491, 0.9618055820465088, 0.9729166626930237, 0.9763888716697693, 0.9819444417953491, 0.9902777671813965, 0.9826388955116272, 0.9916666746139526, 0.9895833134651184, 0.9895833134651184, 0.987500011920929, 0.9902777671813965, 0.9902777671813965, 0.9930555820465088]\n",
      "Precision of Train ......................................\n",
      "[0.47925034165382385, 0.6088235378265381, 0.7551928758621216, 0.8761609792709351, 0.9269746541976929, 0.9629629850387573, 0.9762963056564331, 0.9796215295791626, 0.9884225726127625, 0.9913294911384583, 0.9942528605461121, 0.9985755085945129, 0.9914407730102539, 0.9985795617103577, 0.9985734820365906, 1.0, 0.9971428513526917, 0.994350254535675, 1.0, 0.9985835552215576]\n",
      "Recall of Train ......................................\n",
      "[0.5014005899429321, 0.5798319578170776, 0.7128851413726807, 0.7927170991897583, 0.8711484670639038, 0.9103641510009766, 0.9229691624641418, 0.9425770044326782, 0.9565826058387756, 0.9607843160629272, 0.9691876769065857, 0.981792688369751, 0.9733893275260925, 0.9845938086509705, 0.9803921580314636, 0.9789915680885315, 0.9775910377502441, 0.9859943985939026, 0.9803921580314636, 0.9873949289321899]\n",
      "AUC of Train ......................................\n",
      "[0.45869794487953186, 0.6657503247261047, 0.8266690969467163, 0.9182137846946716, 0.9641043543815613, 0.9835705161094666, 0.9897977113723755, 0.994833767414093, 0.9965410232543945, 0.9977322220802307, 0.9981104731559753, 0.9988164305686951, 0.9972133040428162, 0.9990518093109131, 0.9993373155593872, 0.9993605017662048, 0.9982618689537048, 0.9997009634971619, 0.9994048476219177, 0.9993093609809875]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9131597220897675\n",
      " Loss:0.3338707767426968\n",
      " Precision:0.9258267059922218\n",
      " Recall:0.8975490123033524\n",
      " AUC:0.9392238810658455\n",
      "Score for fold 1: loss of 0.15452398359775543; accuracy of 0.9916666746139526%\n",
      "[[174   0]\n",
      " [  3 183]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 433.3765518 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:174,FN:3,TP:183,FP:0\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9916666666666667\n",
      " Loss:0.15452398359775543\n",
      " Precision:1.0\n",
      " Recall:0.9838709677419355\n",
      " AUC:0.9834609075997813\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1921      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 33s 366ms/step - loss: 0.6852 - accuracy: 0.5681 - binary_crossentropy: 0.6852 - precision: 0.5355 - recall: 0.9621 - auc: 0.7131\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.5754 - accuracy: 0.6965 - binary_crossentropy: 0.5754 - precision: 0.6287 - recall: 0.9453 - auc: 0.8615\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.4926 - accuracy: 0.8313 - binary_crossentropy: 0.4926 - precision: 0.7658 - recall: 0.9495 - auc: 0.9407\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.4409 - accuracy: 0.8958 - binary_crossentropy: 0.4409 - precision: 0.8488 - recall: 0.9607 - auc: 0.9740\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.3968 - accuracy: 0.9215 - binary_crossentropy: 0.3968 - precision: 0.8958 - recall: 0.9523 - auc: 0.9846\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.3580 - accuracy: 0.9611 - binary_crossentropy: 0.3580 - precision: 0.9531 - recall: 0.9691 - auc: 0.9932\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.3276 - accuracy: 0.9667 - binary_crossentropy: 0.3276 - precision: 0.9561 - recall: 0.9776 - auc: 0.9955\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.3091 - accuracy: 0.9674 - binary_crossentropy: 0.3091 - precision: 0.9717 - recall: 0.9621 - auc: 0.9962\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2765 - accuracy: 0.9847 - binary_crossentropy: 0.2765 - precision: 0.9873 - recall: 0.9818 - auc: 0.9988\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2565 - accuracy: 0.9896 - binary_crossentropy: 0.2565 - precision: 0.9888 - recall: 0.9902 - auc: 0.9994\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2450 - accuracy: 0.9833 - binary_crossentropy: 0.2450 - precision: 0.9900 - recall: 0.9762 - auc: 0.9992\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2260 - accuracy: 0.9917 - binary_crossentropy: 0.2260 - precision: 0.9972 - recall: 0.9860 - auc: 0.9998\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2134 - accuracy: 0.9931 - binary_crossentropy: 0.2134 - precision: 0.9958 - recall: 0.9902 - auc: 0.9995\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2025 - accuracy: 0.9903 - binary_crossentropy: 0.2025 - precision: 0.9929 - recall: 0.9874 - auc: 0.9997\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1893 - accuracy: 0.9868 - binary_crossentropy: 0.1893 - precision: 0.9971 - recall: 0.9762 - auc: 0.9997\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1804 - accuracy: 0.9937 - binary_crossentropy: 0.1804 - precision: 0.9958 - recall: 0.9916 - auc: 0.9999\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1677 - accuracy: 0.9951 - binary_crossentropy: 0.1677 - precision: 0.9972 - recall: 0.9930 - auc: 0.9999\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1630 - accuracy: 0.9924 - binary_crossentropy: 0.1630 - precision: 0.9986 - recall: 0.9860 - auc: 0.9999\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.1508 - accuracy: 0.9965 - binary_crossentropy: 0.1508 - precision: 0.9986 - recall: 0.9944 - auc: 0.9999\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1455 - accuracy: 0.9937 - binary_crossentropy: 0.1455 - precision: 0.9972 - recall: 0.9902 - auc: 0.9999\n",
      "Loss of Train ......................................\n",
      "[0.6851827502250671, 0.5754188299179077, 0.4925616681575775, 0.4408678412437439, 0.3968484699726105, 0.3579891622066498, 0.32760298252105713, 0.30912408232688904, 0.27654922008514404, 0.2564913332462311, 0.24504274129867554, 0.22602081298828125, 0.21340486407279968, 0.20252153277397156, 0.18931801617145538, 0.18041501939296722, 0.16768288612365723, 0.16299675405025482, 0.1507519781589508, 0.145528182387352]\n",
      "Accuracy of Train ......................................\n",
      "[0.5680555701255798, 0.6965277791023254, 0.831250011920929, 0.8958333134651184, 0.9215278029441833, 0.9611111283302307, 0.9666666388511658, 0.9673610925674438, 0.9847221970558167, 0.9895833134651184, 0.9833333492279053, 0.9916666746139526, 0.9930555820465088, 0.9902777671813965, 0.9868055582046509, 0.9937499761581421, 0.9951388835906982, 0.9923611283302307, 0.9965277910232544, 0.9937499761581421]\n",
      "Precision of Train ......................................\n",
      "[0.5355191230773926, 0.628731369972229, 0.7658371329307556, 0.8488227725028992, 0.8957783579826355, 0.9531034231185913, 0.9561042785644531, 0.9716714024543762, 0.9873060584068298, 0.9887955188751221, 0.9900426864624023, 0.9971631169319153, 0.995768666267395, 0.9929478168487549, 0.9971346855163574, 0.9957746267318726, 0.997183084487915, 0.9985795617103577, 0.9985915422439575, 0.9971751570701599]\n",
      "Recall of Train ......................................\n",
      "[0.9621318578720093, 0.9453015327453613, 0.9495091438293457, 0.9607293009757996, 0.9523141384124756, 0.9691444635391235, 0.9775596261024475, 0.9621318578720093, 0.9817671775817871, 0.9901823401451111, 0.9761570692062378, 0.9859747290611267, 0.9901823401451111, 0.9873772859573364, 0.9761570692062378, 0.991584837436676, 0.9929873943328857, 0.9859747290611267, 0.9943898916244507, 0.9901823401451111]\n",
      "AUC of Train ......................................\n",
      "[0.7131364941596985, 0.8615378737449646, 0.940698504447937, 0.9740156531333923, 0.9846031069755554, 0.9932458996772766, 0.995466411113739, 0.9961668252944946, 0.9987817406654358, 0.9993575811386108, 0.9991781711578369, 0.9997703433036804, 0.9995350241661072, 0.9996874332427979, 0.9997279644012451, 0.9999024868011475, 0.9999324679374695, 0.9999006390571594, 0.9999401569366455, 0.9999286532402039]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9349652767181397\n",
      " Loss:0.30011595636606214\n",
      " Precision:0.9246015191078186\n",
      " Recall:0.9760869562625885\n",
      " AUC:0.9727256715297699\n",
      "Score for fold 2: loss of 0.14471276104450226; accuracy of 0.9916666746139526%\n",
      "[[173   0]\n",
      " [  3 184]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 843.9212063 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:173,FN:3,TP:184,FP:0\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9916666666666667\n",
      " Loss:0.14471276104450226\n",
      " Precision:1.0\n",
      " Recall:0.983957219251337\n",
      " AUC:0.9834558823529411\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 32s 369ms/step - loss: 0.6297 - accuracy: 0.6215 - binary_crossentropy: 0.6297 - precision: 0.5761 - recall: 0.9237 - auc: 0.7690\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 18s 412ms/step - loss: 0.5380 - accuracy: 0.7590 - binary_crossentropy: 0.5380 - precision: 0.6932 - recall: 0.9307 - auc: 0.8970\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.4699 - accuracy: 0.8722 - binary_crossentropy: 0.4699 - precision: 0.8286 - recall: 0.9390 - auc: 0.9571\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.4248 - accuracy: 0.9174 - binary_crossentropy: 0.4248 - precision: 0.8940 - recall: 0.9473 - auc: 0.9757\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.3826 - accuracy: 0.9375 - binary_crossentropy: 0.3826 - precision: 0.9328 - recall: 0.9431 - auc: 0.9878\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.3464 - accuracy: 0.9625 - binary_crossentropy: 0.3464 - precision: 0.9626 - recall: 0.9626 - auc: 0.9931\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.3108 - accuracy: 0.9771 - binary_crossentropy: 0.3108 - precision: 0.9859 - recall: 0.9681 - auc: 0.9973\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2907 - accuracy: 0.9806 - binary_crossentropy: 0.2907 - precision: 0.9901 - recall: 0.9709 - auc: 0.9977\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2732 - accuracy: 0.9792 - binary_crossentropy: 0.2732 - precision: 0.9873 - recall: 0.9709 - auc: 0.9985\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2473 - accuracy: 0.9847 - binary_crossentropy: 0.2473 - precision: 0.9916 - recall: 0.9778 - auc: 0.9988\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.2307 - accuracy: 0.9875 - binary_crossentropy: 0.2307 - precision: 0.9944 - recall: 0.9806 - auc: 0.9997\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2159 - accuracy: 0.9903 - binary_crossentropy: 0.2159 - precision: 0.9930 - recall: 0.9875 - auc: 0.9995\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2079 - accuracy: 0.9882 - binary_crossentropy: 0.2079 - precision: 0.9930 - recall: 0.9834 - auc: 0.9995\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1903 - accuracy: 0.9951 - binary_crossentropy: 0.1903 - precision: 0.9986 - recall: 0.9917 - auc: 0.9999\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1744 - accuracy: 0.9965 - binary_crossentropy: 0.1744 - precision: 0.9986 - recall: 0.9945 - auc: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.1763 - accuracy: 0.9924 - binary_crossentropy: 0.1763 - precision: 0.9986 - recall: 0.9861 - auc: 0.9997\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1620 - accuracy: 0.9944 - binary_crossentropy: 0.1620 - precision: 0.9986 - recall: 0.9903 - auc: 0.9999\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.1589 - accuracy: 0.9931 - binary_crossentropy: 0.1589 - precision: 0.9986 - recall: 0.9875 - auc: 0.9997\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1493 - accuracy: 0.9937 - binary_crossentropy: 0.1493 - precision: 0.9986 - recall: 0.9889 - auc: 0.9999\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1430 - accuracy: 0.9958 - binary_crossentropy: 0.1430 - precision: 0.9986 - recall: 0.9931 - auc: 0.9998\n",
      "Loss of Train ......................................\n",
      "[0.6296656131744385, 0.5379976630210876, 0.4698847830295563, 0.42478373646736145, 0.38257718086242676, 0.346377968788147, 0.3107713758945465, 0.29072707891464233, 0.2731937766075134, 0.247273787856102, 0.2307480424642563, 0.21587802469730377, 0.20794759690761566, 0.19033347070217133, 0.17440390586853027, 0.17625929415225983, 0.16198952496051788, 0.15892019867897034, 0.14925234019756317, 0.14298318326473236]\n",
      "Accuracy of Train ......................................\n",
      "[0.6215277910232544, 0.7590277791023254, 0.8722222447395325, 0.9173611402511597, 0.9375, 0.9624999761581421, 0.9770833253860474, 0.980555534362793, 0.9791666865348816, 0.9847221970558167, 0.987500011920929, 0.9902777671813965, 0.988194465637207, 0.9951388835906982, 0.9965277910232544, 0.9923611283302307, 0.9944444298744202, 0.9930555820465088, 0.9937499761581421, 0.9958333373069763]\n",
      "Precision of Train ......................................\n",
      "[0.5761245489120483, 0.6931818127632141, 0.8286413550376892, 0.8939790725708008, 0.9327846169471741, 0.962552011013031, 0.9858757257461548, 0.9900990128517151, 0.9873060584068298, 0.9915611743927002, 0.9943740963935852, 0.9930264949798584, 0.9929971694946289, 0.998603343963623, 0.9986072182655334, 0.9985954761505127, 0.9986013770103455, 0.9985975027084351, 0.9985994100570679, 0.9986053109169006]\n",
      "Recall of Train ......................................\n",
      "[0.9237170815467834, 0.930651843547821, 0.9389736652374268, 0.9472954273223877, 0.9431345462799072, 0.962552011013031, 0.96809983253479, 0.9708737730979919, 0.9708737730979919, 0.9778085947036743, 0.9805825352668762, 0.9875173568725586, 0.9833564758300781, 0.9916782379150391, 0.994452178478241, 0.9861303567886353, 0.9902912378311157, 0.9875173568725586, 0.9889042973518372, 0.9930651783943176]\n",
      "AUC of Train ......................................\n",
      "[0.7689955830574036, 0.8969963192939758, 0.9570726156234741, 0.9756770730018616, 0.9878394603729248, 0.9930941462516785, 0.9973235130310059, 0.9976987838745117, 0.9985185265541077, 0.9988271594047546, 0.999683678150177, 0.9995225667953491, 0.9994550943374634, 0.999889075756073, 0.9999662637710571, 0.9997038841247559, 0.9999285936355591, 0.9997366666793823, 0.9998842477798462, 0.9997965097427368]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9459375023841858\n",
      " Loss:0.2860984273254871\n",
      " Precision:0.9406356394290925\n",
      " Recall:0.9708737879991531\n",
      " AUC:0.9784804880619049\n",
      "Score for fold 3: loss of 0.13143299520015717; accuracy of 0.9972222447395325%\n",
      "[[181   0]\n",
      " [  1 178]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1255.3674151 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:181,FN:1,TP:178,FP:0\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9972222222222222\n",
      " Loss:0.13143299520015717\n",
      " Precision:1.0\n",
      " Recall:0.994413407821229\n",
      " AUC:0.9944594511633618\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 31s 369ms/step - loss: 0.7206 - accuracy: 0.5583 - binary_crossentropy: 0.7206 - precision: 0.5375 - recall: 0.9150 - auc: 0.5905\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.6180 - accuracy: 0.6646 - binary_crossentropy: 0.6180 - precision: 0.6154 - recall: 0.8999 - auc: 0.7633\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.5438 - accuracy: 0.7708 - binary_crossentropy: 0.5438 - precision: 0.7125 - recall: 0.9177 - auc: 0.8712\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.4894 - accuracy: 0.8479 - binary_crossentropy: 0.4894 - precision: 0.8072 - recall: 0.9191 - auc: 0.9267\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 423ms/step - loss: 0.4335 - accuracy: 0.8986 - binary_crossentropy: 0.4335 - precision: 0.8752 - recall: 0.9328 - auc: 0.9637\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.3975 - accuracy: 0.9299 - binary_crossentropy: 0.3975 - precision: 0.9187 - recall: 0.9451 - auc: 0.9801\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.3617 - accuracy: 0.9493 - binary_crossentropy: 0.3617 - precision: 0.9505 - recall: 0.9492 - auc: 0.9874\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.3371 - accuracy: 0.9556 - binary_crossentropy: 0.3371 - precision: 0.9549 - recall: 0.9575 - auc: 0.9915\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.3110 - accuracy: 0.9611 - binary_crossentropy: 0.3110 - precision: 0.9680 - recall: 0.9547 - auc: 0.9945\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.2911 - accuracy: 0.9715 - binary_crossentropy: 0.2911 - precision: 0.9751 - recall: 0.9684 - auc: 0.9965\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2715 - accuracy: 0.9715 - binary_crossentropy: 0.2715 - precision: 0.9725 - recall: 0.9712 - auc: 0.9968\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2495 - accuracy: 0.9819 - binary_crossentropy: 0.2495 - precision: 0.9835 - recall: 0.9808 - auc: 0.9982\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2348 - accuracy: 0.9840 - binary_crossentropy: 0.2348 - precision: 0.9822 - recall: 0.9863 - auc: 0.9989\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2246 - accuracy: 0.9806 - binary_crossentropy: 0.2246 - precision: 0.9888 - recall: 0.9726 - auc: 0.9982\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2141 - accuracy: 0.9826 - binary_crossentropy: 0.2141 - precision: 0.9889 - recall: 0.9767 - auc: 0.9982\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2025 - accuracy: 0.9875 - binary_crossentropy: 0.2025 - precision: 0.9903 - recall: 0.9849 - auc: 0.9989\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1876 - accuracy: 0.9910 - binary_crossentropy: 0.1876 - precision: 0.9958 - recall: 0.9863 - auc: 0.9995\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1805 - accuracy: 0.9875 - binary_crossentropy: 0.1805 - precision: 0.9944 - recall: 0.9808 - auc: 0.9989\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1743 - accuracy: 0.9875 - binary_crossentropy: 0.1743 - precision: 0.9917 - recall: 0.9835 - auc: 0.9993\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1685 - accuracy: 0.9868 - binary_crossentropy: 0.1685 - precision: 0.9903 - recall: 0.9835 - auc: 0.9992\n",
      "Loss of Train ......................................\n",
      "[0.7205732464790344, 0.6180095672607422, 0.5437750220298767, 0.48943185806274414, 0.43352118134498596, 0.3974817097187042, 0.36172354221343994, 0.33706262707710266, 0.3110484480857849, 0.2910732924938202, 0.27150794863700867, 0.2495490461587906, 0.23478201031684875, 0.22457945346832275, 0.2140931636095047, 0.20247787237167358, 0.18763592839241028, 0.1804990917444229, 0.17427515983581543, 0.16848042607307434]\n",
      "Accuracy of Train ......................................\n",
      "[0.5583333373069763, 0.6645833253860474, 0.7708333134651184, 0.8479166626930237, 0.8986111283302307, 0.9298611283302307, 0.949305534362793, 0.9555555582046509, 0.9611111283302307, 0.9715277552604675, 0.9715277552604675, 0.9819444417953491, 0.9840278029441833, 0.980555534362793, 0.9826388955116272, 0.987500011920929, 0.9909722208976746, 0.987500011920929, 0.987500011920929, 0.9868055582046509]\n",
      "Precision of Train ......................................\n",
      "[0.5374698042869568, 0.6153846383094788, 0.7124600410461426, 0.8072289228439331, 0.8751608729362488, 0.918666660785675, 0.9505494236946106, 0.9548563361167908, 0.9680111408233643, 0.9751381278038025, 0.9725274443626404, 0.9834938049316406, 0.9822404384613037, 0.9888424277305603, 0.9888888597488403, 0.9903448224067688, 0.9958449006080627, 0.9944367408752441, 0.9917012453079224, 0.9903314709663391]\n",
      "Recall of Train ......................................\n",
      "[0.9149519801139832, 0.8998628258705139, 0.9176954627037048, 0.9190672039985657, 0.9327846169471741, 0.9451302886009216, 0.9492455124855042, 0.957476019859314, 0.9547325372695923, 0.9684499502182007, 0.9711934328079224, 0.9807956218719482, 0.9862825870513916, 0.9725651741027832, 0.9766803979873657, 0.9849108457565308, 0.9862825870513916, 0.9807956218719482, 0.9835391044616699, 0.9835391044616699]\n",
      "AUC of Train ......................................\n",
      "[0.5905485153198242, 0.7632548809051514, 0.8711836338043213, 0.9267005324363708, 0.9637395143508911, 0.9800557494163513, 0.9873504042625427, 0.9915332198143005, 0.9944734573364258, 0.9964944124221802, 0.9968311190605164, 0.9981796741485596, 0.9989166855812073, 0.998186469078064, 0.9981797337532043, 0.9988877773284912, 0.9995051622390747, 0.9989311695098877, 0.9993267059326172, 0.9991694688796997]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9174305558204651\n",
      " Loss:0.33057902976870535\n",
      " Precision:0.9096789062023163\n",
      " Recall:0.9582990437746048\n",
      " AUC:0.9525724142789841\n",
      "Score for fold 4: loss of 0.1545722633600235; accuracy of 0.9916666746139526%\n",
      "[[188   1]\n",
      " [  2 169]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1665.3286024 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:188,FN:2,TP:169,FP:1\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9916666666666667\n",
      " Loss:0.1545722633600235\n",
      " Precision:0.9941176470588236\n",
      " Recall:0.9883040935672515\n",
      " AUC:0.9888888888888889\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 32s 369ms/step - loss: 0.7299 - accuracy: 0.5028 - binary_crossentropy: 0.7299 - precision: 0.5028 - recall: 0.8714 - auc: 0.5748\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.6188 - accuracy: 0.6250 - binary_crossentropy: 0.6188 - precision: 0.5840 - recall: 0.8797 - auc: 0.7638\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.5353 - accuracy: 0.7681 - binary_crossentropy: 0.5353 - precision: 0.7213 - recall: 0.8769 - auc: 0.8841\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.4727 - accuracy: 0.8771 - binary_crossentropy: 0.4727 - precision: 0.8527 - recall: 0.9129 - auc: 0.9488\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.4238 - accuracy: 0.9229 - binary_crossentropy: 0.4238 - precision: 0.9158 - recall: 0.9322 - auc: 0.9752\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.3785 - accuracy: 0.9493 - binary_crossentropy: 0.3785 - precision: 0.9603 - recall: 0.9378 - auc: 0.9896\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.3483 - accuracy: 0.9535 - binary_crossentropy: 0.3483 - precision: 0.9646 - recall: 0.9419 - auc: 0.9899\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 424ms/step - loss: 0.3259 - accuracy: 0.9604 - binary_crossentropy: 0.3259 - precision: 0.9757 - recall: 0.9447 - auc: 0.9924\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2986 - accuracy: 0.9736 - binary_crossentropy: 0.2986 - precision: 0.9844 - recall: 0.9627 - auc: 0.9966\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2715 - accuracy: 0.9785 - binary_crossentropy: 0.2715 - precision: 0.9943 - recall: 0.9627 - auc: 0.9983\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.2571 - accuracy: 0.9833 - binary_crossentropy: 0.2571 - precision: 0.9916 - recall: 0.9751 - auc: 0.9979\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2471 - accuracy: 0.9785 - binary_crossentropy: 0.2471 - precision: 0.9943 - recall: 0.9627 - auc: 0.9987\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2288 - accuracy: 0.9833 - binary_crossentropy: 0.2288 - precision: 0.9943 - recall: 0.9723 - auc: 0.9987\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2160 - accuracy: 0.9833 - binary_crossentropy: 0.2160 - precision: 0.9972 - recall: 0.9696 - auc: 0.9987\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.2042 - accuracy: 0.9875 - binary_crossentropy: 0.2042 - precision: 0.9986 - recall: 0.9765 - auc: 0.9994\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1927 - accuracy: 0.9861 - binary_crossentropy: 0.1927 - precision: 0.9944 - recall: 0.9779 - auc: 0.9994\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.1791 - accuracy: 0.9903 - binary_crossentropy: 0.1791 - precision: 1.0000 - recall: 0.9806 - auc: 0.9995\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.1705 - accuracy: 0.9882 - binary_crossentropy: 0.1705 - precision: 0.9972 - recall: 0.9793 - auc: 0.9998\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.1605 - accuracy: 0.9889 - binary_crossentropy: 0.1605 - precision: 0.9972 - recall: 0.9806 - auc: 0.9997\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1576 - accuracy: 0.9882 - binary_crossentropy: 0.1576 - precision: 0.9972 - recall: 0.9793 - auc: 0.9997\n",
      "Loss of Train ......................................\n",
      "[0.7298643589019775, 0.6187743544578552, 0.5352655053138733, 0.4726564288139343, 0.4237939119338989, 0.37850508093833923, 0.3482682704925537, 0.32587048411369324, 0.2985602915287018, 0.27153173089027405, 0.25711798667907715, 0.24711331725120544, 0.2288023680448532, 0.21597802639007568, 0.20421810448169708, 0.192656010389328, 0.179117813706398, 0.17047786712646484, 0.16054105758666992, 0.15764592587947845]\n",
      "Accuracy of Train ......................................\n",
      "[0.5027777552604675, 0.625, 0.7680555582046509, 0.8770833611488342, 0.9229166507720947, 0.949305534362793, 0.9534721970558167, 0.9604166746139526, 0.9736111164093018, 0.9784722328186035, 0.9833333492279053, 0.9784722328186035, 0.9833333492279053, 0.9833333492279053, 0.987500011920929, 0.9861111044883728, 0.9902777671813965, 0.988194465637207, 0.9888888597488403, 0.988194465637207]\n",
      "Precision of Train ......................................\n",
      "[0.5027933120727539, 0.584022045135498, 0.721274197101593, 0.8527131676673889, 0.91576087474823, 0.9603399634361267, 0.9645892381668091, 0.9757142663002014, 0.9844412803649902, 0.9942857027053833, 0.9915611743927002, 0.9942857027053833, 0.9943422675132751, 0.9971550703048706, 0.99858558177948, 0.9943740963935852, 1.0, 0.997183084487915, 0.997187077999115, 0.997183084487915]\n",
      "Recall of Train ......................................\n",
      "[0.8713693022727966, 0.8796680569648743, 0.8769018054008484, 0.9128630757331848, 0.932226836681366, 0.9377593398094177, 0.9419087171554565, 0.9446749687194824, 0.9626556038856506, 0.9626556038856506, 0.9751037359237671, 0.9626556038856506, 0.9723374843597412, 0.9695712327957153, 0.97648686170578, 0.977869987487793, 0.9806362390518188, 0.9792531132698059, 0.9806362390518188, 0.9792531132698059]\n",
      "AUC of Train ......................................\n",
      "[0.5747727155685425, 0.7638472318649292, 0.8841453790664673, 0.9487722516059875, 0.9752050042152405, 0.9895763993263245, 0.9899399876594543, 0.9923571348190308, 0.9966145157814026, 0.9983198046684265, 0.9978712797164917, 0.9986544847488403, 0.9987037181854248, 0.9986699223518372, 0.9993952512741089, 0.9994414448738098, 0.9994570016860962, 0.9997627139091492, 0.999691367149353, 0.9996711015701294]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9184375017881393\n",
      " Loss:0.32083794474601746\n",
      " Precision:0.9208895593881607\n",
      " Recall:0.9488243460655212\n",
      " AUC:0.9552434355020523\n",
      "Score for fold 5: loss of 0.14457502961158752; accuracy of 0.9861111044883728%\n",
      "[[183   0]\n",
      " [  5 172]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 2077.5831441 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:183,FN:5,TP:172,FP:0\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9861111111111112\n",
      " Loss:0.14457502961158752\n",
      " Precision:1.0\n",
      " Recall:0.9717514124293786\n",
      " AUC:0.9725778338742638\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9131597220897675 - Loss: 0.3338707767426968\n",
      "> Fold 1 - Precision: 0.9258267059922218\n",
      "> Fold 1 - Recall: 0.8975490123033524\n",
      "> Fold 1 - AUC: 0.9392238810658455\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9916666666666667 - Loss: 0.15452398359775543\n",
      "> Fold 1 - Precision: 1.0\n",
      "> Fold 1 - Recall: 0.9838709677419355\n",
      "> Fold 1 - AUC: 0.9834609075997813\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.9349652767181397 - Loss: 0.30011595636606214\n",
      "> Fold 2 - Precision: 0.9246015191078186\n",
      "> Fold 2 - Recall: 0.9760869562625885\n",
      "> Fold 2 - AUC: 0.9727256715297699\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.9916666666666667 - Loss: 0.14471276104450226\n",
      "> Fold 2 - Precision: 1.0\n",
      "> Fold 2 - Recall: 0.983957219251337\n",
      "> Fold 2 - AUC: 0.9834558823529411\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9459375023841858 - Loss: 0.2860984273254871\n",
      "> Fold 3 - Precision: 0.9406356394290925\n",
      "> Fold 3 - Recall: 0.9708737879991531\n",
      "> Fold 3 - AUC: 0.9784804880619049\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9972222222222222 - Loss: 0.13143299520015717\n",
      "> Fold 3 - Precision: 1.0\n",
      "> Fold 3 - Recall: 0.994413407821229\n",
      "> Fold 3 - AUC: 0.9944594511633618\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9174305558204651 - Loss: 0.33057902976870535\n",
      "> Fold 4 - Precision: 0.9096789062023163\n",
      "> Fold 4 - Recall: 0.9582990437746048\n",
      "> Fold 4 - AUC: 0.9525724142789841\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9916666666666667 - Loss: 0.1545722633600235\n",
      "> Fold 4 - Precision: 0.9941176470588236\n",
      "> Fold 4 - Recall: 0.9883040935672515\n",
      "> Fold 4 - AUC: 0.9888888888888889\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9184375017881393 - Loss: 0.32083794474601746\n",
      "> Fold 5 - Precision: 0.9208895593881607\n",
      "> Fold 5 - Recall: 0.9488243460655212\n",
      "> Fold 5 - AUC: 0.9552434355020523\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9861111111111112 - Loss: 0.14457502961158752\n",
      "> Fold 5 - Precision: 1.0\n",
      "> Fold 5 - Recall: 0.9717514124293786\n",
      "> Fold 5 - AUC: 0.9725778338742638\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9259861117601395 (+- 0.012436870290380674)\n",
      "> Loss: 0.3143004269897938 (+- 0.018369989810767647)\n",
      "> Precision: 0.924326466023922 (+- 0.009946646141004737)\n",
      "> Recall: 0.950326629281044 (+- 0.028060909746991304)\n",
      "> AUC: 0.9596491780877112 (+- 0.014228821653611399)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9916666666666668 (+- 0.0035136418446315197)\n",
      "> Loss: 0.14596340656280518 (+- 0.008509059333031165)\n",
      "> Precision: 0.9988235294117647 (+- 0.00235294117647058)\n",
      "> Recall: 0.9844594201622263 (+- 0.007429068938310476)\n",
      "> AUC: 0.9845685927758474 (+- 0.007248964451791065)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 899 FN SUM: 14 TP SUM: 886 FP SUM: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2, DenseNet201\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Colonscopy/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(DenseNet201(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d71e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
