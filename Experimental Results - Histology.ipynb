{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18013032",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e227ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 8s 94ms/step - loss: 0.6815 - accuracy: 0.5597 - binary_crossentropy: 0.6815 - precision: 0.5614 - recall: 0.5738 - auc: 0.5876\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 4s 97ms/step - loss: 0.6375 - accuracy: 0.6486 - binary_crossentropy: 0.6375 - precision: 0.6466 - recall: 0.6662 - auc: 0.7039\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 100ms/step - loss: 0.6005 - accuracy: 0.7125 - binary_crossentropy: 0.6005 - precision: 0.7212 - recall: 0.6993 - auc: 0.7933\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 102ms/step - loss: 0.5684 - accuracy: 0.7660 - binary_crossentropy: 0.5684 - precision: 0.7546 - recall: 0.7931 - auc: 0.8447\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 104ms/step - loss: 0.5388 - accuracy: 0.8042 - binary_crossentropy: 0.5388 - precision: 0.8124 - recall: 0.7945 - auc: 0.8824\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 105ms/step - loss: 0.5137 - accuracy: 0.8153 - binary_crossentropy: 0.5137 - precision: 0.8056 - recall: 0.8345 - auc: 0.9051\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 105ms/step - loss: 0.4942 - accuracy: 0.8368 - binary_crossentropy: 0.4942 - precision: 0.8258 - recall: 0.8566 - auc: 0.9132\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 106ms/step - loss: 0.4722 - accuracy: 0.8528 - binary_crossentropy: 0.4722 - precision: 0.8597 - recall: 0.8455 - auc: 0.9291\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 106ms/step - loss: 0.4581 - accuracy: 0.8542 - binary_crossentropy: 0.4581 - precision: 0.8447 - recall: 0.8703 - auc: 0.9332\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 106ms/step - loss: 0.4413 - accuracy: 0.8583 - binary_crossentropy: 0.4413 - precision: 0.8564 - recall: 0.8634 - auc: 0.9396\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 107ms/step - loss: 0.4293 - accuracy: 0.8625 - binary_crossentropy: 0.4293 - precision: 0.8605 - recall: 0.8676 - auc: 0.9418\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 107ms/step - loss: 0.4179 - accuracy: 0.8625 - binary_crossentropy: 0.4179 - precision: 0.8518 - recall: 0.8800 - auc: 0.9462\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.4059 - accuracy: 0.8708 - binary_crossentropy: 0.4059 - precision: 0.8608 - recall: 0.8869 - auc: 0.9492\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.3963 - accuracy: 0.8778 - binary_crossentropy: 0.3963 - precision: 0.8725 - recall: 0.8869 - auc: 0.9514\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.3884 - accuracy: 0.8715 - binary_crossentropy: 0.3884 - precision: 0.8678 - recall: 0.8786 - auc: 0.9536\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3795 - accuracy: 0.8771 - binary_crossentropy: 0.3795 - precision: 0.8703 - recall: 0.8883 - auc: 0.9564\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3708 - accuracy: 0.8799 - binary_crossentropy: 0.3708 - precision: 0.8660 - recall: 0.9007 - auc: 0.9568\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3654 - accuracy: 0.8854 - binary_crossentropy: 0.3654 - precision: 0.8794 - recall: 0.8952 - auc: 0.9578\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3584 - accuracy: 0.8819 - binary_crossentropy: 0.3584 - precision: 0.8735 - recall: 0.8952 - auc: 0.9599\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3509 - accuracy: 0.8813 - binary_crossentropy: 0.3509 - precision: 0.8774 - recall: 0.8883 - auc: 0.9611\n",
      "Loss of Train ......................................\n",
      "[0.6815466284751892, 0.6374596357345581, 0.6005021929740906, 0.5683937072753906, 0.5388299822807312, 0.513666033744812, 0.49419310688972473, 0.4722398519515991, 0.4580930173397064, 0.4412938058376312, 0.42933306097984314, 0.4179099500179291, 0.40592873096466064, 0.39630988240242004, 0.3883984386920929, 0.37948280572891235, 0.37083303928375244, 0.3654068410396576, 0.3584149181842804, 0.35090017318725586]\n",
      "Accuracy of Train ......................................\n",
      "[0.5597222447395325, 0.6486111283302307, 0.7124999761581421, 0.7659721970558167, 0.8041666746139526, 0.8152777552604675, 0.8368055820465088, 0.8527777791023254, 0.8541666865348816, 0.8583333492279053, 0.862500011920929, 0.862500011920929, 0.8708333373069763, 0.8777777552604675, 0.8715277910232544, 0.8770833611488342, 0.8798611164093018, 0.8854166865348816, 0.8819444179534912, 0.8812500238418579]\n",
      "Precision of Train ......................................\n",
      "[0.5614035129547119, 0.6465863585472107, 0.721194863319397, 0.7545931935310364, 0.8124118447303772, 0.8055925369262695, 0.8257978558540344, 0.8597475290298462, 0.8447121977806091, 0.8563611507415771, 0.8604651093482971, 0.851802408695221, 0.860776424407959, 0.872455894947052, 0.8678473830223083, 0.8702702522277832, 0.866047739982605, 0.8794037699699402, 0.8734858632087708, 0.8773841857910156]\n",
      "Recall of Train ......................................\n",
      "[0.5737931132316589, 0.6662068963050842, 0.6993103623390198, 0.7931034564971924, 0.7944827675819397, 0.834482729434967, 0.8565517067909241, 0.8455172181129456, 0.8703448176383972, 0.8634482622146606, 0.8675861954689026, 0.8799999952316284, 0.886896550655365, 0.886896550655365, 0.8786206841468811, 0.8882758617401123, 0.9006896615028381, 0.8951724171638489, 0.8951724171638489, 0.8882758617401123]\n",
      "AUC of Train ......................................\n",
      "[0.5876209735870361, 0.7038610577583313, 0.793321430683136, 0.8447310924530029, 0.8823573589324951, 0.9051313996315002, 0.9131873250007629, 0.929145872592926, 0.9331777095794678, 0.9395660161972046, 0.9417796730995178, 0.9462010860443115, 0.9492316842079163, 0.9514126181602478, 0.9536252617835999, 0.9564244151115417, 0.9568053483963013, 0.9577564597129822, 0.9598697423934937, 0.9611295461654663]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8229513943195343\n",
      " Loss:0.4634567901492119\n",
      " Precision:0.8184170037508011\n",
      " Recall:0.8332413762807847\n",
      " AUC:0.8983168035745621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 0.3524661064147949; accuracy of 0.8777777552604675%\n",
      "[[157  28]\n",
      " [ 16 159]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 112.77973109999999 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:157,FN:16,TP:159,FP:28\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8777777777777778\n",
      " Loss:0.3524661064147949\n",
      " Precision:0.8502673796791443\n",
      " Recall:0.9085714285714286\n",
      " AUC:0.9080429397192403\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 109ms/step - loss: 0.6815 - accuracy: 0.5743 - binary_crossentropy: 0.6815 - precision: 0.5712 - recall: 0.5672 - auc: 0.5946\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.6309 - accuracy: 0.6556 - binary_crossentropy: 0.6309 - precision: 0.6603 - recall: 0.6289 - auc: 0.7123\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.5942 - accuracy: 0.7201 - binary_crossentropy: 0.5942 - precision: 0.7263 - recall: 0.6989 - auc: 0.7889\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.5664 - accuracy: 0.7549 - binary_crossentropy: 0.5664 - precision: 0.7682 - recall: 0.7241 - auc: 0.8330\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.5377 - accuracy: 0.7854 - binary_crossentropy: 0.5377 - precision: 0.7824 - recall: 0.7857 - auc: 0.8684\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.5117 - accuracy: 0.8014 - binary_crossentropy: 0.5117 - precision: 0.7981 - recall: 0.8025 - auc: 0.8910\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 111ms/step - loss: 0.4911 - accuracy: 0.8215 - binary_crossentropy: 0.4911 - precision: 0.8223 - recall: 0.8165 - auc: 0.9076\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.4729 - accuracy: 0.8333 - binary_crossentropy: 0.4729 - precision: 0.8273 - recall: 0.8389 - auc: 0.9186\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.4546 - accuracy: 0.8424 - binary_crossentropy: 0.4546 - precision: 0.8406 - recall: 0.8417 - auc: 0.9275\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.4402 - accuracy: 0.8507 - binary_crossentropy: 0.4402 - precision: 0.8413 - recall: 0.8613 - auc: 0.9315\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.4265 - accuracy: 0.8646 - binary_crossentropy: 0.4265 - precision: 0.8650 - recall: 0.8613 - auc: 0.9388\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.4158 - accuracy: 0.8715 - binary_crossentropy: 0.4158 - precision: 0.8599 - recall: 0.8852 - auc: 0.9440\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.4053 - accuracy: 0.8674 - binary_crossentropy: 0.4053 - precision: 0.8647 - recall: 0.8683 - auc: 0.9449\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.3966 - accuracy: 0.8764 - binary_crossentropy: 0.3966 - precision: 0.8722 - recall: 0.8796 - auc: 0.9483\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.3853 - accuracy: 0.8750 - binary_crossentropy: 0.3853 - precision: 0.8688 - recall: 0.8810 - auc: 0.9523\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.3787 - accuracy: 0.8840 - binary_crossentropy: 0.3787 - precision: 0.8783 - recall: 0.8894 - auc: 0.9533\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.3698 - accuracy: 0.8813 - binary_crossentropy: 0.3698 - precision: 0.8735 - recall: 0.8894 - auc: 0.9561\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.3623 - accuracy: 0.8854 - binary_crossentropy: 0.3623 - precision: 0.8828 - recall: 0.8866 - auc: 0.9572\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3553 - accuracy: 0.8847 - binary_crossentropy: 0.3553 - precision: 0.8774 - recall: 0.8922 - auc: 0.9594\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3493 - accuracy: 0.8868 - binary_crossentropy: 0.3493 - precision: 0.8864 - recall: 0.8852 - auc: 0.9599\n",
      "Loss of Train ......................................\n",
      "[0.6814988851547241, 0.6308554410934448, 0.5942383408546448, 0.566351592540741, 0.5377273559570312, 0.5116583108901978, 0.4911227226257324, 0.4728884696960449, 0.45462310314178467, 0.44015464186668396, 0.4265226125717163, 0.41581523418426514, 0.40529942512512207, 0.3966456949710846, 0.38526082038879395, 0.3786657154560089, 0.3698066771030426, 0.36230289936065674, 0.3552773892879486, 0.34926119446754456]\n",
      "Accuracy of Train ......................................\n",
      "[0.574305534362793, 0.6555555462837219, 0.7201389074325562, 0.7548611164093018, 0.7854166626930237, 0.8013888597488403, 0.8215277791023254, 0.8333333134651184, 0.8423610925674438, 0.8506944179534912, 0.8645833134651184, 0.8715277910232544, 0.8673611283302307, 0.8763889074325562, 0.875, 0.8840277791023254, 0.8812500238418579, 0.8854166865348816, 0.8847222328186035, 0.886805534362793]\n",
      "Precision of Train ......................................\n",
      "[0.5712270736694336, 0.6602941155433655, 0.7263464331626892, 0.7682020664215088, 0.7824267745018005, 0.7980501651763916, 0.8222849369049072, 0.8273480534553528, 0.8405594229698181, 0.8413132429122925, 0.8649789094924927, 0.8598639369010925, 0.8647140860557556, 0.8722222447395325, 0.8687845468521118, 0.8782849311828613, 0.8734525442123413, 0.8828451633453369, 0.8774104714393616, 0.8863955140113831]\n",
      "Recall of Train ......................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5672268867492676, 0.6288515329360962, 0.6988795399665833, 0.7240896224975586, 0.7857142686843872, 0.8025209903717041, 0.8165265917778015, 0.8389355540275574, 0.8417366743087769, 0.8613445162773132, 0.8613445162773132, 0.8851540684700012, 0.8683473467826843, 0.8795518279075623, 0.8809523582458496, 0.8893557190895081, 0.8893557190895081, 0.8865545988082886, 0.8921568393707275, 0.8851540684700012]\n",
      "AUC of Train ......................................\n",
      "[0.59458988904953, 0.712315022945404, 0.7889167070388794, 0.8330034613609314, 0.8684197068214417, 0.8910340666770935, 0.9076479077339172, 0.9185812473297119, 0.9275007843971252, 0.9314873218536377, 0.9388335347175598, 0.9439592957496643, 0.94487464427948, 0.9482641816139221, 0.9522545337677002, 0.9532577991485596, 0.9561042785644531, 0.9572298526763916, 0.9593799114227295, 0.9599122405052185]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8208333313465118\n",
      " Loss:0.46129882633686065\n",
      " Precision:0.8183502316474914\n",
      " Recall:0.8191876620054245\n",
      " AUC:0.8943783193826675\n",
      "Score for fold 2: loss of 0.36118707060813904; accuracy of 0.8694444298744202%\n",
      "[[145  29]\n",
      " [ 18 168]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 220.9903991 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:145,FN:18,TP:168,FP:29\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8694444444444445\n",
      " Loss:0.36118707060813904\n",
      " Precision:0.8527918781725888\n",
      " Recall:0.9032258064516129\n",
      " AUC:0.896398179299426\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 109ms/step - loss: 0.6758 - accuracy: 0.5750 - binary_crossentropy: 0.6758 - precision: 0.5663 - recall: 0.5791 - auc: 0.6113\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.6315 - accuracy: 0.6535 - binary_crossentropy: 0.6315 - precision: 0.6557 - recall: 0.6215 - auc: 0.7158\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.5956 - accuracy: 0.7118 - binary_crossentropy: 0.5956 - precision: 0.7066 - recall: 0.7076 - auc: 0.7872\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.5603 - accuracy: 0.7583 - binary_crossentropy: 0.5603 - precision: 0.7564 - recall: 0.7500 - auc: 0.8398\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.5347 - accuracy: 0.7812 - binary_crossentropy: 0.5347 - precision: 0.7779 - recall: 0.7768 - auc: 0.8665\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.5116 - accuracy: 0.8076 - binary_crossentropy: 0.5116 - precision: 0.8014 - recall: 0.8093 - auc: 0.8915\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4887 - accuracy: 0.8208 - binary_crossentropy: 0.4887 - precision: 0.8160 - recall: 0.8206 - auc: 0.9046\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4727 - accuracy: 0.8313 - binary_crossentropy: 0.4727 - precision: 0.8298 - recall: 0.8263 - auc: 0.9139\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4516 - accuracy: 0.8417 - binary_crossentropy: 0.4516 - precision: 0.8399 - recall: 0.8376 - auc: 0.9215\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4408 - accuracy: 0.8438 - binary_crossentropy: 0.4408 - precision: 0.8378 - recall: 0.8460 - auc: 0.9313\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4286 - accuracy: 0.8479 - binary_crossentropy: 0.4286 - precision: 0.8401 - recall: 0.8531 - auc: 0.9320\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4159 - accuracy: 0.8583 - binary_crossentropy: 0.4159 - precision: 0.8529 - recall: 0.8602 - auc: 0.9388\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4036 - accuracy: 0.8611 - binary_crossentropy: 0.4036 - precision: 0.8518 - recall: 0.8686 - auc: 0.9419\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3968 - accuracy: 0.8687 - binary_crossentropy: 0.3968 - precision: 0.8670 - recall: 0.8658 - auc: 0.9451\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.3864 - accuracy: 0.8715 - binary_crossentropy: 0.3864 - precision: 0.8688 - recall: 0.8701 - auc: 0.9476\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.3788 - accuracy: 0.8694 - binary_crossentropy: 0.3788 - precision: 0.8631 - recall: 0.8729 - auc: 0.9504\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.3711 - accuracy: 0.8757 - binary_crossentropy: 0.3711 - precision: 0.8720 - recall: 0.8757 - auc: 0.9514\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3647 - accuracy: 0.8736 - binary_crossentropy: 0.3647 - precision: 0.8683 - recall: 0.8757 - auc: 0.9521\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3571 - accuracy: 0.8854 - binary_crossentropy: 0.3571 - precision: 0.8797 - recall: 0.8884 - auc: 0.9546\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3507 - accuracy: 0.8813 - binary_crossentropy: 0.3507 - precision: 0.8734 - recall: 0.8870 - auc: 0.9560\n",
      "Loss of Train ......................................\n",
      "[0.6758076548576355, 0.6314989924430847, 0.595553994178772, 0.5603330731391907, 0.5347471237182617, 0.5116092562675476, 0.4886622130870819, 0.47265195846557617, 0.4515523612499237, 0.4407811164855957, 0.42856496572494507, 0.4159106910228729, 0.4036369025707245, 0.3967876434326172, 0.38635602593421936, 0.37877020239830017, 0.3710828125476837, 0.3647416830062866, 0.35714372992515564, 0.3507063686847687]\n",
      "Accuracy of Train ......................................\n",
      "[0.574999988079071, 0.6534722447395325, 0.7118055820465088, 0.7583333253860474, 0.78125, 0.8076388835906982, 0.8208333253860474, 0.831250011920929, 0.8416666388511658, 0.84375, 0.8479166626930237, 0.8583333492279053, 0.8611111044883728, 0.8687499761581421, 0.8715277910232544, 0.8694444298744202, 0.8756944537162781, 0.8736110925674438, 0.8854166865348816, 0.8812500238418579]\n",
      "Precision of Train ......................................\n",
      "[0.5662983655929565, 0.6557376980781555, 0.7066290378570557, 0.7564102411270142, 0.7779349088668823, 0.8013985753059387, 0.8160112500190735, 0.8297872543334961, 0.8399433493614197, 0.8377622365951538, 0.8400556445121765, 0.8529411554336548, 0.8518005609512329, 0.8670438528060913, 0.8688293099403381, 0.8631284832954407, 0.8720112442970276, 0.8683473467826843, 0.8797202706336975, 0.8734353184700012]\n",
      "Recall of Train ......................................\n",
      "[0.5790960192680359, 0.6214689016342163, 0.7076271176338196, 0.75, 0.7768361568450928, 0.8093220591545105, 0.8206214904785156, 0.8262711763381958, 0.8375706076622009, 0.846045196056366, 0.8531073331832886, 0.8601694703102112, 0.8686440587043762, 0.8658192157745361, 0.8700565099716187, 0.8728813529014587, 0.8757061958312988, 0.8757061958312988, 0.8884180784225464, 0.887005627155304]\n",
      "AUC of Train ......................................\n",
      "[0.6112703084945679, 0.7158054709434509, 0.7871910929679871, 0.8397895693778992, 0.8665369749069214, 0.891451358795166, 0.9046435952186584, 0.913919985294342, 0.9214596748352051, 0.9313099384307861, 0.9320335388183594, 0.9388430118560791, 0.9419408440589905, 0.9451024532318115, 0.9475934505462646, 0.9503719806671143, 0.9514198303222656, 0.9521423578262329, 0.9545764327049255, 0.9559860825538635]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.815902778506279\n",
      " Loss:0.4608449384570122\n",
      " Precision:0.8112613052129746\n",
      " Recall:0.8146186381578445\n",
      " AUC:0.8926693975925446\n",
      "Score for fold 3: loss of 0.3794865906238556; accuracy of 0.8416666388511658%\n",
      "[[139  29]\n",
      " [ 28 164]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 326.5866229 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:139,FN:28,TP:164,FP:29\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8416666666666667\n",
      " Loss:0.3794865906238556\n",
      " Precision:0.8497409326424871\n",
      " Recall:0.8541666666666666\n",
      " AUC:0.843250998003992\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 108ms/step - loss: 0.7176 - accuracy: 0.5042 - binary_crossentropy: 0.7176 - precision: 0.5074 - recall: 0.5702 - auc: 0.5091\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.6603 - accuracy: 0.6167 - binary_crossentropy: 0.6603 - precision: 0.6145 - recall: 0.6433 - auc: 0.6505\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.6171 - accuracy: 0.6896 - binary_crossentropy: 0.6171 - precision: 0.6883 - recall: 0.7025 - auc: 0.7457\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.5806 - accuracy: 0.7319 - binary_crossentropy: 0.5806 - precision: 0.7231 - recall: 0.7590 - auc: 0.8127\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.5475 - accuracy: 0.7854 - binary_crossentropy: 0.5475 - precision: 0.7776 - recall: 0.8044 - auc: 0.8631\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.5175 - accuracy: 0.8042 - binary_crossentropy: 0.5175 - precision: 0.8049 - recall: 0.8072 - auc: 0.8872\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4962 - accuracy: 0.8285 - binary_crossentropy: 0.4962 - precision: 0.8131 - recall: 0.8567 - auc: 0.9069\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4763 - accuracy: 0.8382 - binary_crossentropy: 0.4763 - precision: 0.8372 - recall: 0.8430 - auc: 0.9166\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4571 - accuracy: 0.8528 - binary_crossentropy: 0.4571 - precision: 0.8373 - recall: 0.8788 - auc: 0.9290\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4430 - accuracy: 0.8528 - binary_crossentropy: 0.4430 - precision: 0.8464 - recall: 0.8650 - auc: 0.9332\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4281 - accuracy: 0.8639 - binary_crossentropy: 0.4281 - precision: 0.8543 - recall: 0.8802 - auc: 0.9395\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4152 - accuracy: 0.8764 - binary_crossentropy: 0.4152 - precision: 0.8733 - recall: 0.8829 - auc: 0.9438\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.4041 - accuracy: 0.8771 - binary_crossentropy: 0.4041 - precision: 0.8714 - recall: 0.8871 - auc: 0.9473\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3927 - accuracy: 0.8764 - binary_crossentropy: 0.3927 - precision: 0.8663 - recall: 0.8926 - auc: 0.9512\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3860 - accuracy: 0.8736 - binary_crossentropy: 0.3860 - precision: 0.8676 - recall: 0.8843 - auc: 0.9510\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3759 - accuracy: 0.8792 - binary_crossentropy: 0.3759 - precision: 0.8710 - recall: 0.8926 - auc: 0.9544\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3684 - accuracy: 0.8854 - binary_crossentropy: 0.3684 - precision: 0.8837 - recall: 0.8898 - auc: 0.9561\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3597 - accuracy: 0.8813 - binary_crossentropy: 0.3597 - precision: 0.8776 - recall: 0.8884 - auc: 0.9582\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.3519 - accuracy: 0.8951 - binary_crossentropy: 0.3519 - precision: 0.8818 - recall: 0.9146 - auc: 0.9598\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3458 - accuracy: 0.8931 - binary_crossentropy: 0.3458 - precision: 0.8854 - recall: 0.9050 - auc: 0.9615\n",
      "Loss of Train ......................................\n",
      "[0.7176383137702942, 0.6602855920791626, 0.6170898675918579, 0.5806108117103577, 0.5474725365638733, 0.5175124406814575, 0.49618399143218994, 0.4763484597206116, 0.45710644125938416, 0.4429902732372284, 0.42810091376304626, 0.4152061343193054, 0.40409308671951294, 0.392729789018631, 0.3860178291797638, 0.3759014904499054, 0.3684094250202179, 0.35968470573425293, 0.3518945574760437, 0.3457551598548889]\n",
      "Accuracy of Train ......................................\n",
      "[0.5041666626930237, 0.6166666746139526, 0.6895833611488342, 0.7319444417953491, 0.7854166626930237, 0.8041666746139526, 0.8284721970558167, 0.8381944298744202, 0.8527777791023254, 0.8527777791023254, 0.8638888597488403, 0.8763889074325562, 0.8770833611488342, 0.8763889074325562, 0.8736110925674438, 0.8791666626930237, 0.8854166865348816, 0.8812500238418579, 0.8951388597488403, 0.8930555582046509]\n",
      "Precision of Train ......................................\n",
      "[0.5073529481887817, 0.6144737005233765, 0.6882591247558594, 0.7230970859527588, 0.7776298522949219, 0.8049450516700745, 0.8130719065666199, 0.8372092843055725, 0.8372703194618225, 0.8463611602783203, 0.8542780876159668, 0.8732969760894775, 0.8714479207992554, 0.866310179233551, 0.8675675392150879, 0.8709677457809448, 0.8837209343910217, 0.8775510191917419, 0.8818061351776123, 0.8854447603225708]\n",
      "Recall of Train ......................................\n",
      "[0.5702479481697083, 0.6432507038116455, 0.702479362487793, 0.7589531540870667, 0.8044077157974243, 0.8071625232696533, 0.8567492961883545, 0.8429751992225647, 0.8787878751754761, 0.8650137782096863, 0.8801652789115906, 0.8829200863838196, 0.8870523571968079, 0.8925619721412659, 0.8842975497245789, 0.8925619721412659, 0.8898071646690369, 0.8884297609329224, 0.9146005511283875, 0.9049586653709412]\n",
      "AUC of Train ......................................\n",
      "[0.5090572834014893, 0.6504859328269958, 0.7457413673400879, 0.8127011060714722, 0.8631415367126465, 0.8872105479240417, 0.9069110751152039, 0.9166319370269775, 0.9290421605110168, 0.933215856552124, 0.9395270347595215, 0.9438223242759705, 0.9472503662109375, 0.9512321949005127, 0.9510073661804199, 0.9543699026107788, 0.9560695290565491, 0.9581519961357117, 0.9597734212875366, 0.9615049362182617]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8152777791023255\n",
      " Loss:0.46705159097909926\n",
      " Precision:0.8091030865907669\n",
      " Recall:0.8323691457509994\n",
      " AUC:0.8838423937559128\n",
      "Score for fold 4: loss of 0.36135029792785645; accuracy of 0.8861111402511597%\n",
      "[[164  22]\n",
      " [ 19 155]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 431.9018258 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:164,FN:19,TP:155,FP:22\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8861111111111111\n",
      " Loss:0.36135029792785645\n",
      " Precision:0.8757062146892656\n",
      " Recall:0.8908045977011494\n",
      " AUC:0.8934897305445637\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4096)              16781312  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 108ms/step - loss: 0.6761 - accuracy: 0.5701 - binary_crossentropy: 0.6761 - precision: 0.5694 - recall: 0.6094 - auc: 0.6075\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.6275 - accuracy: 0.6715 - binary_crossentropy: 0.6275 - precision: 0.6680 - recall: 0.6946 - auc: 0.7306\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.5907 - accuracy: 0.7236 - binary_crossentropy: 0.5907 - precision: 0.7150 - recall: 0.7524 - auc: 0.7979\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.5580 - accuracy: 0.7611 - binary_crossentropy: 0.5580 - precision: 0.7570 - recall: 0.7758 - auc: 0.8473\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.5295 - accuracy: 0.7986 - binary_crossentropy: 0.5295 - precision: 0.7886 - recall: 0.8212 - auc: 0.8792\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.5064 - accuracy: 0.8201 - binary_crossentropy: 0.5064 - precision: 0.8120 - recall: 0.8377 - auc: 0.8957\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.4884 - accuracy: 0.8347 - binary_crossentropy: 0.4884 - precision: 0.8221 - recall: 0.8583 - auc: 0.9064\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 111ms/step - loss: 0.4668 - accuracy: 0.8417 - binary_crossentropy: 0.4668 - precision: 0.8322 - recall: 0.8597 - auc: 0.9192\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.4514 - accuracy: 0.8528 - binary_crossentropy: 0.4514 - precision: 0.8429 - recall: 0.8707 - auc: 0.9279\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.4343 - accuracy: 0.8556 - binary_crossentropy: 0.4343 - precision: 0.8446 - recall: 0.8748 - auc: 0.9331\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.4257 - accuracy: 0.8653 - binary_crossentropy: 0.4257 - precision: 0.8587 - recall: 0.8776 - auc: 0.9363\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.4134 - accuracy: 0.8694 - binary_crossentropy: 0.4134 - precision: 0.8657 - recall: 0.8776 - auc: 0.9403\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.4020 - accuracy: 0.8687 - binary_crossentropy: 0.4020 - precision: 0.8625 - recall: 0.8803 - auc: 0.9430\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 111ms/step - loss: 0.3923 - accuracy: 0.8701 - binary_crossentropy: 0.3923 - precision: 0.8610 - recall: 0.8858 - auc: 0.9469\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 111ms/step - loss: 0.3833 - accuracy: 0.8806 - binary_crossentropy: 0.3833 - precision: 0.8765 - recall: 0.8886 - auc: 0.9491\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 111ms/step - loss: 0.3760 - accuracy: 0.8813 - binary_crossentropy: 0.3760 - precision: 0.8757 - recall: 0.8913 - auc: 0.9503\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.3675 - accuracy: 0.8813 - binary_crossentropy: 0.3675 - precision: 0.8798 - recall: 0.8858 - auc: 0.9521\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.3605 - accuracy: 0.8875 - binary_crossentropy: 0.3605 - precision: 0.8844 - recall: 0.8941 - auc: 0.9547\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 111ms/step - loss: 0.3548 - accuracy: 0.8896 - binary_crossentropy: 0.3548 - precision: 0.8880 - recall: 0.8941 - auc: 0.9555\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.3472 - accuracy: 0.8958 - binary_crossentropy: 0.3472 - precision: 0.8936 - recall: 0.9010 - auc: 0.9575\n",
      "Loss of Train ......................................\n",
      "[0.6761484146118164, 0.6275428533554077, 0.5907016396522522, 0.558040976524353, 0.52951979637146, 0.5064319372177124, 0.48844489455223083, 0.4667641818523407, 0.4514010548591614, 0.43428391218185425, 0.42571309208869934, 0.4133532643318176, 0.402039110660553, 0.39227184653282166, 0.3833170235157013, 0.37599918246269226, 0.367467999458313, 0.36054903268814087, 0.35479211807250977, 0.34715259075164795]\n",
      "Accuracy of Train ......................................\n",
      "[0.5701388716697693, 0.6715278029441833, 0.7236111164093018, 0.7611111402511597, 0.7986111044883728, 0.8201388716697693, 0.8347222208976746, 0.8416666388511658, 0.8527777791023254, 0.855555534362793, 0.8652777671813965, 0.8694444298744202, 0.8687499761581421, 0.8701388835906982, 0.8805555701255798, 0.8812500238418579, 0.8812500238418579, 0.887499988079071, 0.8895833492279053, 0.8958333134651184]\n",
      "Precision of Train ......................................\n",
      "[0.5694087147712708, 0.6679894328117371, 0.715032696723938, 0.7570469975471497, 0.7886393666267395, 0.8119999766349792, 0.8221343755722046, 0.8322237133979797, 0.842876136302948, 0.8446215391159058, 0.8586810231208801, 0.8656716346740723, 0.862533688545227, 0.8609625697135925, 0.8765264749526978, 0.8756756782531738, 0.8797814249992371, 0.884353756904602, 0.8879781365394592, 0.8935880064964294]\n",
      "Recall of Train ......................................\n",
      "[0.6093534827232361, 0.6946355104446411, 0.7524071335792542, 0.7757909297943115, 0.8211829662322998, 0.8376891613006592, 0.8583218455314636, 0.8596974015235901, 0.8707014918327332, 0.874828040599823, 0.8775790929794312, 0.8775790929794312, 0.8803301453590393, 0.8858321905136108, 0.888583242893219, 0.8913342356681824, 0.8858321905136108, 0.8940852880477905, 0.8940852880477905, 0.9009628891944885]\n",
      "AUC of Train ......................................\n",
      "[0.6074600219726562, 0.7306342720985413, 0.797877311706543, 0.8472502827644348, 0.8792266845703125, 0.8957192897796631, 0.9063993096351624, 0.9191792607307434, 0.9279069900512695, 0.9330636858940125, 0.9363173246383667, 0.9402884840965271, 0.94302898645401, 0.9469143152236938, 0.9490982294082642, 0.9502605199813843, 0.9520643353462219, 0.9546533226966858, 0.955546498298645, 0.9574795365333557]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8259722203016281\n",
      " Loss:0.4575967460870743\n",
      " Precision:0.8198862671852112\n",
      " Recall:0.8415405809879303\n",
      " AUC:0.8965184330940247\n",
      "Score for fold 5: loss of 0.3559410870075226; accuracy of 0.8666666746139526%\n",
      "[[155  32]\n",
      " [ 16 157]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 537.2644586 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:155,FN:16,TP:157,FP:32\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8666666666666667\n",
      " Loss:0.3559410870075226\n",
      " Precision:0.8306878306878307\n",
      " Recall:0.9075144508670521\n",
      " AUC:0.9069735997025319\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.8229513943195343 - Loss: 0.4634567901492119\n",
      "> Fold 1 - Precision: 0.8184170037508011\n",
      "> Fold 1 - Recall: 0.8332413762807847\n",
      "> Fold 1 - AUC: 0.8983168035745621\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.8777777777777778 - Loss: 0.3524661064147949\n",
      "> Fold 1 - Precision: 0.8502673796791443\n",
      "> Fold 1 - Recall: 0.9085714285714286\n",
      "> Fold 1 - AUC: 0.9080429397192403\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8208333313465118 - Loss: 0.46129882633686065\n",
      "> Fold 2 - Precision: 0.8183502316474914\n",
      "> Fold 2 - Recall: 0.8191876620054245\n",
      "> Fold 2 - AUC: 0.8943783193826675\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8694444444444445 - Loss: 0.36118707060813904\n",
      "> Fold 2 - Precision: 0.8527918781725888\n",
      "> Fold 2 - Recall: 0.9032258064516129\n",
      "> Fold 2 - AUC: 0.896398179299426\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.815902778506279 - Loss: 0.4608449384570122\n",
      "> Fold 3 - Precision: 0.8112613052129746\n",
      "> Fold 3 - Recall: 0.8146186381578445\n",
      "> Fold 3 - AUC: 0.8926693975925446\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.8416666666666667 - Loss: 0.3794865906238556\n",
      "> Fold 3 - Precision: 0.8497409326424871\n",
      "> Fold 3 - Recall: 0.8541666666666666\n",
      "> Fold 3 - AUC: 0.843250998003992\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.8152777791023255 - Loss: 0.46705159097909926\n",
      "> Fold 4 - Precision: 0.8091030865907669\n",
      "> Fold 4 - Recall: 0.8323691457509994\n",
      "> Fold 4 - AUC: 0.8838423937559128\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.8861111111111111 - Loss: 0.36135029792785645\n",
      "> Fold 4 - Precision: 0.8757062146892656\n",
      "> Fold 4 - Recall: 0.8908045977011494\n",
      "> Fold 4 - AUC: 0.8934897305445637\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.8259722203016281 - Loss: 0.4575967460870743\n",
      "> Fold 5 - Precision: 0.8198862671852112\n",
      "> Fold 5 - Recall: 0.8415405809879303\n",
      "> Fold 5 - AUC: 0.8965184330940247\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.8666666666666667 - Loss: 0.3559410870075226\n",
      "> Fold 5 - Precision: 0.8306878306878307\n",
      "> Fold 5 - Recall: 0.9075144508670521\n",
      "> Fold 5 - AUC: 0.9069735997025319\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.8201875007152557 (+- 0.004098375201895839)\n",
      "> Loss: 0.4620497784018517 (+- 0.003125472003015496)\n",
      "> Precision: 0.815403578877449 (+- 0.004352301015440508)\n",
      "> Recall: 0.8281914806365966 (+- 0.009863504599393906)\n",
      "> AUC: 0.8931450694799423 (+- 0.005028187751302619)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.8683333333333334 (+- 0.014969103983674964)\n",
      "> Loss: 0.36208623051643374 (+- 0.009321289542328545)\n",
      "> Precision: 0.8518388471742633 (+- 0.01431639447668408)\n",
      "> Recall: 0.8928565900515819 (+- 0.020349204044768292)\n",
      "> AUC: 0.8896310894539508 (+- 0.0238811825120241)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 760 FN SUM: 97 TP SUM: 803 FP SUM: 140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  model = VGG16()\n",
    "  model_2 = Sequential()\n",
    "  for layer in model.layers[:-3]:\n",
    "    model_2.add(layer)\n",
    "\n",
    "  # Freeze the layers\n",
    "  for layer in model_2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(Dense(1,activation='sigmoid'))\n",
    "  model_2.summary()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78698743",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df91a604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 122ms/step - loss: 0.6816 - accuracy: 0.5681 - binary_crossentropy: 0.6816 - precision: 0.5653 - recall: 0.5684 - auc: 0.5963\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 123ms/step - loss: 0.6436 - accuracy: 0.6528 - binary_crossentropy: 0.6436 - precision: 0.6627 - recall: 0.6145 - auc: 0.6937\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 124ms/step - loss: 0.6150 - accuracy: 0.6875 - binary_crossentropy: 0.6150 - precision: 0.6812 - recall: 0.6983 - auc: 0.7488\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 124ms/step - loss: 0.5853 - accuracy: 0.7111 - binary_crossentropy: 0.5853 - precision: 0.7089 - recall: 0.7109 - auc: 0.7972\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 125ms/step - loss: 0.5618 - accuracy: 0.7597 - binary_crossentropy: 0.5618 - precision: 0.7507 - recall: 0.7737 - auc: 0.8340\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 125ms/step - loss: 0.5395 - accuracy: 0.7889 - binary_crossentropy: 0.5395 - precision: 0.7853 - recall: 0.7919 - auc: 0.8598\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 126ms/step - loss: 0.5198 - accuracy: 0.7924 - binary_crossentropy: 0.5198 - precision: 0.7876 - recall: 0.7975 - auc: 0.8723\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 126ms/step - loss: 0.5035 - accuracy: 0.8042 - binary_crossentropy: 0.5035 - precision: 0.7989 - recall: 0.8101 - auc: 0.8885\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.4882 - accuracy: 0.8236 - binary_crossentropy: 0.4882 - precision: 0.8130 - recall: 0.8380 - auc: 0.9000\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.4758 - accuracy: 0.8215 - binary_crossentropy: 0.4758 - precision: 0.8114 - recall: 0.8352 - auc: 0.9097\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.4631 - accuracy: 0.8333 - binary_crossentropy: 0.4631 - precision: 0.8234 - recall: 0.8464 - auc: 0.9154\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.4522 - accuracy: 0.8403 - binary_crossentropy: 0.4522 - precision: 0.8302 - recall: 0.8534 - auc: 0.9195\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4410 - accuracy: 0.8465 - binary_crossentropy: 0.4410 - precision: 0.8377 - recall: 0.8575 - auc: 0.9268\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4290 - accuracy: 0.8521 - binary_crossentropy: 0.4290 - precision: 0.8459 - recall: 0.8589 - auc: 0.9324\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4238 - accuracy: 0.8458 - binary_crossentropy: 0.4238 - precision: 0.8365 - recall: 0.8575 - auc: 0.9328\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4137 - accuracy: 0.8611 - binary_crossentropy: 0.4137 - precision: 0.8496 - recall: 0.8757 - auc: 0.9386\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4062 - accuracy: 0.8590 - binary_crossentropy: 0.4062 - precision: 0.8509 - recall: 0.8687 - auc: 0.9396\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4035 - accuracy: 0.8646 - binary_crossentropy: 0.4035 - precision: 0.8544 - recall: 0.8771 - auc: 0.9406\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3925 - accuracy: 0.8681 - binary_crossentropy: 0.3925 - precision: 0.8564 - recall: 0.8827 - auc: 0.9456\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3864 - accuracy: 0.8687 - binary_crossentropy: 0.3864 - precision: 0.8595 - recall: 0.8799 - auc: 0.9470\n",
      "Loss of Train ......................................\n",
      "[0.6815529465675354, 0.6435893177986145, 0.6149560213088989, 0.5853075385093689, 0.56183922290802, 0.5395447015762329, 0.519836962223053, 0.5035378932952881, 0.4882051646709442, 0.47579967975616455, 0.46314266324043274, 0.4521963894367218, 0.4410400688648224, 0.4289754331111908, 0.4237971305847168, 0.41366302967071533, 0.4062059223651886, 0.40353405475616455, 0.39248377084732056, 0.38644567131996155]\n",
      "Accuracy of Train ......................................\n",
      "[0.5680555701255798, 0.6527777910232544, 0.6875, 0.7111111283302307, 0.7597222328186035, 0.7888888716697693, 0.7923611402511597, 0.8041666746139526, 0.8236111402511597, 0.8215277791023254, 0.8333333134651184, 0.8402777910232544, 0.8465277552604675, 0.8520833253860474, 0.8458333611488342, 0.8611111044883728, 0.8590278029441833, 0.8645833134651184, 0.8680555820465088, 0.8687499761581421]\n",
      "Precision of Train ......................................\n",
      "[0.5652777552604675, 0.6626505851745605, 0.6811988949775696, 0.7089136242866516, 0.7506775259971619, 0.7853185534477234, 0.7875862121582031, 0.7988981008529663, 0.8130081295967102, 0.8113975524902344, 0.823369562625885, 0.8301630616188049, 0.8376534581184387, 0.8459421992301941, 0.8365122675895691, 0.8495935201644897, 0.8508892059326172, 0.8544217944145203, 0.8563685417175293, 0.8594815731048584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of Train ......................................\n",
      "[0.5684357285499573, 0.6145251393318176, 0.6983240246772766, 0.7108938694000244, 0.7737430334091187, 0.7918994426727295, 0.7974860072135925, 0.8100558519363403, 0.8379888534545898, 0.8351955413818359, 0.8463687300682068, 0.8533519506454468, 0.8575419187545776, 0.8589385747909546, 0.8575419187545776, 0.8756983280181885, 0.8687151074409485, 0.8770949840545654, 0.8826815485954285, 0.8798882961273193]\n",
      "AUC of Train ......................................\n",
      "[0.5963088870048523, 0.693715512752533, 0.7487913966178894, 0.7972362637519836, 0.8339685797691345, 0.8597931265830994, 0.8722992539405823, 0.8884543180465698, 0.9000006914138794, 0.9096866250038147, 0.9154015183448792, 0.9195075631141663, 0.9268303513526917, 0.9323946833610535, 0.9327573180198669, 0.938614010810852, 0.9396412968635559, 0.94056236743927, 0.9456349015235901, 0.9470469355583191]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7974652826786042\n",
      " Loss:0.4912826791405678\n",
      " Precision:0.7904661059379577\n",
      " Recall:0.8048184424638748\n",
      " AUC:0.8719322800636291\n",
      "Score for fold 1: loss of 0.38900476694107056; accuracy of 0.8666666746139526%\n",
      "[[151  25]\n",
      " [ 23 161]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 135.9318288 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:151,FN:23,TP:161,FP:25\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8666666666666667\n",
      " Loss:0.38900476694107056\n",
      " Precision:0.8655913978494624\n",
      " Recall:0.875\n",
      " AUC:0.8714080459770115\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 127ms/step - loss: 0.6838 - accuracy: 0.5653 - binary_crossentropy: 0.6838 - precision: 0.5714 - recall: 0.5557 - auc: 0.5855\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.6422 - accuracy: 0.6313 - binary_crossentropy: 0.6422 - precision: 0.6253 - recall: 0.6726 - auc: 0.6925\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.6124 - accuracy: 0.6951 - binary_crossentropy: 0.6124 - precision: 0.6962 - recall: 0.7029 - auc: 0.7686\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.5765 - accuracy: 0.7479 - binary_crossentropy: 0.5765 - precision: 0.7370 - recall: 0.7785 - auc: 0.8234\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.5561 - accuracy: 0.7743 - binary_crossentropy: 0.5561 - precision: 0.7631 - recall: 0.8019 - auc: 0.8585\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.5337 - accuracy: 0.8062 - binary_crossentropy: 0.5337 - precision: 0.7894 - recall: 0.8404 - auc: 0.8829\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.5126 - accuracy: 0.8188 - binary_crossentropy: 0.5126 - precision: 0.8149 - recall: 0.8294 - auc: 0.8984\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.4940 - accuracy: 0.8243 - binary_crossentropy: 0.4940 - precision: 0.8046 - recall: 0.8611 - auc: 0.9094\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.4802 - accuracy: 0.8368 - binary_crossentropy: 0.4802 - precision: 0.8170 - recall: 0.8721 - auc: 0.9205\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.4641 - accuracy: 0.8569 - binary_crossentropy: 0.4641 - precision: 0.8441 - recall: 0.8790 - auc: 0.9306\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.4519 - accuracy: 0.8521 - binary_crossentropy: 0.4519 - precision: 0.8373 - recall: 0.8776 - auc: 0.9319\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.4393 - accuracy: 0.8590 - binary_crossentropy: 0.4393 - precision: 0.8475 - recall: 0.8790 - auc: 0.9380\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.4281 - accuracy: 0.8694 - binary_crossentropy: 0.4281 - precision: 0.8541 - recall: 0.8941 - auc: 0.9432\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.4201 - accuracy: 0.8646 - binary_crossentropy: 0.4201 - precision: 0.8528 - recall: 0.8845 - auc: 0.9456\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4107 - accuracy: 0.8653 - binary_crossentropy: 0.4107 - precision: 0.8568 - recall: 0.8803 - auc: 0.9459\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.4021 - accuracy: 0.8639 - binary_crossentropy: 0.4021 - precision: 0.8453 - recall: 0.8941 - auc: 0.9483\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.3943 - accuracy: 0.8785 - binary_crossentropy: 0.3943 - precision: 0.8690 - recall: 0.8941 - auc: 0.9530\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3866 - accuracy: 0.8743 - binary_crossentropy: 0.3866 - precision: 0.8518 - recall: 0.9092 - auc: 0.9536\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.3815 - accuracy: 0.8771 - binary_crossentropy: 0.3815 - precision: 0.8553 - recall: 0.9106 - auc: 0.9538\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.3737 - accuracy: 0.8875 - binary_crossentropy: 0.3737 - precision: 0.8732 - recall: 0.9092 - auc: 0.9578\n",
      "Loss of Train ......................................\n",
      "[0.6838103532791138, 0.642231822013855, 0.6123858690261841, 0.5765039920806885, 0.5560997128486633, 0.5336785316467285, 0.5126299262046814, 0.4940318167209625, 0.4802466928958893, 0.4641401171684265, 0.45186179876327515, 0.4392714500427246, 0.4280850291252136, 0.4201287627220154, 0.4106776714324951, 0.4020984172821045, 0.3943450152873993, 0.3865711987018585, 0.3815250098705292, 0.37374910712242126]\n",
      "Accuracy of Train ......................................\n",
      "[0.5652777552604675, 0.6312500238418579, 0.6951388716697693, 0.7479166388511658, 0.7743055820465088, 0.8062499761581421, 0.8187500238418579, 0.824305534362793, 0.8368055820465088, 0.8569444417953491, 0.8520833253860474, 0.8590278029441833, 0.8694444298744202, 0.8645833134651184, 0.8652777671813965, 0.8638888597488403, 0.8784722089767456, 0.8743055462837219, 0.8770833611488342, 0.887499988079071]\n",
      "Precision of Train ......................................\n",
      "[0.5714285969734192, 0.6253197193145752, 0.696185290813446, 0.7369791865348816, 0.7630890011787415, 0.7894057035446167, 0.8148648738861084, 0.8046272397041321, 0.8170102834701538, 0.844121515750885, 0.8372703194618225, 0.8474801182746887, 0.8541392683982849, 0.8527851700782776, 0.8567603826522827, 0.845253586769104, 0.8689839839935303, 0.8518041372299194, 0.8552971482276917, 0.8731836080551147]\n",
      "Recall of Train ......................................\n",
      "[0.5557084083557129, 0.6726272106170654, 0.7028886079788208, 0.7785419821739197, 0.8019257187843323, 0.8404401540756226, 0.8294360637664795, 0.8610728979110718, 0.8720770478248596, 0.8789545893669128, 0.8775790929794312, 0.8789545893669128, 0.8940852880477905, 0.8844566941261292, 0.8803301453590393, 0.8940852880477905, 0.8940852880477905, 0.9092159271240234, 0.9105914831161499, 0.9092159271240234]\n",
      "AUC of Train ......................................\n",
      "[0.5854951739311218, 0.6924834847450256, 0.7686036825180054, 0.8233966827392578, 0.8584723472595215, 0.882893979549408, 0.898434579372406, 0.9094021320343018, 0.9205383658409119, 0.9305933713912964, 0.9318733811378479, 0.9380265474319458, 0.9432103037834167, 0.9456121325492859, 0.9459438920021057, 0.9482638239860535, 0.9530443549156189, 0.953633725643158, 0.9538468718528748, 0.9578192234039307]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8124305516481399\n",
      " Loss:0.4822036147117615\n",
      " Precision:0.8002994567155838\n",
      " Recall:0.8363136202096939\n",
      " AUC:0.8870794028043747\n",
      "Score for fold 2: loss of 0.42772406339645386; accuracy of 0.8416666388511658%\n",
      "[[147  40]\n",
      " [ 17 156]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 258.4915606 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:147,FN:17,TP:156,FP:40\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8416666666666667\n",
      " Loss:0.42772406339645386\n",
      " Precision:0.7959183673469388\n",
      " Recall:0.9017341040462428\n",
      " AUC:0.8990377837304384\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 127ms/step - loss: 0.7153 - accuracy: 0.5132 - binary_crossentropy: 0.7153 - precision: 0.5131 - recall: 0.4652 - auc: 0.5209\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.6648 - accuracy: 0.6014 - binary_crossentropy: 0.6648 - precision: 0.6020 - recall: 0.5919 - auc: 0.6343\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 6s 128ms/step - loss: 0.6297 - accuracy: 0.6569 - binary_crossentropy: 0.6297 - precision: 0.6564 - recall: 0.6546 - auc: 0.7188\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.6041 - accuracy: 0.6951 - binary_crossentropy: 0.6041 - precision: 0.6903 - recall: 0.7047 - auc: 0.7628\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.5746 - accuracy: 0.7278 - binary_crossentropy: 0.5746 - precision: 0.7369 - recall: 0.7061 - auc: 0.8152\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.5497 - accuracy: 0.7701 - binary_crossentropy: 0.5497 - precision: 0.7556 - recall: 0.7967 - auc: 0.8471\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.5368 - accuracy: 0.7889 - binary_crossentropy: 0.5368 - precision: 0.7805 - recall: 0.8022 - auc: 0.8589\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.5146 - accuracy: 0.7979 - binary_crossentropy: 0.5146 - precision: 0.7969 - recall: 0.7981 - auc: 0.8808\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.4975 - accuracy: 0.8083 - binary_crossentropy: 0.4975 - precision: 0.7970 - recall: 0.8259 - auc: 0.8946\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4806 - accuracy: 0.8201 - binary_crossentropy: 0.4806 - precision: 0.8131 - recall: 0.8301 - auc: 0.9080\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4701 - accuracy: 0.8347 - binary_crossentropy: 0.4701 - precision: 0.8333 - recall: 0.8357 - auc: 0.9130\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4604 - accuracy: 0.8285 - binary_crossentropy: 0.4604 - precision: 0.8161 - recall: 0.8468 - auc: 0.9153\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4474 - accuracy: 0.8431 - binary_crossentropy: 0.4474 - precision: 0.8333 - recall: 0.8565 - auc: 0.9226\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4379 - accuracy: 0.8500 - binary_crossentropy: 0.4379 - precision: 0.8374 - recall: 0.8677 - auc: 0.9284\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4265 - accuracy: 0.8625 - binary_crossentropy: 0.4265 - precision: 0.8485 - recall: 0.8816 - auc: 0.9358\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4191 - accuracy: 0.8542 - binary_crossentropy: 0.4191 - precision: 0.8489 - recall: 0.8607 - auc: 0.9364\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 129ms/step - loss: 0.4114 - accuracy: 0.8549 - binary_crossentropy: 0.4114 - precision: 0.8362 - recall: 0.8816 - auc: 0.9377\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 129ms/step - loss: 0.4028 - accuracy: 0.8701 - binary_crossentropy: 0.4028 - precision: 0.8517 - recall: 0.8955 - auc: 0.9419\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 129ms/step - loss: 0.3961 - accuracy: 0.8674 - binary_crossentropy: 0.3961 - precision: 0.8527 - recall: 0.8872 - auc: 0.9449\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 129ms/step - loss: 0.3867 - accuracy: 0.8743 - binary_crossentropy: 0.3867 - precision: 0.8604 - recall: 0.8928 - auc: 0.9476\n",
      "Loss of Train ......................................\n",
      "[0.7152649760246277, 0.6647961735725403, 0.6296939849853516, 0.6041231751441956, 0.5746086835861206, 0.5496547818183899, 0.5367708206176758, 0.5146431922912598, 0.49753427505493164, 0.4806341528892517, 0.4701375365257263, 0.4603855609893799, 0.44735726714134216, 0.4379148781299591, 0.4265241324901581, 0.41906827688217163, 0.4113999307155609, 0.4028466045856476, 0.3961491584777832, 0.38665252923965454]\n",
      "Accuracy of Train ......................................\n",
      "[0.5131944417953491, 0.6013888716697693, 0.6569444537162781, 0.6951388716697693, 0.7277777791023254, 0.7701388597488403, 0.7888888716697693, 0.7979166507720947, 0.8083333373069763, 0.8201388716697693, 0.8347222208976746, 0.8284721970558167, 0.8430555462837219, 0.8500000238418579, 0.862500011920929, 0.8541666865348816, 0.8548611402511597, 0.8701388835906982, 0.8673611283302307, 0.8743055462837219]\n",
      "Precision of Train ......................................\n",
      "[0.5130568146705627, 0.6019830107688904, 0.6564245820045471, 0.6903137564659119, 0.7369186282157898, 0.7556142807006836, 0.7804877758026123, 0.7969402074813843, 0.7970430254936218, 0.8130968809127808, 0.8333333134651184, 0.8161073923110962, 0.8333333134651184, 0.8373655676841736, 0.8485254645347595, 0.848901093006134, 0.8361955285072327, 0.8516556024551392, 0.8527442812919617, 0.8604027032852173]\n",
      "Recall of Train ......................................\n",
      "[0.46518105268478394, 0.5919219851493835, 0.6545960903167725, 0.7047353982925415, 0.7061281204223633, 0.796657383441925, 0.8022283911705017, 0.7980501651763916, 0.8259052634239197, 0.8300835490226746, 0.835654616355896, 0.8467966318130493, 0.8565459847450256, 0.867688000202179, 0.8816155791282654, 0.8607242107391357, 0.8816155791282654, 0.8955431580543518, 0.8871866464614868, 0.8927576541900635]\n",
      "AUC of Train ......................................\n",
      "[0.5208672285079956, 0.6342969536781311, 0.7187767624855042, 0.7628241181373596, 0.8151596188545227, 0.8471419215202332, 0.8588618040084839, 0.8808305263519287, 0.8946326375007629, 0.9079661965370178, 0.9129584431648254, 0.9153475761413574, 0.9225543737411499, 0.9284176230430603, 0.9357971549034119, 0.9363873600959778, 0.9376769661903381, 0.9418976902961731, 0.9449359178543091, 0.9476278424263]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7859722197055816\n",
      " Loss:0.5013080045580864\n",
      " Precision:0.7780221611261368\n",
      " Recall:0.7940807729959488\n",
      " AUC:0.8582479357719421\n",
      "Score for fold 3: loss of 0.42264997959136963; accuracy of 0.8416666388511658%\n",
      "[[168  10]\n",
      " [ 47 135]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 381.7049376 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:168,FN:47,TP:135,FP:10\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8416666666666667\n",
      " Loss:0.42264997959136963\n",
      " Precision:0.9310344827586207\n",
      " Recall:0.7417582417582418\n",
      " AUC:0.7615767952977255\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 126ms/step - loss: 0.7187 - accuracy: 0.5104 - binary_crossentropy: 0.7187 - precision: 0.5079 - recall: 0.5411 - auc: 0.4993\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.6718 - accuracy: 0.5868 - binary_crossentropy: 0.6718 - precision: 0.5897 - recall: 0.5593 - auc: 0.6176\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.6368 - accuracy: 0.6493 - binary_crossentropy: 0.6368 - precision: 0.6592 - recall: 0.6123 - auc: 0.7048\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.6099 - accuracy: 0.6958 - binary_crossentropy: 0.6099 - precision: 0.6898 - recall: 0.7071 - auc: 0.7543\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.5835 - accuracy: 0.7444 - binary_crossentropy: 0.5835 - precision: 0.7504 - recall: 0.7294 - auc: 0.8076\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.5600 - accuracy: 0.7653 - binary_crossentropy: 0.5600 - precision: 0.7680 - recall: 0.7573 - auc: 0.8415\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.5378 - accuracy: 0.7910 - binary_crossentropy: 0.5378 - precision: 0.7842 - recall: 0.8006 - auc: 0.8680\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.5223 - accuracy: 0.8069 - binary_crossentropy: 0.5223 - precision: 0.8028 - recall: 0.8117 - auc: 0.8795\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.5063 - accuracy: 0.8174 - binary_crossentropy: 0.5063 - precision: 0.8206 - recall: 0.8103 - auc: 0.8918\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4887 - accuracy: 0.8215 - binary_crossentropy: 0.4887 - precision: 0.8108 - recall: 0.8368 - auc: 0.9039\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4770 - accuracy: 0.8292 - binary_crossentropy: 0.4770 - precision: 0.8248 - recall: 0.8340 - auc: 0.9105\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4648 - accuracy: 0.8354 - binary_crossentropy: 0.4648 - precision: 0.8270 - recall: 0.8466 - auc: 0.9151\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4519 - accuracy: 0.8431 - binary_crossentropy: 0.4519 - precision: 0.8349 - recall: 0.8536 - auc: 0.9250\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4420 - accuracy: 0.8500 - binary_crossentropy: 0.4420 - precision: 0.8446 - recall: 0.8563 - auc: 0.9270\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4342 - accuracy: 0.8542 - binary_crossentropy: 0.4342 - precision: 0.8412 - recall: 0.8717 - auc: 0.9313\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4238 - accuracy: 0.8549 - binary_crossentropy: 0.4238 - precision: 0.8442 - recall: 0.8689 - auc: 0.9350\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4141 - accuracy: 0.8632 - binary_crossentropy: 0.4141 - precision: 0.8581 - recall: 0.8689 - auc: 0.9408\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.4071 - accuracy: 0.8604 - binary_crossentropy: 0.4071 - precision: 0.8458 - recall: 0.8801 - auc: 0.9428\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.3988 - accuracy: 0.8653 - binary_crossentropy: 0.3988 - precision: 0.8568 - recall: 0.8759 - auc: 0.9446\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.3942 - accuracy: 0.8597 - binary_crossentropy: 0.3942 - precision: 0.8523 - recall: 0.8689 - auc: 0.9446\n",
      "Loss of Train ......................................\n",
      "[0.7186877131462097, 0.6717745661735535, 0.636780858039856, 0.6098777055740356, 0.5835363268852234, 0.5599536895751953, 0.5378450155258179, 0.5223276019096375, 0.5063111782073975, 0.4886910617351532, 0.47703883051872253, 0.4648175835609436, 0.4518783986568451, 0.442000150680542, 0.43422695994377136, 0.4238259196281433, 0.4140869081020355, 0.40709343552589417, 0.3987828493118286, 0.39422377943992615]\n",
      "Accuracy of Train ......................................\n",
      "[0.5104166865348816, 0.5868055820465088, 0.6493055820465088, 0.6958333253860474, 0.7444444298744202, 0.7652778029441833, 0.7909722328186035, 0.8069444298744202, 0.8173611164093018, 0.8215277791023254, 0.8291666507720947, 0.8354166746139526, 0.8430555462837219, 0.8500000238418579, 0.8541666865348816, 0.8548611402511597, 0.863194465637207, 0.8604166507720947, 0.8652777671813965, 0.8597221970558167]\n",
      "Precision of Train ......................................\n",
      "[0.5078533887863159, 0.5897058844566345, 0.6591591835021973, 0.6897959113121033, 0.7503587007522583, 0.7680339217185974, 0.7841529846191406, 0.8027586340904236, 0.8206214904785156, 0.8108108043670654, 0.8248276114463806, 0.8269754648208618, 0.8349249362945557, 0.8445667028427124, 0.8411843776702881, 0.8441734313964844, 0.858126699924469, 0.8458445072174072, 0.8567530512809753, 0.8522571921348572]\n",
      "Recall of Train ......................................\n",
      "[0.5411436557769775, 0.5592747330665588, 0.6122733354568481, 0.7071129679679871, 0.7294281721115112, 0.7573221921920776, 0.8005578517913818, 0.8117154836654663, 0.8103207945823669, 0.8368200659751892, 0.8340306878089905, 0.8465830087661743, 0.8535565137863159, 0.8563458919525146, 0.8716875910758972, 0.8688982129096985, 0.8688982129096985, 0.8800557851791382, 0.8758716583251953, 0.8688982129096985]\n",
      "AUC of Train ......................................\n",
      "[0.4993460178375244, 0.6176273822784424, 0.7047884464263916, 0.7542733550071716, 0.8075950741767883, 0.8414912223815918, 0.8679693937301636, 0.8794548511505127, 0.8918085694313049, 0.9038862586021423, 0.9104787707328796, 0.9151172041893005, 0.9249910116195679, 0.9270010590553284, 0.9312922358512878, 0.9350268244743347, 0.9408081769943237, 0.9427594542503357, 0.9445881843566895, 0.9446228742599487]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7852083384990692\n",
      " Loss:0.5071880266070365\n",
      " Precision:0.7806442439556122\n",
      " Recall:0.7895397514104843\n",
      " AUC:0.8542463183403015\n",
      "Score for fold 4: loss of 0.3799826204776764; accuracy of 0.8916666507720947%\n",
      "[[165  12]\n",
      " [ 27 156]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 505.393061 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:165,FN:27,TP:156,FP:12\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8916666666666667\n",
      " Loss:0.3799826204776764\n",
      " Precision:0.9285714285714286\n",
      " Recall:0.8524590163934426\n",
      " AUC:0.8559170081967213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 126ms/step - loss: 0.6858 - accuracy: 0.5771 - binary_crossentropy: 0.6858 - precision: 0.5871 - recall: 0.5277 - auc: 0.5899\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.6454 - accuracy: 0.6229 - binary_crossentropy: 0.6454 - precision: 0.6224 - recall: 0.6302 - auc: 0.6789\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.6119 - accuracy: 0.6771 - binary_crossentropy: 0.6119 - precision: 0.6833 - recall: 0.6634 - auc: 0.7543\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 127ms/step - loss: 0.5839 - accuracy: 0.7243 - binary_crossentropy: 0.5839 - precision: 0.7248 - recall: 0.7258 - auc: 0.8065\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.5600 - accuracy: 0.7583 - binary_crossentropy: 0.5600 - precision: 0.7641 - recall: 0.7493 - auc: 0.8397\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.5358 - accuracy: 0.7896 - binary_crossentropy: 0.5358 - precision: 0.7874 - recall: 0.7950 - auc: 0.8689\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.5164 - accuracy: 0.8035 - binary_crossentropy: 0.5164 - precision: 0.8096 - recall: 0.7950 - auc: 0.8869\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.4976 - accuracy: 0.8132 - binary_crossentropy: 0.4976 - precision: 0.8168 - recall: 0.8089 - auc: 0.9050\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4800 - accuracy: 0.8264 - binary_crossentropy: 0.4800 - precision: 0.8155 - recall: 0.8449 - auc: 0.9177\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4679 - accuracy: 0.8375 - binary_crossentropy: 0.4679 - precision: 0.8333 - recall: 0.8449 - auc: 0.9224\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4531 - accuracy: 0.8493 - binary_crossentropy: 0.4531 - precision: 0.8426 - recall: 0.8601 - auc: 0.9316\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4414 - accuracy: 0.8431 - binary_crossentropy: 0.4414 - precision: 0.8397 - recall: 0.8490 - auc: 0.9349\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4322 - accuracy: 0.8653 - binary_crossentropy: 0.4322 - precision: 0.8539 - recall: 0.8823 - auc: 0.9399\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4209 - accuracy: 0.8674 - binary_crossentropy: 0.4209 - precision: 0.8545 - recall: 0.8864 - auc: 0.9462\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4129 - accuracy: 0.8674 - binary_crossentropy: 0.4129 - precision: 0.8554 - recall: 0.8850 - auc: 0.9469\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4036 - accuracy: 0.8701 - binary_crossentropy: 0.4036 - precision: 0.8620 - recall: 0.8823 - auc: 0.9521\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3952 - accuracy: 0.8736 - binary_crossentropy: 0.3952 - precision: 0.8581 - recall: 0.8961 - auc: 0.9533\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3861 - accuracy: 0.8833 - binary_crossentropy: 0.3861 - precision: 0.8723 - recall: 0.8989 - auc: 0.9569\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.3797 - accuracy: 0.8840 - binary_crossentropy: 0.3797 - precision: 0.8675 - recall: 0.9072 - auc: 0.9589\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.3738 - accuracy: 0.8764 - binary_crossentropy: 0.3738 - precision: 0.8607 - recall: 0.8989 - auc: 0.9591\n",
      "Loss of Train ......................................\n",
      "[0.6858067512512207, 0.6454476118087769, 0.6119330525398254, 0.5839455723762512, 0.5600196719169617, 0.5358221530914307, 0.5164269804954529, 0.4975772500038147, 0.48003798723220825, 0.46787580847740173, 0.453056663274765, 0.44139206409454346, 0.43215206265449524, 0.4208963215351105, 0.4128621816635132, 0.40357720851898193, 0.395208477973938, 0.38608378171920776, 0.37968212366104126, 0.3737899661064148]\n",
      "Accuracy of Train ......................................\n",
      "[0.5770833492279053, 0.6229166388511658, 0.6770833134651184, 0.7243055701255798, 0.7583333253860474, 0.7895833253860474, 0.8034722208976746, 0.8131944537162781, 0.8263888955116272, 0.8374999761581421, 0.8493055701255798, 0.8430555462837219, 0.8652777671813965, 0.8673611283302307, 0.8673611283302307, 0.8701388835906982, 0.8736110925674438, 0.8833333253860474, 0.8840277791023254, 0.8763889074325562]\n",
      "Precision of Train ......................................\n",
      "[0.5870569944381714, 0.6224350333213806, 0.6833095550537109, 0.724757969379425, 0.7641242742538452, 0.7873799800872803, 0.8095909953117371, 0.8167831897735596, 0.8155080080032349, 0.8333333134651184, 0.8426051735877991, 0.8397260308265686, 0.8538873791694641, 0.8544726371765137, 0.8554216623306274, 0.8619756698608398, 0.8580901622772217, 0.8723118305206299, 0.8675496578216553, 0.8607426881790161]\n",
      "Recall of Train ......................................\n",
      "[0.5277008414268494, 0.6301938891410828, 0.6634349226951599, 0.7257617712020874, 0.7493074536323547, 0.7950138449668884, 0.7950138449668884, 0.8088642954826355, 0.8448753356933594, 0.8448753356933594, 0.8601108193397522, 0.8490304946899414, 0.8822714686393738, 0.886426568031311, 0.8850415349006653, 0.8822714686393738, 0.8961218595504761, 0.8988919854164124, 0.9072022438049316, 0.8988919854164124]\n",
      "AUC of Train ......................................\n",
      "[0.5899274349212646, 0.6788526773452759, 0.7542535066604614, 0.8064953684806824, 0.8396544456481934, 0.8688724637031555, 0.8869049549102783, 0.9050214886665344, 0.9176681637763977, 0.9224039316177368, 0.9315947890281677, 0.9349175691604614, 0.9398664236068726, 0.9462100863456726, 0.9468640089035034, 0.9520936012268066, 0.9532644748687744, 0.9568506479263306, 0.9588721990585327, 0.9591412544250488]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8054861098527908\n",
      " Loss:0.4841796845197678\n",
      " Precision:0.8005531102418899\n",
      " Recall:0.8115650981664657\n",
      " AUC:0.8824864745140075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 0.40564125776290894; accuracy of 0.8472222089767456%\n",
      "[[155  27]\n",
      " [ 28 150]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 631.0592575 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:155,FN:28,TP:150,FP:27\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8472222222222222\n",
      " Loss:0.40564125776290894\n",
      " Precision:0.847457627118644\n",
      " Recall:0.8426966292134831\n",
      " AUC:0.8448455823663044\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.7974652826786042 - Loss: 0.4912826791405678\n",
      "> Fold 1 - Precision: 0.7904661059379577\n",
      "> Fold 1 - Recall: 0.8048184424638748\n",
      "> Fold 1 - AUC: 0.8719322800636291\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.8666666666666667 - Loss: 0.38900476694107056\n",
      "> Fold 1 - Precision: 0.8655913978494624\n",
      "> Fold 1 - Recall: 0.875\n",
      "> Fold 1 - AUC: 0.8714080459770115\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8124305516481399 - Loss: 0.4822036147117615\n",
      "> Fold 2 - Precision: 0.8002994567155838\n",
      "> Fold 2 - Recall: 0.8363136202096939\n",
      "> Fold 2 - AUC: 0.8870794028043747\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8416666666666667 - Loss: 0.42772406339645386\n",
      "> Fold 2 - Precision: 0.7959183673469388\n",
      "> Fold 2 - Recall: 0.9017341040462428\n",
      "> Fold 2 - AUC: 0.8990377837304384\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.7859722197055816 - Loss: 0.5013080045580864\n",
      "> Fold 3 - Precision: 0.7780221611261368\n",
      "> Fold 3 - Recall: 0.7940807729959488\n",
      "> Fold 3 - AUC: 0.8582479357719421\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.8416666666666667 - Loss: 0.42264997959136963\n",
      "> Fold 3 - Precision: 0.9310344827586207\n",
      "> Fold 3 - Recall: 0.7417582417582418\n",
      "> Fold 3 - AUC: 0.7615767952977255\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.7852083384990692 - Loss: 0.5071880266070365\n",
      "> Fold 4 - Precision: 0.7806442439556122\n",
      "> Fold 4 - Recall: 0.7895397514104843\n",
      "> Fold 4 - AUC: 0.8542463183403015\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.8916666666666667 - Loss: 0.3799826204776764\n",
      "> Fold 4 - Precision: 0.9285714285714286\n",
      "> Fold 4 - Recall: 0.8524590163934426\n",
      "> Fold 4 - AUC: 0.8559170081967213\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.8054861098527908 - Loss: 0.4841796845197678\n",
      "> Fold 5 - Precision: 0.8005531102418899\n",
      "> Fold 5 - Recall: 0.8115650981664657\n",
      "> Fold 5 - AUC: 0.8824864745140075\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.8472222222222222 - Loss: 0.40564125776290894\n",
      "> Fold 5 - Precision: 0.847457627118644\n",
      "> Fold 5 - Recall: 0.8426966292134831\n",
      "> Fold 5 - AUC: 0.8448455823663044\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.797312500476837 (+- 0.010681754621830008)\n",
      "> Loss: 0.493232401907444 (+- 0.009668113330980374)\n",
      "> Precision: 0.789997015595436 (+- 0.009472728750218082)\n",
      "> Recall: 0.8072635370492935 (+- 0.016470015741699873)\n",
      "> AUC: 0.870798482298851 (+- 0.012918617431714324)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.8577777777777778 (+- 0.019277057303219432)\n",
      "> Loss: 0.4050005376338959 (+- 0.018493419400795)\n",
      "> Precision: 0.8737146607290189 (+- 0.05119083795649115)\n",
      "> Recall: 0.8427295982822821 (+- 0.05442938182547785)\n",
      "> AUC: 0.8465570431136402 (+- 0.04622549305762652)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 786 FN SUM: 142 TP SUM: 758 FP SUM: 114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  model = VGG19()\n",
    "  model_2 = Sequential()\n",
    "  for layer in model.layers[:-3]:\n",
    "    model_2.add(layer)\n",
    "\n",
    "  # Freeze the layers\n",
    "  for layer in model_2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(Dense(1,activation='sigmoid'))\n",
    "  model_2.summary()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3bed4d",
   "metadata": {},
   "source": [
    "# ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde118c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 28s 395ms/step - loss: 0.7230 - accuracy: 0.5125 - binary_crossentropy: 0.7230 - precision: 0.4947 - recall: 0.4023 - auc: 0.5172\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.6866 - accuracy: 0.5660 - binary_crossentropy: 0.6866 - precision: 0.5647 - recall: 0.4454 - auc: 0.5934\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.6598 - accuracy: 0.5979 - binary_crossentropy: 0.6598 - precision: 0.6032 - recall: 0.4914 - auc: 0.6473\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.6351 - accuracy: 0.6465 - binary_crossentropy: 0.6351 - precision: 0.6615 - recall: 0.5503 - auc: 0.7022\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.6199 - accuracy: 0.6750 - binary_crossentropy: 0.6199 - precision: 0.6945 - recall: 0.5848 - auc: 0.7240\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.5933 - accuracy: 0.7160 - binary_crossentropy: 0.5933 - precision: 0.7372 - recall: 0.6408 - auc: 0.7776\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.5727 - accuracy: 0.7208 - binary_crossentropy: 0.5727 - precision: 0.7341 - recall: 0.6624 - auc: 0.8078\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.5567 - accuracy: 0.7576 - binary_crossentropy: 0.5567 - precision: 0.7758 - recall: 0.7011 - auc: 0.8369\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.5376 - accuracy: 0.7799 - binary_crossentropy: 0.5376 - precision: 0.8013 - recall: 0.7241 - auc: 0.8609\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.5202 - accuracy: 0.7917 - binary_crossentropy: 0.5202 - precision: 0.8018 - recall: 0.7557 - auc: 0.8821\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.5071 - accuracy: 0.8035 - binary_crossentropy: 0.5071 - precision: 0.8182 - recall: 0.7629 - auc: 0.8925\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.4918 - accuracy: 0.8222 - binary_crossentropy: 0.4918 - precision: 0.8333 - recall: 0.7902 - auc: 0.9086\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.4776 - accuracy: 0.8340 - binary_crossentropy: 0.4776 - precision: 0.8336 - recall: 0.8204 - auc: 0.9218\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.4659 - accuracy: 0.8507 - binary_crossentropy: 0.4659 - precision: 0.8574 - recall: 0.8290 - auc: 0.9284\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.4478 - accuracy: 0.8597 - binary_crossentropy: 0.4478 - precision: 0.8549 - recall: 0.8549 - auc: 0.9438\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.4390 - accuracy: 0.8785 - binary_crossentropy: 0.4390 - precision: 0.8716 - recall: 0.8779 - auc: 0.9501\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.4281 - accuracy: 0.8764 - binary_crossentropy: 0.4281 - precision: 0.8820 - recall: 0.8592 - auc: 0.9543\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.4245 - accuracy: 0.8785 - binary_crossentropy: 0.4245 - precision: 0.8695 - recall: 0.8807 - auc: 0.9506\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.4071 - accuracy: 0.9007 - binary_crossentropy: 0.4071 - precision: 0.9025 - recall: 0.8908 - auc: 0.9651\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.4032 - accuracy: 0.8965 - binary_crossentropy: 0.4032 - precision: 0.8868 - recall: 0.9009 - auc: 0.9625\n",
      "Loss of Train ......................................\n",
      "[0.7229794263839722, 0.6866055130958557, 0.6598483324050903, 0.6351403594017029, 0.619914710521698, 0.5933440327644348, 0.5726892948150635, 0.5567237734794617, 0.5375711917877197, 0.5201729536056519, 0.5070609450340271, 0.4918471872806549, 0.4776478707790375, 0.46593454480171204, 0.4478282928466797, 0.439039021730423, 0.4280656576156616, 0.4245222210884094, 0.407114714384079, 0.40316852927207947]\n",
      "Accuracy of Train ......................................\n",
      "[0.512499988079071, 0.5659722089767456, 0.5979166626930237, 0.6465277671813965, 0.675000011920929, 0.7159722447395325, 0.7208333611488342, 0.7576388716697693, 0.7798610925674438, 0.7916666865348816, 0.8034722208976746, 0.8222222328186035, 0.8340277671813965, 0.8506944179534912, 0.8597221970558167, 0.8784722089767456, 0.8763889074325562, 0.8784722089767456, 0.9006944298744202, 0.8965277671813965]\n",
      "Precision of Train ......................................\n",
      "[0.4946996569633484, 0.5646630525588989, 0.60317462682724, 0.6614853143692017, 0.6945392489433289, 0.7371900677680969, 0.7340764403343201, 0.7758346796035767, 0.8012718558311462, 0.8018292784690857, 0.8181818127632141, 0.8333333134651184, 0.8335766196250916, 0.8573551177978516, 0.8548850417137146, 0.871612012386322, 0.8820058703422546, 0.8695035576820374, 0.9024745225906372, 0.8868458271026611]\n",
      "Recall of Train ......................................\n",
      "[0.40229883790016174, 0.4454022943973541, 0.4913793206214905, 0.5502873659133911, 0.584770143032074, 0.6408045887947083, 0.6623563170433044, 0.7011494040489197, 0.7241379022598267, 0.7557471394538879, 0.7629310488700867, 0.790229856967926, 0.8204023241996765, 0.829023003578186, 0.8548850417137146, 0.8778735399246216, 0.8591954112052917, 0.8807471394538879, 0.8908045887947083, 0.9008620977401733]\n",
      "AUC of Train ......................................\n",
      "[0.5171834230422974, 0.5934110879898071, 0.6473164558410645, 0.7022366523742676, 0.7240346670150757, 0.7776339054107666, 0.8077879548072815, 0.8369165658950806, 0.8608852028846741, 0.8821114897727966, 0.892546534538269, 0.9085702896118164, 0.9218257665634155, 0.9283878207206726, 0.9438274502754211, 0.9501219987869263, 0.954338788986206, 0.9506492018699646, 0.9650518894195557, 0.9625403881072998]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7682291626930237\n",
      " Loss:0.5298609286546707\n",
      " Precision:0.7739268958568573\n",
      " Recall:0.7212643682956695\n",
      " AUC:0.836368876695633\n",
      "Score for fold 1: loss of 0.49955445528030396; accuracy of 0.7666666507720947%\n",
      "[[124  32]\n",
      " [ 52 152]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 393.90796470000004 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:124,FN:52,TP:152,FP:32\n",
      "Test of epochs .................................\n",
      " Accuracy:0.7666666666666667\n",
      " Loss:0.49955445528030396\n",
      " Precision:0.8260869565217391\n",
      " Recall:0.7450980392156863\n",
      " AUC:0.7248217468805704\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 2049      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 25s 409ms/step - loss: 0.7806 - accuracy: 0.4569 - binary_crossentropy: 0.7806 - precision: 0.4738 - recall: 0.7372 - auc: 0.4293\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.7359 - accuracy: 0.5076 - binary_crossentropy: 0.7359 - precision: 0.5067 - recall: 0.7372 - auc: 0.5113\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.6982 - accuracy: 0.5458 - binary_crossentropy: 0.6982 - precision: 0.5344 - recall: 0.7414 - auc: 0.5770\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.6747 - accuracy: 0.5708 - binary_crossentropy: 0.6747 - precision: 0.5549 - recall: 0.7344 - auc: 0.6217\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.6439 - accuracy: 0.6146 - binary_crossentropy: 0.6439 - precision: 0.5948 - recall: 0.7289 - auc: 0.6826\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.6231 - accuracy: 0.6410 - binary_crossentropy: 0.6231 - precision: 0.6168 - recall: 0.7524 - auc: 0.7219\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.6017 - accuracy: 0.6687 - binary_crossentropy: 0.6017 - precision: 0.6457 - recall: 0.7538 - auc: 0.7618\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.5754 - accuracy: 0.7319 - binary_crossentropy: 0.5754 - precision: 0.7052 - recall: 0.8008 - auc: 0.8139\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.5639 - accuracy: 0.7417 - binary_crossentropy: 0.5639 - precision: 0.7224 - recall: 0.7884 - auc: 0.8251\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.5435 - accuracy: 0.7715 - binary_crossentropy: 0.5435 - precision: 0.7500 - recall: 0.8174 - auc: 0.8612\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.5240 - accuracy: 0.7965 - binary_crossentropy: 0.5240 - precision: 0.7792 - recall: 0.8299 - auc: 0.8813\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.5097 - accuracy: 0.8160 - binary_crossentropy: 0.5097 - precision: 0.8005 - recall: 0.8437 - auc: 0.9003\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.4943 - accuracy: 0.8229 - binary_crossentropy: 0.4943 - precision: 0.8087 - recall: 0.8479 - auc: 0.9147\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.4863 - accuracy: 0.8444 - binary_crossentropy: 0.4863 - precision: 0.8349 - recall: 0.8603 - auc: 0.9216\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.4746 - accuracy: 0.8542 - binary_crossentropy: 0.4746 - precision: 0.8443 - recall: 0.8700 - auc: 0.9274\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.4538 - accuracy: 0.8736 - binary_crossentropy: 0.4538 - precision: 0.8611 - recall: 0.8921 - auc: 0.9467\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.4375 - accuracy: 0.8778 - binary_crossentropy: 0.4375 - precision: 0.8752 - recall: 0.8824 - auc: 0.9524\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.4299 - accuracy: 0.8806 - binary_crossentropy: 0.4299 - precision: 0.8790 - recall: 0.8838 - auc: 0.9563\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.4173 - accuracy: 0.8944 - binary_crossentropy: 0.4173 - precision: 0.8906 - recall: 0.9004 - auc: 0.9657\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.4070 - accuracy: 0.9062 - binary_crossentropy: 0.4070 - precision: 0.8973 - recall: 0.9184 - auc: 0.9712\n",
      "Loss of Train ......................................\n",
      "[0.7806008458137512, 0.735863983631134, 0.6981623768806458, 0.6747035384178162, 0.6438857316970825, 0.6231127977371216, 0.6016724705696106, 0.5753734111785889, 0.5639207363128662, 0.5434801578521729, 0.52400141954422, 0.5096755623817444, 0.49428507685661316, 0.48633819818496704, 0.4746379852294922, 0.4538094699382782, 0.437505841255188, 0.4299091696739197, 0.4173380136489868, 0.40703284740448]\n",
      "Accuracy of Train ......................................\n",
      "[0.45694443583488464, 0.5076388716697693, 0.5458333492279053, 0.5708333253860474, 0.6145833134651184, 0.6409721970558167, 0.668749988079071, 0.7319444417953491, 0.7416666746139526, 0.7715277671813965, 0.7965278029441833, 0.8159722089767456, 0.8229166865348816, 0.8444444537162781, 0.8541666865348816, 0.8736110925674438, 0.8777777552604675, 0.8805555701255798, 0.894444465637207, 0.90625]\n",
      "Precision of Train ......................................\n",
      "[0.47377777099609375, 0.5066539645195007, 0.5343968272209167, 0.554858922958374, 0.5948081016540527, 0.6167800426483154, 0.6457346081733704, 0.7052375078201294, 0.7224334478378296, 0.75, 0.7792207598686218, 0.8005249500274658, 0.8087071180343628, 0.8348993062973022, 0.84429532289505, 0.8611481785774231, 0.8751714825630188, 0.8789545893669128, 0.8905608654022217, 0.8972973227500916]\n",
      "Recall of Train ......................................\n",
      "[0.7372061014175415, 0.7372061014175415, 0.7413554787635803, 0.7344398498535156, 0.7289073467254639, 0.7524204850196838, 0.7538036108016968, 0.8008298873901367, 0.7883817553520203, 0.817427396774292, 0.8298755288124084, 0.8437067866325378, 0.8478561639785767, 0.8603042960166931, 0.8699861764907837, 0.8921161890029907, 0.8824343085289001, 0.8838174343109131, 0.9004149436950684, 0.9183955788612366]\n",
      "AUC of Train ......................................\n",
      "[0.4293023943901062, 0.5113061666488647, 0.577039361000061, 0.6216793656349182, 0.6825715899467468, 0.7218537926673889, 0.7617782950401306, 0.813934862613678, 0.8251203298568726, 0.8611510992050171, 0.8812990784645081, 0.9002644419670105, 0.9147217273712158, 0.9216353893280029, 0.9274051785469055, 0.9466637969017029, 0.9523563981056213, 0.9563302993774414, 0.9656793475151062, 0.9712321758270264]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.740868054330349\n",
      " Loss:0.5537654817104339\n",
      " Precision:0.7287730544805526\n",
      " Recall:0.816044270992279\n",
      " AUC:0.8071662545204162\n",
      "Score for fold 2: loss of 0.4797848165035248; accuracy of 0.8222222328186035%\n",
      "[[148  35]\n",
      " [ 29 148]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 777.2465755000001 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:148,FN:29,TP:148,FP:35\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8222222222222222\n",
      " Loss:0.4797848165035248\n",
      " Precision:0.8087431693989071\n",
      " Recall:0.8361581920903954\n",
      " AUC:0.8361581920903954\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 25s 411ms/step - loss: 0.6763 - accuracy: 0.5882 - binary_crossentropy: 0.6763 - precision: 0.5699 - recall: 0.7466 - auc: 0.6224\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.6537 - accuracy: 0.6042 - binary_crossentropy: 0.6537 - precision: 0.5842 - recall: 0.7452 - auc: 0.6609\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.6302 - accuracy: 0.6354 - binary_crossentropy: 0.6302 - precision: 0.6125 - recall: 0.7534 - auc: 0.7031\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.6083 - accuracy: 0.6819 - binary_crossentropy: 0.6083 - precision: 0.6584 - recall: 0.7672 - auc: 0.7473\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.5815 - accuracy: 0.7083 - binary_crossentropy: 0.5815 - precision: 0.6861 - recall: 0.7769 - auc: 0.7918\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.5640 - accuracy: 0.7333 - binary_crossentropy: 0.5640 - precision: 0.7111 - recall: 0.7934 - auc: 0.8213\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.5472 - accuracy: 0.7660 - binary_crossentropy: 0.5472 - precision: 0.7398 - recall: 0.8264 - auc: 0.8476\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.5261 - accuracy: 0.7812 - binary_crossentropy: 0.5261 - precision: 0.7553 - recall: 0.8375 - auc: 0.8724\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.5120 - accuracy: 0.7986 - binary_crossentropy: 0.5120 - precision: 0.7774 - recall: 0.8416 - auc: 0.8892\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.4954 - accuracy: 0.8160 - binary_crossentropy: 0.4954 - precision: 0.7944 - recall: 0.8567 - auc: 0.9030\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.4820 - accuracy: 0.8326 - binary_crossentropy: 0.4820 - precision: 0.8129 - recall: 0.8678 - auc: 0.9180\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.4645 - accuracy: 0.8472 - binary_crossentropy: 0.4645 - precision: 0.8277 - recall: 0.8802 - auc: 0.9324\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.4498 - accuracy: 0.8576 - binary_crossentropy: 0.4498 - precision: 0.8459 - recall: 0.8774 - auc: 0.9410\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.4370 - accuracy: 0.8806 - binary_crossentropy: 0.4370 - precision: 0.8551 - recall: 0.9187 - auc: 0.9501\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.4322 - accuracy: 0.8771 - binary_crossentropy: 0.4322 - precision: 0.8636 - recall: 0.8981 - auc: 0.9505\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.4195 - accuracy: 0.8833 - binary_crossentropy: 0.4195 - precision: 0.8642 - recall: 0.9118 - auc: 0.9589\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.4058 - accuracy: 0.9007 - binary_crossentropy: 0.4058 - precision: 0.8810 - recall: 0.9284 - auc: 0.9654\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.3897 - accuracy: 0.9111 - binary_crossentropy: 0.3897 - precision: 0.8934 - recall: 0.9353 - auc: 0.9735\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.3893 - accuracy: 0.9153 - binary_crossentropy: 0.3893 - precision: 0.8974 - recall: 0.9394 - auc: 0.9706\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.3716 - accuracy: 0.9215 - binary_crossentropy: 0.3716 - precision: 0.9038 - recall: 0.9449 - auc: 0.9777\n",
      "Loss of Train ......................................\n",
      "[0.676304042339325, 0.6537489295005798, 0.6301757097244263, 0.6083144545555115, 0.5814926624298096, 0.5640446543693542, 0.5471541285514832, 0.5260642766952515, 0.5119525790214539, 0.49539804458618164, 0.4819917380809784, 0.46450185775756836, 0.4497855007648468, 0.43704354763031006, 0.4322284758090973, 0.41950467228889465, 0.40583041310310364, 0.38971492648124695, 0.3892877697944641, 0.37160247564315796]\n",
      "Accuracy of Train ......................................\n",
      "[0.5881944298744202, 0.6041666865348816, 0.6354166865348816, 0.6819444298744202, 0.7083333134651184, 0.7333333492279053, 0.7659721970558167, 0.78125, 0.7986111044883728, 0.8159722089767456, 0.8326388597488403, 0.8472222089767456, 0.8576388955116272, 0.8805555701255798, 0.8770833611488342, 0.8833333253860474, 0.9006944298744202, 0.9111111164093018, 0.9152777791023254, 0.9215278029441833]\n",
      "Precision of Train ......................................\n",
      "[0.569926381111145, 0.584233283996582, 0.6125419735908508, 0.6583924293518066, 0.6861313581466675, 0.7111111283302307, 0.7398273944854736, 0.7552794814109802, 0.7773537039756775, 0.7943806052207947, 0.8129032254219055, 0.8277202248573303, 0.8459495306015015, 0.8551282286643982, 0.8635761737823486, 0.8642297387123108, 0.8810457587242126, 0.8934210538864136, 0.8973684310913086, 0.903820812702179]\n",
      "Recall of Train ......................................\n",
      "[0.7465564608573914, 0.7451790571212769, 0.7534435391426086, 0.7672176361083984, 0.7768595218658447, 0.7933884263038635, 0.8264462947845459, 0.8374655842781067, 0.8415977954864502, 0.8567492961883545, 0.8677685856819153, 0.8801652789115906, 0.8774104714393616, 0.918732762336731, 0.8980716466903687, 0.9118457436561584, 0.9283746480941772, 0.9352617263793945, 0.939393937587738, 0.944903552532196]\n",
      "AUC of Train ......................................\n",
      "[0.6224072575569153, 0.6608705520629883, 0.7030600309371948, 0.7473088502883911, 0.7918480634689331, 0.8213291764259338, 0.8476292490959167, 0.8724284768104553, 0.889231264591217, 0.9030343890190125, 0.9179832935333252, 0.9323998689651489, 0.9410192370414734, 0.9500842690467834, 0.9504894018173218, 0.9588879346847534, 0.9653863310813904, 0.9735427498817444, 0.9706200361251831, 0.977749228477478]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7970138877630234\n",
      " Loss:0.5018070429563523\n",
      " Precision:0.7767170459032059\n",
      " Recall:0.8523415982723236\n",
      " AUC:0.869865483045578\n",
      "Score for fold 3: loss of 0.43948793411254883; accuracy of 0.8361111283302307%\n",
      "[[156  30]\n",
      " [ 29 145]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1163.3121861 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:156,FN:29,TP:145,FP:30\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8361111111111111\n",
      " Loss:0.43948793411254883\n",
      " Precision:0.8285714285714286\n",
      " Recall:0.8333333333333334\n",
      " AUC:0.8382882882882883\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 25s 409ms/step - loss: 0.7256 - accuracy: 0.4993 - binary_crossentropy: 0.7256 - precision: 0.5104 - recall: 0.5678 - auc: 0.5037\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.6873 - accuracy: 0.5604 - binary_crossentropy: 0.6873 - precision: 0.5651 - recall: 0.6179 - auc: 0.5835\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.6648 - accuracy: 0.5882 - binary_crossentropy: 0.6648 - precision: 0.5924 - recall: 0.6301 - auc: 0.6268\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.6454 - accuracy: 0.6201 - binary_crossentropy: 0.6454 - precision: 0.6226 - recall: 0.6572 - auc: 0.6689\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 414ms/step - loss: 0.6232 - accuracy: 0.6438 - binary_crossentropy: 0.6232 - precision: 0.6471 - recall: 0.6707 - auc: 0.7080\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.6031 - accuracy: 0.6806 - binary_crossentropy: 0.6031 - precision: 0.6819 - recall: 0.7060 - auc: 0.7478\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.5745 - accuracy: 0.7257 - binary_crossentropy: 0.5745 - precision: 0.7260 - recall: 0.7466 - auc: 0.8019\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.5617 - accuracy: 0.7306 - binary_crossentropy: 0.5617 - precision: 0.7358 - recall: 0.7398 - auc: 0.8234\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.5476 - accuracy: 0.7639 - binary_crossentropy: 0.5476 - precision: 0.7734 - recall: 0.7629 - auc: 0.8475\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.5342 - accuracy: 0.7750 - binary_crossentropy: 0.5342 - precision: 0.7790 - recall: 0.7832 - auc: 0.8583\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.5120 - accuracy: 0.8021 - binary_crossentropy: 0.5120 - precision: 0.8065 - recall: 0.8076 - auc: 0.8895\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.5022 - accuracy: 0.8104 - binary_crossentropy: 0.5022 - precision: 0.8146 - recall: 0.8157 - auc: 0.8971\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.4871 - accuracy: 0.8299 - binary_crossentropy: 0.4871 - precision: 0.8265 - recall: 0.8455 - auc: 0.9175\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.4708 - accuracy: 0.8368 - binary_crossentropy: 0.4708 - precision: 0.8331 - recall: 0.8523 - auc: 0.9297\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.4616 - accuracy: 0.8542 - binary_crossentropy: 0.4616 - precision: 0.8465 - recall: 0.8740 - auc: 0.9327\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.4482 - accuracy: 0.8556 - binary_crossentropy: 0.4482 - precision: 0.8515 - recall: 0.8699 - auc: 0.9424\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.4292 - accuracy: 0.8889 - binary_crossentropy: 0.4292 - precision: 0.8916 - recall: 0.8916 - auc: 0.9597\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.4285 - accuracy: 0.8667 - binary_crossentropy: 0.4285 - precision: 0.8650 - recall: 0.8767 - auc: 0.9523\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.4114 - accuracy: 0.8958 - binary_crossentropy: 0.4114 - precision: 0.8868 - recall: 0.9133 - auc: 0.9666\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.4020 - accuracy: 0.9000 - binary_crossentropy: 0.4020 - precision: 0.8960 - recall: 0.9106 - auc: 0.9684\n",
      "Loss of Train ......................................\n",
      "[0.7256141901016235, 0.6872727274894714, 0.6648377776145935, 0.645350456237793, 0.623223602771759, 0.6031284928321838, 0.5745078921318054, 0.5617424249649048, 0.547627329826355, 0.5341648459434509, 0.5120161175727844, 0.5021501779556274, 0.48711106181144714, 0.4708164930343628, 0.4615703523159027, 0.44815316796302795, 0.42922067642211914, 0.42851799726486206, 0.41136854887008667, 0.40204688906669617]\n",
      "Accuracy of Train ......................................\n",
      "[0.4993055462837219, 0.5604166388511658, 0.5881944298744202, 0.6201388835906982, 0.643750011920929, 0.6805555820465088, 0.7256944179534912, 0.730555534362793, 0.7638888955116272, 0.7749999761581421, 0.8020833134651184, 0.8104166388511658, 0.8298611044883728, 0.8368055820465088, 0.8541666865348816, 0.855555534362793, 0.8888888955116272, 0.8666666746139526, 0.8958333134651184, 0.8999999761581421]\n",
      "Precision of Train ......................................\n",
      "[0.5103532075881958, 0.565055787563324, 0.5923566818237305, 0.6225930452346802, 0.6470588445663452, 0.6819371581077576, 0.7259551882743835, 0.7358490824699402, 0.7733516693115234, 0.7789757251739502, 0.8064952492713928, 0.8146143555641174, 0.826490044593811, 0.8331125974655151, 0.8464567065238953, 0.8514589071273804, 0.8915989398956299, 0.864973247051239, 0.8868421316146851, 0.8960000276565552]\n",
      "Recall of Train ......................................\n",
      "[0.5677506923675537, 0.6178861856460571, 0.630081295967102, 0.6571815609931946, 0.6707317233085632, 0.705962061882019, 0.7466124892234802, 0.7398374080657959, 0.7628726363182068, 0.783197820186615, 0.8075881004333496, 0.8157181739807129, 0.8455284833908081, 0.8523035049438477, 0.8739837408065796, 0.869918704032898, 0.8915989398956299, 0.8766937851905823, 0.913279116153717, 0.9105691313743591]\n",
      "AUC of Train ......................................\n",
      "[0.5037388205528259, 0.5835118293762207, 0.6267989277839661, 0.6689086556434631, 0.7080236077308655, 0.7478044033050537, 0.8019180297851562, 0.8233590126037598, 0.8474934101104736, 0.8582795262336731, 0.8894824385643005, 0.8971193432807922, 0.9174908995628357, 0.9297313690185547, 0.9326951503753662, 0.9423665404319763, 0.9597288370132446, 0.9523323178291321, 0.9666033387184143, 0.9683878421783447]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7563888818025589\n",
      " Loss:0.5360220611095429\n",
      " Precision:0.7575764298439026\n",
      " Recall:0.7769647777080536\n",
      " AUC:0.826288715004921\n",
      "Score for fold 4: loss of 0.4846947193145752; accuracy of 0.8194444179534912%\n",
      "[[161  37]\n",
      " [ 28 134]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1550.0408405 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:161,FN:28,TP:134,FP:37\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8194444444444444\n",
      " Loss:0.4846947193145752\n",
      " Precision:0.783625730994152\n",
      " Recall:0.8271604938271605\n",
      " AUC:0.8395061728395061\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 25s 410ms/step - loss: 0.7654 - accuracy: 0.4840 - binary_crossentropy: 0.7654 - precision: 0.4529 - recall: 0.1743 - auc: 0.4735\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.7336 - accuracy: 0.5215 - binary_crossentropy: 0.7336 - precision: 0.5440 - recall: 0.2413 - auc: 0.5280\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.6930 - accuracy: 0.5646 - binary_crossentropy: 0.6930 - precision: 0.6230 - recall: 0.3180 - auc: 0.6024\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.6684 - accuracy: 0.5868 - binary_crossentropy: 0.6684 - precision: 0.6473 - recall: 0.3738 - auc: 0.6494\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.6449 - accuracy: 0.6236 - binary_crossentropy: 0.6449 - precision: 0.6940 - recall: 0.4365 - auc: 0.6919\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.6141 - accuracy: 0.6757 - binary_crossentropy: 0.6141 - precision: 0.7500 - recall: 0.5230 - auc: 0.7498\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.5923 - accuracy: 0.7069 - binary_crossentropy: 0.5923 - precision: 0.7886 - recall: 0.5621 - auc: 0.7913\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.5751 - accuracy: 0.7236 - binary_crossentropy: 0.5751 - precision: 0.8038 - recall: 0.5886 - auc: 0.8205\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.5540 - accuracy: 0.7583 - binary_crossentropy: 0.5540 - precision: 0.8122 - recall: 0.6695 - auc: 0.8496\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.5353 - accuracy: 0.7792 - binary_crossentropy: 0.5353 - precision: 0.8308 - recall: 0.6987 - auc: 0.8728\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.5185 - accuracy: 0.7993 - binary_crossentropy: 0.5185 - precision: 0.8463 - recall: 0.7294 - auc: 0.8929\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.5052 - accuracy: 0.8125 - binary_crossentropy: 0.5052 - precision: 0.8476 - recall: 0.7601 - auc: 0.9031\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.4909 - accuracy: 0.8292 - binary_crossentropy: 0.4909 - precision: 0.8674 - recall: 0.7755 - auc: 0.9182\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.4776 - accuracy: 0.8493 - binary_crossentropy: 0.4776 - precision: 0.8776 - recall: 0.8103 - auc: 0.9284\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.4605 - accuracy: 0.8667 - binary_crossentropy: 0.4605 - precision: 0.8947 - recall: 0.8298 - auc: 0.9446\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.4467 - accuracy: 0.8764 - binary_crossentropy: 0.4467 - precision: 0.9004 - recall: 0.8452 - auc: 0.9533\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.4376 - accuracy: 0.8681 - binary_crossentropy: 0.4376 - precision: 0.8836 - recall: 0.8466 - auc: 0.9512\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.4269 - accuracy: 0.8924 - binary_crossentropy: 0.4269 - precision: 0.9084 - recall: 0.8717 - auc: 0.9608\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.4118 - accuracy: 0.8882 - binary_crossentropy: 0.4118 - precision: 0.8971 - recall: 0.8759 - auc: 0.9647\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.3954 - accuracy: 0.9194 - binary_crossentropy: 0.3954 - precision: 0.9287 - recall: 0.9079 - auc: 0.9790\n",
      "Loss of Train ......................................\n",
      "[0.7654088139533997, 0.733626127243042, 0.6930149793624878, 0.6683841943740845, 0.6448569893836975, 0.6141403913497925, 0.5922800302505493, 0.5751035213470459, 0.5540194511413574, 0.5353236794471741, 0.5185169577598572, 0.5052178502082825, 0.4909440279006958, 0.4776390492916107, 0.4605402946472168, 0.4467241168022156, 0.4376487731933594, 0.42691391706466675, 0.4117915630340576, 0.395446240901947]\n",
      "Accuracy of Train ......................................\n",
      "[0.48402777314186096, 0.5215277671813965, 0.5645833611488342, 0.5868055820465088, 0.6236110925674438, 0.675694465637207, 0.706944465637207, 0.7236111164093018, 0.7583333253860474, 0.7791666388511658, 0.7993055582046509, 0.8125, 0.8291666507720947, 0.8493055701255798, 0.8666666746139526, 0.8763889074325562, 0.8680555820465088, 0.8923611044883728, 0.8881944417953491, 0.9194444417953491]\n",
      "Precision of Train ......................................\n",
      "[0.4528985619544983, 0.544025182723999, 0.6229507923126221, 0.6473429799079895, 0.6940132975578308, 0.75, 0.7886496782302856, 0.8038095235824585, 0.8121827244758606, 0.8308457732200623, 0.8462783098220825, 0.8475894331932068, 0.8673946857452393, 0.8776435256004333, 0.8947368264198303, 0.9004457592964172, 0.8835516571998596, 0.9084302186965942, 0.8971428275108337, 0.9286733269691467]\n",
      "Recall of Train ......................................\n",
      "[0.17433752119541168, 0.241283118724823, 0.3179916441440582, 0.37377962470054626, 0.4365411400794983, 0.5230125784873962, 0.5620641708374023, 0.5885634422302246, 0.6694560647010803, 0.6987447738647461, 0.7294281721115112, 0.7601115703582764, 0.7754532694816589, 0.8103207945823669, 0.8298465609550476, 0.8451882600784302, 0.8465830087661743, 0.8716875910758972, 0.8758716583251953, 0.9079498052597046]\n",
      "AUC of Train ......................................\n",
      "[0.4734669625759125, 0.5279971957206726, 0.602400541305542, 0.6494258046150208, 0.6918898224830627, 0.7498499751091003, 0.7912724614143372, 0.8204955458641052, 0.8495681285858154, 0.8727755546569824, 0.892909049987793, 0.9030702710151672, 0.9181833863258362, 0.9283590912818909, 0.9445996880531311, 0.9533238410949707, 0.9511749744415283, 0.9608163237571716, 0.9646676182746887, 0.9789917469024658]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7512847259640694\n",
      " Loss:0.547377048432827\n",
      " Precision:0.7899302542209625\n",
      " Recall:0.6419107384979725\n",
      " AUC:0.8212618991732598\n",
      "Score for fold 5: loss of 0.473774790763855; accuracy of 0.8305555582046509%\n",
      "[[151  26]\n",
      " [ 35 148]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1937.4071948 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:151,FN:35,TP:148,FP:26\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8305555555555556\n",
      " Loss:0.473774790763855\n",
      " Precision:0.8505747126436781\n",
      " Recall:0.8087431693989071\n",
      " AUC:0.8102855631940772\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.7682291626930237 - Loss: 0.5298609286546707\n",
      "> Fold 1 - Precision: 0.7739268958568573\n",
      "> Fold 1 - Recall: 0.7212643682956695\n",
      "> Fold 1 - AUC: 0.836368876695633\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.7666666666666667 - Loss: 0.49955445528030396\n",
      "> Fold 1 - Precision: 0.8260869565217391\n",
      "> Fold 1 - Recall: 0.7450980392156863\n",
      "> Fold 1 - AUC: 0.7248217468805704\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.740868054330349 - Loss: 0.5537654817104339\n",
      "> Fold 2 - Precision: 0.7287730544805526\n",
      "> Fold 2 - Recall: 0.816044270992279\n",
      "> Fold 2 - AUC: 0.8071662545204162\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8222222222222222 - Loss: 0.4797848165035248\n",
      "> Fold 2 - Precision: 0.8087431693989071\n",
      "> Fold 2 - Recall: 0.8361581920903954\n",
      "> Fold 2 - AUC: 0.8361581920903954\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.7970138877630234 - Loss: 0.5018070429563523\n",
      "> Fold 3 - Precision: 0.7767170459032059\n",
      "> Fold 3 - Recall: 0.8523415982723236\n",
      "> Fold 3 - AUC: 0.869865483045578\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.8361111111111111 - Loss: 0.43948793411254883\n",
      "> Fold 3 - Precision: 0.8285714285714286\n",
      "> Fold 3 - Recall: 0.8333333333333334\n",
      "> Fold 3 - AUC: 0.8382882882882883\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.7563888818025589 - Loss: 0.5360220611095429\n",
      "> Fold 4 - Precision: 0.7575764298439026\n",
      "> Fold 4 - Recall: 0.7769647777080536\n",
      "> Fold 4 - AUC: 0.826288715004921\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.8194444444444444 - Loss: 0.4846947193145752\n",
      "> Fold 4 - Precision: 0.783625730994152\n",
      "> Fold 4 - Recall: 0.8271604938271605\n",
      "> Fold 4 - AUC: 0.8395061728395061\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.7512847259640694 - Loss: 0.547377048432827\n",
      "> Fold 5 - Precision: 0.7899302542209625\n",
      "> Fold 5 - Recall: 0.6419107384979725\n",
      "> Fold 5 - AUC: 0.8212618991732598\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.8305555555555556 - Loss: 0.473774790763855\n",
      "> Fold 5 - Precision: 0.8505747126436781\n",
      "> Fold 5 - Recall: 0.8087431693989071\n",
      "> Fold 5 - AUC: 0.8102855631940772\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.7627569425106049 (+- 0.019260170649253238)\n",
      "> Loss: 0.5337665125727653 (+- 0.018038593271499384)\n",
      "> Precision: 0.7653847360610961 (+- 0.021001224136734494)\n",
      "> Recall: 0.7617051507532597 (+- 0.07400908040963342)\n",
      "> AUC: 0.8321902456879616 (+- 0.021058686677723565)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.8150000000000001 (+- 0.024882439640620757)\n",
      "> Loss: 0.4754593431949615 (+- 0.0199065632698689)\n",
      "> Precision: 0.819520399625981 (+- 0.02233377298619217)\n",
      "> Recall: 0.8100986455730965 (+- 0.03387321504769651)\n",
      "> AUC: 0.8098119926585676 (+- 0.04384137799013029)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 740 FN SUM: 173 TP SUM: 727 FP SUM: 160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(ResNet152V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa221c",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134515bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 23s 347ms/step - loss: 0.6802 - accuracy: 0.5667 - binary_crossentropy: 0.6802 - precision: 0.6108 - recall: 0.3338 - auc: 0.6093\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 15s 343ms/step - loss: 0.6785 - accuracy: 0.5667 - binary_crossentropy: 0.6785 - precision: 0.6150 - recall: 0.3239 - auc: 0.6255\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 16s 348ms/step - loss: 0.6775 - accuracy: 0.5653 - binary_crossentropy: 0.6775 - precision: 0.6160 - recall: 0.3141 - auc: 0.6315\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.6762 - accuracy: 0.5660 - binary_crossentropy: 0.6762 - precision: 0.6197 - recall: 0.3099 - auc: 0.6336\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.6764 - accuracy: 0.5667 - binary_crossentropy: 0.6764 - precision: 0.6257 - recall: 0.3014 - auc: 0.6353\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.6739 - accuracy: 0.5715 - binary_crossentropy: 0.6739 - precision: 0.6356 - recall: 0.3070 - auc: 0.6506\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 16s 347ms/step - loss: 0.6738 - accuracy: 0.5840 - binary_crossentropy: 0.6738 - precision: 0.6599 - recall: 0.3225 - auc: 0.6485\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.6706 - accuracy: 0.5917 - binary_crossentropy: 0.6706 - precision: 0.6743 - recall: 0.3324 - auc: 0.6724\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 16s 348ms/step - loss: 0.6675 - accuracy: 0.5944 - binary_crossentropy: 0.6675 - precision: 0.6790 - recall: 0.3366 - auc: 0.6816\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 16s 352ms/step - loss: 0.6674 - accuracy: 0.5965 - binary_crossentropy: 0.6674 - precision: 0.6838 - recall: 0.3380 - auc: 0.6849\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 16s 350ms/step - loss: 0.6667 - accuracy: 0.5938 - binary_crossentropy: 0.6667 - precision: 0.6844 - recall: 0.3268 - auc: 0.6923\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 16s 352ms/step - loss: 0.6637 - accuracy: 0.5986 - binary_crossentropy: 0.6637 - precision: 0.6908 - recall: 0.3366 - auc: 0.7025\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 16s 351ms/step - loss: 0.6629 - accuracy: 0.6021 - binary_crossentropy: 0.6629 - precision: 0.7009 - recall: 0.3366 - auc: 0.7115\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.6629 - accuracy: 0.6132 - binary_crossentropy: 0.6629 - precision: 0.7257 - recall: 0.3465 - auc: 0.7072\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6601 - accuracy: 0.6118 - binary_crossentropy: 0.6601 - precision: 0.7309 - recall: 0.3366 - auc: 0.7213\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.6568 - accuracy: 0.6271 - binary_crossentropy: 0.6568 - precision: 0.7507 - recall: 0.3648 - auc: 0.7386\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 16s 351ms/step - loss: 0.6555 - accuracy: 0.6181 - binary_crossentropy: 0.6555 - precision: 0.7424 - recall: 0.3451 - auc: 0.7446\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 16s 360ms/step - loss: 0.6573 - accuracy: 0.6257 - binary_crossentropy: 0.6573 - precision: 0.7478 - recall: 0.3634 - auc: 0.7351\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6557 - accuracy: 0.6222 - binary_crossentropy: 0.6557 - precision: 0.7385 - recall: 0.3620 - auc: 0.7393\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6525 - accuracy: 0.6167 - binary_crossentropy: 0.6525 - precision: 0.7219 - recall: 0.3620 - auc: 0.7459\n",
      "Loss of Train ......................................\n",
      "[0.6802218556404114, 0.6785270571708679, 0.6774592995643616, 0.6762147545814514, 0.6764202117919922, 0.6739373803138733, 0.6738023161888123, 0.6706015467643738, 0.6675145626068115, 0.667422890663147, 0.6666983962059021, 0.6637187004089355, 0.6629036664962769, 0.6628752946853638, 0.6601352095603943, 0.6567602753639221, 0.6555331349372864, 0.6572849154472351, 0.6556557416915894, 0.6525375843048096]\n",
      "Accuracy of Train ......................................\n",
      "[0.5666666626930237, 0.5666666626930237, 0.5652777552604675, 0.5659722089767456, 0.5666666626930237, 0.5715277791023254, 0.5840277671813965, 0.5916666388511658, 0.5944444537162781, 0.5965277552604675, 0.59375, 0.5986111164093018, 0.6020833253860474, 0.613194465637207, 0.6118055582046509, 0.6270833611488342, 0.6180555820465088, 0.6256944537162781, 0.6222222447395325, 0.6166666746139526]\n",
      "Precision of Train ......................................\n",
      "[0.6108247637748718, 0.614973247051239, 0.6160221099853516, 0.6197183132171631, 0.6257309913635254, 0.6355684995651245, 0.6599423885345459, 0.6742857098579407, 0.6789772510528564, 0.6837607026100159, 0.6843658089637756, 0.6907514333724976, 0.7008797526359558, 0.7256637215614319, 0.7308868765830994, 0.7507246136665344, 0.7424242496490479, 0.747826099395752, 0.7385057210922241, 0.7219101190567017]\n",
      "Recall of Train ......................................\n",
      "[0.33380281925201416, 0.3239436745643616, 0.3140845000743866, 0.30985915660858154, 0.30140843987464905, 0.3070422410964966, 0.3225352168083191, 0.3323943614959717, 0.33661970496177673, 0.3380281627178192, 0.32676056027412415, 0.33661970496177673, 0.33661970496177673, 0.3464788794517517, 0.33661970496177673, 0.3647887408733368, 0.34507042169570923, 0.3633802831172943, 0.36197182536125183, 0.36197182536125183]\n",
      "AUC of Train ......................................\n",
      "[0.6092745065689087, 0.6254775524139404, 0.6314933896064758, 0.633617639541626, 0.6353463530540466, 0.6506078243255615, 0.6484998464584351, 0.6724165678024292, 0.6815743446350098, 0.6849189400672913, 0.6923152804374695, 0.702462911605835, 0.7114585638046265, 0.7071810960769653, 0.7213091254234314, 0.7385963797569275, 0.7445813417434692, 0.7350578904151917, 0.7392822504043579, 0.7458932995796204]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.5949305564165115\n",
      " Loss:0.6668112397193908\n",
      " Precision:0.6826871186494827\n",
      " Recall:0.3349999964237213\n",
      " AUC:0.6855682551860809\n",
      "Score for fold 1: loss of 0.6500741839408875; accuracy of 0.6305555701255798%\n",
      "[[155  15]\n",
      " [118  72]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 338.673887 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:155,FN:118,TP:72,FP:15\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6305555555555555\n",
      " Loss:0.6500741839408875\n",
      " Precision:0.8275862068965517\n",
      " Recall:0.37894736842105264\n",
      " AUC:0.4733564680933102\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 2049      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 19s 348ms/step - loss: 0.7235 - accuracy: 0.4382 - binary_crossentropy: 0.7235 - precision: 0.4602 - recall: 0.7153 - auc: 0.3951\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 345ms/step - loss: 0.7230 - accuracy: 0.4514 - binary_crossentropy: 0.7230 - precision: 0.4684 - recall: 0.7208 - auc: 0.3989\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 16s 350ms/step - loss: 0.7169 - accuracy: 0.4528 - binary_crossentropy: 0.7169 - precision: 0.4689 - recall: 0.7111 - auc: 0.4179\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.7136 - accuracy: 0.4486 - binary_crossentropy: 0.7136 - precision: 0.4652 - recall: 0.6861 - auc: 0.4353\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.7137 - accuracy: 0.4576 - binary_crossentropy: 0.7137 - precision: 0.4705 - recall: 0.6764 - auc: 0.4344\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 16s 345ms/step - loss: 0.7101 - accuracy: 0.4785 - binary_crossentropy: 0.7101 - precision: 0.4847 - recall: 0.6819 - auc: 0.4494\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 15s 344ms/step - loss: 0.7062 - accuracy: 0.4924 - binary_crossentropy: 0.7062 - precision: 0.4945 - recall: 0.6889 - auc: 0.4689\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 16s 347ms/step - loss: 0.7036 - accuracy: 0.4819 - binary_crossentropy: 0.7036 - precision: 0.4864 - recall: 0.6472 - auc: 0.4714\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 16s 345ms/step - loss: 0.7001 - accuracy: 0.4958 - binary_crossentropy: 0.7001 - precision: 0.4968 - recall: 0.6569 - auc: 0.4954\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 16s 346ms/step - loss: 0.6985 - accuracy: 0.5049 - binary_crossentropy: 0.6985 - precision: 0.5039 - recall: 0.6236 - auc: 0.4992\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 16s 346ms/step - loss: 0.6956 - accuracy: 0.5083 - binary_crossentropy: 0.6956 - precision: 0.5066 - recall: 0.6403 - auc: 0.5177\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 16s 346ms/step - loss: 0.6952 - accuracy: 0.5063 - binary_crossentropy: 0.6952 - precision: 0.5053 - recall: 0.6014 - auc: 0.5154\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 16s 346ms/step - loss: 0.6917 - accuracy: 0.5271 - binary_crossentropy: 0.6917 - precision: 0.5234 - recall: 0.6069 - auc: 0.5357\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 16s 349ms/step - loss: 0.6918 - accuracy: 0.5299 - binary_crossentropy: 0.6918 - precision: 0.5265 - recall: 0.5931 - auc: 0.5344\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.6897 - accuracy: 0.5417 - binary_crossentropy: 0.6897 - precision: 0.5359 - recall: 0.6222 - auc: 0.5517\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6846 - accuracy: 0.5535 - binary_crossentropy: 0.6846 - precision: 0.5478 - recall: 0.6125 - auc: 0.5793\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.6852 - accuracy: 0.5493 - binary_crossentropy: 0.6852 - precision: 0.5473 - recall: 0.5708 - auc: 0.5714\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6799 - accuracy: 0.5847 - binary_crossentropy: 0.6799 - precision: 0.5831 - recall: 0.5944 - auc: 0.6061\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.6793 - accuracy: 0.5625 - binary_crossentropy: 0.6793 - precision: 0.5611 - recall: 0.5736 - auc: 0.5987\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6791 - accuracy: 0.5694 - binary_crossentropy: 0.6791 - precision: 0.5700 - recall: 0.5653 - auc: 0.6021\n",
      "Loss of Train ......................................\n",
      "[0.723515510559082, 0.7230390906333923, 0.716863751411438, 0.7136163711547852, 0.7136889696121216, 0.7100852727890015, 0.7061858177185059, 0.7036191821098328, 0.7000573873519897, 0.6984955072402954, 0.6955901980400085, 0.6951960921287537, 0.6916958093643188, 0.6918162107467651, 0.6897461414337158, 0.6845941543579102, 0.6851993799209595, 0.6799139380455017, 0.6793391108512878, 0.6790651679039001]\n",
      "Accuracy of Train ......................................\n",
      "[0.4381944537162781, 0.4513888955116272, 0.45277777314186096, 0.4486111104488373, 0.4576388895511627, 0.4784722328186035, 0.4923610985279083, 0.4819444417953491, 0.4958333373069763, 0.5048611164093018, 0.5083333253860474, 0.5062500238418579, 0.5270833373069763, 0.5298610925674438, 0.5416666865348816, 0.5534722208976746, 0.5493055582046509, 0.5847222208976746, 0.5625, 0.5694444179534912]\n",
      "Precision of Train ......................................\n",
      "[0.46023234724998474, 0.46841156482696533, 0.46886447072029114, 0.465160071849823, 0.4705314040184021, 0.48469892144203186, 0.4945164620876312, 0.4864300489425659, 0.4968487322330475, 0.5039281845092773, 0.5065934062004089, 0.505250871181488, 0.5233532786369324, 0.52651047706604, 0.5358851552009583, 0.5478261113166809, 0.5472702980041504, 0.583106279373169, 0.561141312122345, 0.5700280070304871]\n",
      "Recall of Train ......................................\n",
      "[0.7152777910232544, 0.7208333611488342, 0.7111111283302307, 0.6861110925674438, 0.6763888597488403, 0.6819444298744202, 0.6888889074325562, 0.6472222208976746, 0.6569444537162781, 0.6236110925674438, 0.6402778029441833, 0.6013888716697693, 0.6069444417953491, 0.5930555462837219, 0.6222222447395325, 0.612500011920929, 0.5708333253860474, 0.5944444537162781, 0.5736111402511597, 0.5652777552604675]\n",
      "AUC of Train ......................................\n",
      "[0.39510512351989746, 0.3989332318305969, 0.4178617000579834, 0.4352816641330719, 0.43439626693725586, 0.4494405686855316, 0.4688965976238251, 0.4714004695415497, 0.49540606141090393, 0.4992014169692993, 0.5177391767501831, 0.5153954029083252, 0.5356538891792297, 0.5343635082244873, 0.5517332553863525, 0.579333484172821, 0.5713666677474976, 0.6060802340507507, 0.5987480282783508, 0.6020842790603638]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.5067361116409301\n",
      " Loss:0.6990661531686783\n",
      " Precision:0.510329370200634\n",
      " Recall:0.6394444465637207\n",
      " AUC:0.5039210513234138\n",
      "Score for fold 2: loss of 0.6719174385070801; accuracy of 0.5944444537162781%\n",
      "[[105  75]\n",
      " [ 71 109]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 663.0946586 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:105,FN:71,TP:109,FP:75\n",
      "Test of epochs .................................\n",
      " Accuracy:0.5944444444444444\n",
      " Loss:0.6719174385070801\n",
      " Precision:0.592391304347826\n",
      " Recall:0.6055555555555555\n",
      " AUC:0.6010732323232323\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 19s 363ms/step - loss: 0.6746 - accuracy: 0.5597 - binary_crossentropy: 0.6746 - precision: 0.6786 - recall: 0.2129 - auc: 0.6623\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 360ms/step - loss: 0.6732 - accuracy: 0.5562 - binary_crossentropy: 0.6732 - precision: 0.6761 - recall: 0.2017 - auc: 0.6748\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.6725 - accuracy: 0.5646 - binary_crossentropy: 0.6725 - precision: 0.7062 - recall: 0.2087 - auc: 0.6711\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6705 - accuracy: 0.5722 - binary_crossentropy: 0.6705 - precision: 0.7402 - recall: 0.2115 - auc: 0.6895\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.6716 - accuracy: 0.5750 - binary_crossentropy: 0.6716 - precision: 0.7339 - recall: 0.2241 - auc: 0.6808\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6677 - accuracy: 0.5729 - binary_crossentropy: 0.6677 - precision: 0.7124 - recall: 0.2325 - auc: 0.6973\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 16s 360ms/step - loss: 0.6662 - accuracy: 0.5972 - binary_crossentropy: 0.6662 - precision: 0.7680 - recall: 0.2689 - auc: 0.7087\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.6622 - accuracy: 0.6042 - binary_crossentropy: 0.6622 - precision: 0.8077 - recall: 0.2647 - auc: 0.7321\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 16s 360ms/step - loss: 0.6636 - accuracy: 0.5931 - binary_crossentropy: 0.6636 - precision: 0.7667 - recall: 0.2577 - auc: 0.7224\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.6595 - accuracy: 0.5931 - binary_crossentropy: 0.6595 - precision: 0.7689 - recall: 0.2563 - auc: 0.7386\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6588 - accuracy: 0.5903 - binary_crossentropy: 0.6588 - precision: 0.7460 - recall: 0.2633 - auc: 0.7454\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.6584 - accuracy: 0.6056 - binary_crossentropy: 0.6584 - precision: 0.7808 - recall: 0.2843 - auc: 0.7411\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.6570 - accuracy: 0.6222 - binary_crossentropy: 0.6570 - precision: 0.8295 - recall: 0.2997 - auc: 0.7524\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 16s 364ms/step - loss: 0.6546 - accuracy: 0.6181 - binary_crossentropy: 0.6546 - precision: 0.8130 - recall: 0.2983 - auc: 0.7638\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.6526 - accuracy: 0.6215 - binary_crossentropy: 0.6526 - precision: 0.8165 - recall: 0.3053 - auc: 0.7733\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6519 - accuracy: 0.6160 - binary_crossentropy: 0.6519 - precision: 0.8132 - recall: 0.2927 - auc: 0.7816\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 16s 364ms/step - loss: 0.6516 - accuracy: 0.6208 - binary_crossentropy: 0.6516 - precision: 0.8158 - recall: 0.3039 - auc: 0.7752\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.6479 - accuracy: 0.6417 - binary_crossentropy: 0.6479 - precision: 0.8438 - recall: 0.3403 - auc: 0.7896\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 16s 364ms/step - loss: 0.6473 - accuracy: 0.6292 - binary_crossentropy: 0.6473 - precision: 0.8285 - recall: 0.3179 - auc: 0.7939\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.6481 - accuracy: 0.6278 - binary_crossentropy: 0.6481 - precision: 0.8179 - recall: 0.3207 - auc: 0.7823\n",
      "Loss of Train ......................................\n",
      "[0.6745941042900085, 0.6732012033462524, 0.672511637210846, 0.6704564690589905, 0.6716294884681702, 0.6677483320236206, 0.6661973595619202, 0.6621537804603577, 0.6635927557945251, 0.6595346927642822, 0.6587767004966736, 0.6584352254867554, 0.656988799571991, 0.6545826196670532, 0.6526445746421814, 0.6519327759742737, 0.651621401309967, 0.6479219198226929, 0.6473129391670227, 0.6480560898780823]\n",
      "Accuracy of Train ......................................\n",
      "[0.5597222447395325, 0.5562499761581421, 0.5645833611488342, 0.5722222328186035, 0.574999988079071, 0.5729166865348816, 0.5972222089767456, 0.6041666865348816, 0.5930555462837219, 0.5930555462837219, 0.5902777910232544, 0.605555534362793, 0.6222222447395325, 0.6180555820465088, 0.6215277910232544, 0.6159722208976746, 0.6208333373069763, 0.6416666507720947, 0.6291666626930237, 0.6277777552604675]\n",
      "Precision of Train ......................................\n",
      "[0.6785714030265808, 0.6760563254356384, 0.7061611413955688, 0.7401960492134094, 0.7339449524879456, 0.7124463319778442, 0.7680000066757202, 0.807692289352417, 0.7666666507720947, 0.7689075469970703, 0.7460317611694336, 0.7807692289352417, 0.8294573426246643, 0.8129770755767822, 0.8164793848991394, 0.8132295608520508, 0.8157894611358643, 0.84375, 0.8284671306610107, 0.8178571462631226]\n",
      "Recall of Train ......................................\n",
      "[0.21288515627384186, 0.20168067514896393, 0.20868347585201263, 0.21148459613323212, 0.2240896373987198, 0.23249299824237823, 0.2689075767993927, 0.2647058963775635, 0.25770309567451477, 0.25630253553390503, 0.26330533623695374, 0.28431373834609985, 0.299719899892807, 0.29831933975219727, 0.30532214045524597, 0.2927170991897583, 0.30392158031463623, 0.3403361439704895, 0.31792718172073364, 0.3207283020019531]\n",
      "AUC of Train ......................................\n",
      "[0.6623145341873169, 0.6747642755508423, 0.671084463596344, 0.689486563205719, 0.6807725429534912, 0.6972928047180176, 0.7086632251739502, 0.7320849299430847, 0.7224200367927551, 0.7386402487754822, 0.7454000115394592, 0.741112470626831, 0.752440333366394, 0.7638252377510071, 0.7732963562011719, 0.7815675139427185, 0.7751637697219849, 0.7896111607551575, 0.7938552498817444, 0.782301664352417]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.5990625023841858\n",
      " Loss:0.6604946434497834\n",
      " Precision:0.7731725394725799\n",
      " Recall:0.26827732026576995\n",
      " AUC:0.7338048696517945\n",
      "Score for fold 3: loss of 0.6461363434791565; accuracy of 0.6111111044883728%\n",
      "[[165   9]\n",
      " [131  55]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 997.0245878 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:165,FN:131,TP:55,FP:9\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6111111111111112\n",
      " Loss:0.6461363434791565\n",
      " Precision:0.859375\n",
      " Recall:0.2956989247311828\n",
      " AUC:0.4265656785818076\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 19s 363ms/step - loss: 0.6904 - accuracy: 0.5542 - binary_crossentropy: 0.6904 - precision: 0.5469 - recall: 0.6676 - auc: 0.5496\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.6896 - accuracy: 0.5569 - binary_crossentropy: 0.6896 - precision: 0.5498 - recall: 0.6621 - auc: 0.5496\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.6882 - accuracy: 0.5535 - binary_crossentropy: 0.6882 - precision: 0.5493 - recall: 0.6303 - auc: 0.5605\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 16s 364ms/step - loss: 0.6830 - accuracy: 0.5743 - binary_crossentropy: 0.6830 - precision: 0.5662 - recall: 0.6607 - auc: 0.5840\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 16s 364ms/step - loss: 0.6809 - accuracy: 0.5715 - binary_crossentropy: 0.6809 - precision: 0.5670 - recall: 0.6303 - auc: 0.5994\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.6794 - accuracy: 0.5750 - binary_crossentropy: 0.6794 - precision: 0.5712 - recall: 0.6248 - auc: 0.6032\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.6769 - accuracy: 0.5854 - binary_crossentropy: 0.6769 - precision: 0.5833 - recall: 0.6179 - auc: 0.6135\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.6749 - accuracy: 0.6035 - binary_crossentropy: 0.6749 - precision: 0.6021 - recall: 0.6262 - auc: 0.6322\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.6758 - accuracy: 0.5993 - binary_crossentropy: 0.6758 - precision: 0.6014 - recall: 0.6055 - auc: 0.6252\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.6725 - accuracy: 0.6049 - binary_crossentropy: 0.6725 - precision: 0.6054 - recall: 0.6179 - auc: 0.6403\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.6730 - accuracy: 0.5993 - binary_crossentropy: 0.6730 - precision: 0.6054 - recall: 0.5862 - auc: 0.6363\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 16s 364ms/step - loss: 0.6718 - accuracy: 0.5896 - binary_crossentropy: 0.6718 - precision: 0.5954 - recall: 0.5766 - auc: 0.6433\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.6684 - accuracy: 0.6229 - binary_crossentropy: 0.6684 - precision: 0.6319 - recall: 0.6014 - auc: 0.6637\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.6651 - accuracy: 0.6271 - binary_crossentropy: 0.6651 - precision: 0.6407 - recall: 0.5903 - auc: 0.6758\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.6635 - accuracy: 0.6278 - binary_crossentropy: 0.6635 - precision: 0.6417 - recall: 0.5903 - auc: 0.6846\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6599 - accuracy: 0.6458 - binary_crossentropy: 0.6599 - precision: 0.6636 - recall: 0.6014 - auc: 0.7024\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.6601 - accuracy: 0.6438 - binary_crossentropy: 0.6601 - precision: 0.6672 - recall: 0.5834 - auc: 0.6973\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6573 - accuracy: 0.6424 - binary_crossentropy: 0.6573 - precision: 0.6661 - recall: 0.5807 - auc: 0.7101\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.6588 - accuracy: 0.6472 - binary_crossentropy: 0.6588 - precision: 0.6764 - recall: 0.5738 - auc: 0.7023\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.6569 - accuracy: 0.6458 - binary_crossentropy: 0.6569 - precision: 0.6677 - recall: 0.5903 - auc: 0.7094\n",
      "Loss of Train ......................................\n",
      "[0.690367579460144, 0.6896372437477112, 0.6881523728370667, 0.683034360408783, 0.6809329390525818, 0.6794255375862122, 0.6769057512283325, 0.6749390363693237, 0.6758338809013367, 0.672454297542572, 0.6730162501335144, 0.6718375086784363, 0.6683921217918396, 0.6651493906974792, 0.6635061502456665, 0.659881055355072, 0.6601089835166931, 0.657290518283844, 0.6587860584259033, 0.6568808555603027]\n",
      "Accuracy of Train ......................................\n",
      "[0.5541666746139526, 0.5569444298744202, 0.5534722208976746, 0.574305534362793, 0.5715277791023254, 0.574999988079071, 0.5854166746139526, 0.6034722328186035, 0.5993055701255798, 0.6048611402511597, 0.5993055701255798, 0.5895833373069763, 0.6229166388511658, 0.6270833611488342, 0.6277777552604675, 0.6458333134651184, 0.643750011920929, 0.6423611044883728, 0.6472222208976746, 0.6458333134651184]\n",
      "Precision of Train ......................................\n",
      "[0.5468926429748535, 0.5498281717300415, 0.5492788553237915, 0.5661938786506653, 0.5669975280761719, 0.5712484121322632, 0.5833333134651184, 0.6021220088005066, 0.6013698577880859, 0.6054053902626038, 0.6054130792617798, 0.5954415798187256, 0.6318840384483337, 0.6407185792922974, 0.6416791677474976, 0.6636224985122681, 0.6671923995018005, 0.6661392450332642, 0.6764227747917175, 0.6677067279815674]\n",
      "Recall of Train ......................................\n",
      "[0.6675862073898315, 0.6620689630508423, 0.630344808101654, 0.660689651966095, 0.630344808101654, 0.6248275637626648, 0.6179310083389282, 0.6262068748474121, 0.6055172681808472, 0.6179310083389282, 0.5862069129943848, 0.5765517354011536, 0.6013793349266052, 0.5903448462486267, 0.5903448462486267, 0.6013793349266052, 0.5834482908248901, 0.5806896686553955, 0.5737931132316589, 0.5903448462486267]\n",
      "AUC of Train ......................................\n",
      "[0.5496156215667725, 0.5495712757110596, 0.5605382323265076, 0.5839595198631287, 0.5993508100509644, 0.6031724214553833, 0.6135307550430298, 0.6322421431541443, 0.6252259612083435, 0.6402508020401001, 0.6363182663917542, 0.6432977914810181, 0.6637288928031921, 0.6758389472961426, 0.6846192479133606, 0.7024355530738831, 0.697340726852417, 0.7100911736488342, 0.7022695541381836, 0.7094439268112183]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.6035069435834884\n",
      " Loss:0.6723265945911407\n",
      " Precision:0.6099445074796677\n",
      " Recall:0.6108965545892715\n",
      " AUC:0.6391420811414719\n",
      "Score for fold 4: loss of 0.6434993147850037; accuracy of 0.6666666865348816%\n",
      "[[140  45]\n",
      " [ 75 100]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1332.4845496 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:140,FN:75,TP:100,FP:45\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6666666666666666\n",
      " Loss:0.6434993147850037\n",
      " Precision:0.6896551724137931\n",
      " Recall:0.5714285714285714\n",
      " AUC:0.6112956810631229\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 19s 358ms/step - loss: 0.7018 - accuracy: 0.4833 - binary_crossentropy: 0.7018 - precision: 0.4878 - recall: 0.3557 - auc: 0.4846\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.7015 - accuracy: 0.4896 - binary_crossentropy: 0.7015 - precision: 0.4962 - recall: 0.3543 - auc: 0.4865\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.6991 - accuracy: 0.4833 - binary_crossentropy: 0.6991 - precision: 0.4879 - recall: 0.3570 - auc: 0.4948\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.6980 - accuracy: 0.4868 - binary_crossentropy: 0.6980 - precision: 0.4922 - recall: 0.3434 - auc: 0.4966\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.6989 - accuracy: 0.4958 - binary_crossentropy: 0.6989 - precision: 0.5048 - recall: 0.3570 - auc: 0.5040\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6936 - accuracy: 0.5160 - binary_crossentropy: 0.6936 - precision: 0.5351 - recall: 0.3543 - auc: 0.5343\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.6965 - accuracy: 0.5063 - binary_crossentropy: 0.6965 - precision: 0.5201 - recall: 0.3543 - auc: 0.5182\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.6933 - accuracy: 0.5174 - binary_crossentropy: 0.6933 - precision: 0.5390 - recall: 0.3406 - auc: 0.5361\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.6920 - accuracy: 0.5104 - binary_crossentropy: 0.6920 - precision: 0.5279 - recall: 0.3365 - auc: 0.5411\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.6909 - accuracy: 0.5215 - binary_crossentropy: 0.6909 - precision: 0.5449 - recall: 0.3488 - auc: 0.5499\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6893 - accuracy: 0.5188 - binary_crossentropy: 0.6893 - precision: 0.5401 - recall: 0.3502 - auc: 0.5579\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.6856 - accuracy: 0.5361 - binary_crossentropy: 0.6856 - precision: 0.5689 - recall: 0.3557 - auc: 0.5831\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 16s 360ms/step - loss: 0.6804 - accuracy: 0.5611 - binary_crossentropy: 0.6804 - precision: 0.6055 - recall: 0.3885 - auc: 0.6132\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6829 - accuracy: 0.5736 - binary_crossentropy: 0.6829 - precision: 0.6263 - recall: 0.3967 - auc: 0.6033\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6794 - accuracy: 0.5639 - binary_crossentropy: 0.6794 - precision: 0.6173 - recall: 0.3707 - auc: 0.6152\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.6823 - accuracy: 0.5549 - binary_crossentropy: 0.6823 - precision: 0.5974 - recall: 0.3776 - auc: 0.5959\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.6770 - accuracy: 0.5715 - binary_crossentropy: 0.6770 - precision: 0.6295 - recall: 0.3789 - auc: 0.6307\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.6778 - accuracy: 0.5757 - binary_crossentropy: 0.6778 - precision: 0.6364 - recall: 0.3830 - auc: 0.6289\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.6740 - accuracy: 0.5826 - binary_crossentropy: 0.6740 - precision: 0.6464 - recall: 0.3926 - auc: 0.6470\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.6728 - accuracy: 0.5979 - binary_crossentropy: 0.6728 - precision: 0.6696 - recall: 0.4104 - auc: 0.6490\n",
      "Loss of Train ......................................\n",
      "[0.7017558813095093, 0.7015474438667297, 0.6990683078765869, 0.6980397701263428, 0.6988794803619385, 0.6935569047927856, 0.6965427994728088, 0.6932876706123352, 0.6919531226158142, 0.6908983588218689, 0.6892778873443604, 0.6856490969657898, 0.6804245114326477, 0.6829119324684143, 0.6794363856315613, 0.682310163974762, 0.676953911781311, 0.6778314113616943, 0.6739789247512817, 0.672788143157959]\n",
      "Accuracy of Train ......................................\n",
      "[0.4833333194255829, 0.4895833432674408, 0.4833333194255829, 0.4868055582046509, 0.4958333373069763, 0.5159721970558167, 0.5062500238418579, 0.5173611044883728, 0.5104166865348816, 0.5215277671813965, 0.518750011920929, 0.5361111164093018, 0.5611110925674438, 0.5736111402511597, 0.5638889074325562, 0.5548611283302307, 0.5715277791023254, 0.5756944417953491, 0.5826388597488403, 0.5979166626930237]\n",
      "Precision of Train ......................................\n",
      "[0.4878048896789551, 0.4961685836315155, 0.48785045742988586, 0.49215686321258545, 0.5048356056213379, 0.5351239442825317, 0.5200803279876709, 0.5389610528945923, 0.5278970003128052, 0.5448718070983887, 0.5400843620300293, 0.5689277648925781, 0.6055437326431274, 0.6263498663902283, 0.6173120737075806, 0.5974025726318359, 0.6295454502105713, 0.6363636255264282, 0.6463963985443115, 0.6696428656578064]\n",
      "Recall of Train ......................................\n",
      "[0.35567715764045715, 0.35430917143821716, 0.35704514384269714, 0.34336525201797485, 0.35704514384269714, 0.35430917143821716, 0.35430917143821716, 0.3406292796134949, 0.3365253210067749, 0.3488371968269348, 0.3502052128314972, 0.35567715764045715, 0.3885088860988617, 0.396716833114624, 0.37072503566741943, 0.3775649666786194, 0.37893298268318176, 0.38303694128990173, 0.39261284470558167, 0.4103967249393463]\n",
      "AUC of Train ......................................\n",
      "[0.4846443831920624, 0.4865313768386841, 0.49475187063217163, 0.49660032987594604, 0.5040364265441895, 0.5342508554458618, 0.5181523561477661, 0.5360867381095886, 0.5410551428794861, 0.5499364137649536, 0.5578694343566895, 0.5830990672111511, 0.6131629943847656, 0.6033092141151428, 0.6152082085609436, 0.5958807468414307, 0.6306834816932678, 0.6289401650428772, 0.6469826102256775, 0.648960292339325]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.5323263898491859\n",
      " Loss:0.6883546054363251\n",
      " Precision:0.5636659622192383\n",
      " Recall:0.36532147973775864\n",
      " AUC:0.5635071054100991\n",
      "Score for fold 5: loss of 0.6671556830406189; accuracy of 0.5916666388511658%\n",
      "[[150  41]\n",
      " [106  63]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1663.589017 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:150,FN:106,TP:63,FP:41\n",
      "Test of epochs .................................\n",
      " Accuracy:0.5916666666666667\n",
      " Loss:0.6671556830406189\n",
      " Precision:0.6057692307692307\n",
      " Recall:0.3727810650887574\n",
      " AUC:0.4793592825443787\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.5949305564165115 - Loss: 0.6668112397193908\n",
      "> Fold 1 - Precision: 0.6826871186494827\n",
      "> Fold 1 - Recall: 0.3349999964237213\n",
      "> Fold 1 - AUC: 0.6855682551860809\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.6305555555555555 - Loss: 0.6500741839408875\n",
      "> Fold 1 - Precision: 0.8275862068965517\n",
      "> Fold 1 - Recall: 0.37894736842105264\n",
      "> Fold 1 - AUC: 0.4733564680933102\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.5067361116409301 - Loss: 0.6990661531686783\n",
      "> Fold 2 - Precision: 0.510329370200634\n",
      "> Fold 2 - Recall: 0.6394444465637207\n",
      "> Fold 2 - AUC: 0.5039210513234138\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.5944444444444444 - Loss: 0.6719174385070801\n",
      "> Fold 2 - Precision: 0.592391304347826\n",
      "> Fold 2 - Recall: 0.6055555555555555\n",
      "> Fold 2 - AUC: 0.6010732323232323\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.5990625023841858 - Loss: 0.6604946434497834\n",
      "> Fold 3 - Precision: 0.7731725394725799\n",
      "> Fold 3 - Recall: 0.26827732026576995\n",
      "> Fold 3 - AUC: 0.7338048696517945\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.6111111111111112 - Loss: 0.6461363434791565\n",
      "> Fold 3 - Precision: 0.859375\n",
      "> Fold 3 - Recall: 0.2956989247311828\n",
      "> Fold 3 - AUC: 0.4265656785818076\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.6035069435834884 - Loss: 0.6723265945911407\n",
      "> Fold 4 - Precision: 0.6099445074796677\n",
      "> Fold 4 - Recall: 0.6108965545892715\n",
      "> Fold 4 - AUC: 0.6391420811414719\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.6666666666666666 - Loss: 0.6434993147850037\n",
      "> Fold 4 - Precision: 0.6896551724137931\n",
      "> Fold 4 - Recall: 0.5714285714285714\n",
      "> Fold 4 - AUC: 0.6112956810631229\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.5323263898491859 - Loss: 0.6883546054363251\n",
      "> Fold 5 - Precision: 0.5636659622192383\n",
      "> Fold 5 - Recall: 0.36532147973775864\n",
      "> Fold 5 - AUC: 0.5635071054100991\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.5916666666666667 - Loss: 0.6671556830406189\n",
      "> Fold 5 - Precision: 0.6057692307692307\n",
      "> Fold 5 - Recall: 0.3727810650887574\n",
      "> Fold 5 - AUC: 0.4793592825443787\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.5673125007748604 (+- 0.03993590907454967)\n",
      "> Loss: 0.6774106472730635 (+- 0.014234306259069131)\n",
      "> Precision: 0.6279598996043205 (+- 0.09206191988830062)\n",
      "> Recall: 0.44378795951604844 (+- 0.15165918193356975)\n",
      "> AUC: 0.625188672542572 (+- 0.08264178309580769)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.6188888888888889 (+- 0.027632955812101952)\n",
      "> Loss: 0.6557565927505493 (+- 0.011542894126310306)\n",
      "> Precision: 0.7149553828854803 (+- 0.11056798644866982)\n",
      "> Recall: 0.4448822970450239 (+- 0.12135199759207746)\n",
      "> AUC: 0.5183300685211704 (+- 0.07409600046873306)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 715 FN SUM: 501 TP SUM: 399 FP SUM: 185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(Xception(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba450b",
   "metadata": {},
   "source": [
    "# MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010073e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 14s 154ms/step - loss: 0.7548 - accuracy: 0.5083 - binary_crossentropy: 0.7548 - precision: 0.5020 - recall: 0.3493 - auc: 0.4913\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.7024 - accuracy: 0.5576 - binary_crossentropy: 0.7024 - precision: 0.5682 - recall: 0.4282 - auc: 0.5779\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 154ms/step - loss: 0.6644 - accuracy: 0.6021 - binary_crossentropy: 0.6644 - precision: 0.6234 - recall: 0.4873 - auc: 0.6440\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.6279 - accuracy: 0.6535 - binary_crossentropy: 0.6279 - precision: 0.6761 - recall: 0.5704 - auc: 0.7066\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.6008 - accuracy: 0.6833 - binary_crossentropy: 0.6008 - precision: 0.7055 - recall: 0.6141 - auc: 0.7486\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.5740 - accuracy: 0.7056 - binary_crossentropy: 0.5740 - precision: 0.7214 - recall: 0.6563 - auc: 0.7851\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 7s 154ms/step - loss: 0.5460 - accuracy: 0.7333 - binary_crossentropy: 0.5460 - precision: 0.7477 - recall: 0.6930 - auc: 0.8211\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.5313 - accuracy: 0.7458 - binary_crossentropy: 0.5313 - precision: 0.7575 - recall: 0.7127 - auc: 0.8365\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 7s 154ms/step - loss: 0.5014 - accuracy: 0.7896 - binary_crossentropy: 0.5014 - precision: 0.8015 - recall: 0.7620 - auc: 0.8707\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.4826 - accuracy: 0.8076 - binary_crossentropy: 0.4826 - precision: 0.8207 - recall: 0.7803 - auc: 0.8861\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 7s 151ms/step - loss: 0.4718 - accuracy: 0.8042 - binary_crossentropy: 0.4718 - precision: 0.8166 - recall: 0.7775 - auc: 0.8899\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 7s 154ms/step - loss: 0.4601 - accuracy: 0.8174 - binary_crossentropy: 0.4601 - precision: 0.8263 - recall: 0.7972 - auc: 0.8998\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.4440 - accuracy: 0.8222 - binary_crossentropy: 0.4440 - precision: 0.8328 - recall: 0.8000 - auc: 0.9090\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.4228 - accuracy: 0.8410 - binary_crossentropy: 0.4228 - precision: 0.8511 - recall: 0.8211 - auc: 0.9265\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.4154 - accuracy: 0.8382 - binary_crossentropy: 0.4154 - precision: 0.8442 - recall: 0.8239 - auc: 0.9281\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.4065 - accuracy: 0.8569 - binary_crossentropy: 0.4065 - precision: 0.8621 - recall: 0.8451 - auc: 0.9323\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.4055 - accuracy: 0.8611 - binary_crossentropy: 0.4055 - precision: 0.8717 - recall: 0.8423 - auc: 0.9314\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.3778 - accuracy: 0.8771 - binary_crossentropy: 0.3778 - precision: 0.8802 - recall: 0.8690 - auc: 0.9470\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.3773 - accuracy: 0.8743 - binary_crossentropy: 0.3773 - precision: 0.8806 - recall: 0.8620 - auc: 0.9473\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.3655 - accuracy: 0.8778 - binary_crossentropy: 0.3655 - precision: 0.8793 - recall: 0.8718 - auc: 0.9541\n",
      "Loss of Train ......................................\n",
      "[0.7548145055770874, 0.702353298664093, 0.6643666625022888, 0.6278645992279053, 0.6008098721504211, 0.574044406414032, 0.5459743738174438, 0.5313171148300171, 0.5013695955276489, 0.48256248235702515, 0.471819132566452, 0.46006256341934204, 0.4439818859100342, 0.4228336215019226, 0.41537195444107056, 0.406474769115448, 0.40551429986953735, 0.37782567739486694, 0.3772682249546051, 0.36554014682769775]\n",
      "Accuracy of Train ......................................\n",
      "[0.5083333253860474, 0.5576388835906982, 0.6020833253860474, 0.6534722447395325, 0.6833333373069763, 0.7055555582046509, 0.7333333492279053, 0.7458333373069763, 0.7895833253860474, 0.8076388835906982, 0.8041666746139526, 0.8173611164093018, 0.8222222328186035, 0.8409722447395325, 0.8381944298744202, 0.8569444417953491, 0.8611111044883728, 0.8770833611488342, 0.8743055462837219, 0.8777777552604675]\n",
      "Precision of Train ......................................\n",
      "[0.5020242929458618, 0.568224310874939, 0.6234233975410461, 0.6761268973350525, 0.7055016160011292, 0.7213622331619263, 0.7477203607559204, 0.757485032081604, 0.8014814853668213, 0.8207407593727112, 0.8165680766105652, 0.8262773752212524, 0.8328445553779602, 0.8510949015617371, 0.8441558480262756, 0.8620689511299133, 0.8717201352119446, 0.8801711797714233, 0.8805755376815796, 0.8792613744735718]\n",
      "Recall of Train ......................................\n",
      "[0.3492957651615143, 0.42816901206970215, 0.48732393980026245, 0.5704225301742554, 0.6140844821929932, 0.6563380360603333, 0.6929577589035034, 0.7126760482788086, 0.7619718313217163, 0.780281662940979, 0.7774648070335388, 0.797183096408844, 0.800000011920929, 0.8211267590522766, 0.8239436745643616, 0.8450704216957092, 0.8422535061836243, 0.8690140843391418, 0.8619718551635742, 0.8718309998512268]\n",
      "AUC of Train ......................................\n",
      "[0.49134379625320435, 0.577927827835083, 0.644048810005188, 0.7066081762313843, 0.748616635799408, 0.7850655913352966, 0.8211383819580078, 0.8365107178688049, 0.8707293272018433, 0.8861055374145508, 0.8898890018463135, 0.8997559547424316, 0.9090093374252319, 0.9264903664588928, 0.9281467795372009, 0.9322910904884338, 0.9314152002334595, 0.9470210075378418, 0.9473229646682739, 0.9541462063789368]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7628472238779068\n",
      " Loss:0.506608459353447\n",
      " Precision:0.7734414160251617\n",
      " Recall:0.7181690141558648\n",
      " AUC:0.8316791355609894\n",
      "Score for fold 1: loss of 0.5667403936386108; accuracy of 0.7222222089767456%\n",
      "[[ 88  82]\n",
      " [ 18 172]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 162.8001439 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:88,FN:18,TP:172,FP:82\n",
      "Test of epochs .................................\n",
      " Accuracy:0.7222222222222222\n",
      " Loss:0.5667403936386108\n",
      " Precision:0.6771653543307087\n",
      " Recall:0.9052631578947369\n",
      " AUC:0.8677259185700099\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_1 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 12s 151ms/step - loss: 0.7870 - accuracy: 0.4632 - binary_crossentropy: 0.7870 - precision: 0.4755 - recall: 0.6135 - auc: 0.4392\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.7434 - accuracy: 0.5063 - binary_crossentropy: 0.7434 - precision: 0.5087 - recall: 0.6437 - auc: 0.5058\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.6952 - accuracy: 0.5562 - binary_crossentropy: 0.6952 - precision: 0.5506 - recall: 0.6589 - auc: 0.5863\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 7s 152ms/step - loss: 0.6531 - accuracy: 0.5993 - binary_crossentropy: 0.6531 - precision: 0.5874 - recall: 0.6933 - auc: 0.6611\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.6179 - accuracy: 0.6681 - binary_crossentropy: 0.6179 - precision: 0.6513 - recall: 0.7373 - auc: 0.7261\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.6013 - accuracy: 0.6868 - binary_crossentropy: 0.6013 - precision: 0.6691 - recall: 0.7510 - auc: 0.7504\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.5705 - accuracy: 0.7201 - binary_crossentropy: 0.5705 - precision: 0.7045 - recall: 0.7675 - auc: 0.7978\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.5548 - accuracy: 0.7583 - binary_crossentropy: 0.5548 - precision: 0.7464 - recall: 0.7895 - auc: 0.8192\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.5311 - accuracy: 0.7688 - binary_crossentropy: 0.5311 - precision: 0.7526 - recall: 0.8074 - auc: 0.8448\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.5124 - accuracy: 0.7854 - binary_crossentropy: 0.5124 - precision: 0.7765 - recall: 0.8074 - auc: 0.8632\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.4937 - accuracy: 0.8028 - binary_crossentropy: 0.4937 - precision: 0.7934 - recall: 0.8239 - auc: 0.8798\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.4749 - accuracy: 0.8375 - binary_crossentropy: 0.4749 - precision: 0.8327 - recall: 0.8487 - auc: 0.8995\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.4599 - accuracy: 0.8264 - binary_crossentropy: 0.4599 - precision: 0.8167 - recall: 0.8459 - auc: 0.9049\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.4430 - accuracy: 0.8486 - binary_crossentropy: 0.4430 - precision: 0.8435 - recall: 0.8597 - auc: 0.9218\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.4323 - accuracy: 0.8528 - binary_crossentropy: 0.4323 - precision: 0.8523 - recall: 0.8569 - auc: 0.9232\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.4164 - accuracy: 0.8583 - binary_crossentropy: 0.4164 - precision: 0.8539 - recall: 0.8680 - auc: 0.9339\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.4137 - accuracy: 0.8687 - binary_crossentropy: 0.4137 - precision: 0.8606 - recall: 0.8831 - auc: 0.9343\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.4008 - accuracy: 0.8632 - binary_crossentropy: 0.4008 - precision: 0.8610 - recall: 0.8693 - auc: 0.9396\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.3906 - accuracy: 0.8687 - binary_crossentropy: 0.3906 - precision: 0.8635 - recall: 0.8790 - auc: 0.9446\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.3837 - accuracy: 0.8757 - binary_crossentropy: 0.3837 - precision: 0.8733 - recall: 0.8817 - auc: 0.9465\n",
      "Loss of Train ......................................\n",
      "[0.7869898676872253, 0.7434138059616089, 0.6951549053192139, 0.6531274318695068, 0.6179319620132446, 0.6013463139533997, 0.5705347061157227, 0.5547901391983032, 0.5311228632926941, 0.5123648047447205, 0.49374502897262573, 0.4749038815498352, 0.4598836600780487, 0.4430057406425476, 0.43228739500045776, 0.4164271056652069, 0.4137365520000458, 0.40077918767929077, 0.3906257152557373, 0.3836574852466583]\n",
      "Accuracy of Train ......................................\n",
      "[0.46319442987442017, 0.5062500238418579, 0.5562499761581421, 0.5993055701255798, 0.668055534362793, 0.6868055462837219, 0.7201389074325562, 0.7583333253860474, 0.768750011920929, 0.7854166626930237, 0.8027777671813965, 0.8374999761581421, 0.8263888955116272, 0.8486111164093018, 0.8527777791023254, 0.8583333492279053, 0.8687499761581421, 0.863194465637207, 0.8687499761581421, 0.8756944537162781]\n",
      "Precision of Train ......................................\n",
      "[0.47547975182533264, 0.508695662021637, 0.5505747199058533, 0.5874125957489014, 0.6512758135795593, 0.6691176295280457, 0.7045454382896423, 0.7464239001274109, 0.7525641322135925, 0.7764550447463989, 0.7933774590492249, 0.832658588886261, 0.8167330622673035, 0.8434547781944275, 0.8522571921348572, 0.8538565635681152, 0.8605898022651672, 0.8610354065895081, 0.8635135293006897, 0.8732969760894775]\n",
      "Recall of Train ......................................\n",
      "[0.6134800314903259, 0.6437414288520813, 0.6588720679283142, 0.6932599544525146, 0.7372764945030212, 0.7510316371917725, 0.7675378322601318, 0.7895460724830627, 0.8074277639389038, 0.8074277639389038, 0.8239339590072632, 0.8486932516098022, 0.8459421992301941, 0.8596974015235901, 0.8569463491439819, 0.8679504990577698, 0.8830811381340027, 0.8693259954452515, 0.8789545893669128, 0.881705641746521]\n",
      "AUC of Train ......................................\n",
      "[0.4391975700855255, 0.5057605504989624, 0.586345911026001, 0.6611292958259583, 0.7260909676551819, 0.750365138053894, 0.7977616190910339, 0.8192460536956787, 0.8447615504264832, 0.8632394075393677, 0.8797639608383179, 0.8995169401168823, 0.9049186706542969, 0.9217595458030701, 0.9231804013252258, 0.9338671565055847, 0.9343138337135315, 0.9396393895149231, 0.9446137547492981, 0.9464948177337646]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.750763887166977\n",
      " Loss:0.5287914276123047\n",
      " Precision:0.7436659023165703\n",
      " Recall:0.7942916035652161\n",
      " AUC:0.811098326742649\n",
      "Score for fold 2: loss of 0.5585314035415649; accuracy of 0.7388888597488403%\n",
      "[[116  71]\n",
      " [ 23 150]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 318.4012283 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:116,FN:23,TP:150,FP:71\n",
      "Test of epochs .................................\n",
      " Accuracy:0.7388888888888889\n",
      " Loss:0.5585314035415649\n",
      " Precision:0.6787330316742082\n",
      " Recall:0.8670520231213873\n",
      " AUC:0.8507921986110534\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 155ms/step - loss: 0.7229 - accuracy: 0.5118 - binary_crossentropy: 0.7229 - precision: 0.5157 - recall: 0.5193 - auc: 0.5191\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.6811 - accuracy: 0.5681 - binary_crossentropy: 0.6811 - precision: 0.5716 - recall: 0.5716 - auc: 0.6019\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.6498 - accuracy: 0.6236 - binary_crossentropy: 0.6498 - precision: 0.6271 - recall: 0.6253 - auc: 0.6696\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.6232 - accuracy: 0.6722 - binary_crossentropy: 0.6232 - precision: 0.6716 - recall: 0.6846 - auc: 0.7187\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.5954 - accuracy: 0.6986 - binary_crossentropy: 0.5954 - precision: 0.7022 - recall: 0.6983 - auc: 0.7631\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.5740 - accuracy: 0.7229 - binary_crossentropy: 0.5740 - precision: 0.7212 - recall: 0.7342 - auc: 0.7968\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.5465 - accuracy: 0.7694 - binary_crossentropy: 0.5465 - precision: 0.7677 - recall: 0.7782 - auc: 0.8384\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.5316 - accuracy: 0.7750 - binary_crossentropy: 0.5316 - precision: 0.7724 - recall: 0.7851 - auc: 0.8534\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.5043 - accuracy: 0.8076 - binary_crossentropy: 0.5043 - precision: 0.8071 - recall: 0.8127 - auc: 0.8846\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.4931 - accuracy: 0.8028 - binary_crossentropy: 0.4931 - precision: 0.8027 - recall: 0.8072 - auc: 0.8891\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.4707 - accuracy: 0.8313 - binary_crossentropy: 0.4707 - precision: 0.8242 - recall: 0.8457 - auc: 0.9132\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.4585 - accuracy: 0.8326 - binary_crossentropy: 0.4585 - precision: 0.8336 - recall: 0.8347 - auc: 0.9162\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.4446 - accuracy: 0.8444 - binary_crossentropy: 0.4446 - precision: 0.8429 - recall: 0.8499 - auc: 0.9240\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.4324 - accuracy: 0.8556 - binary_crossentropy: 0.4324 - precision: 0.8548 - recall: 0.8595 - auc: 0.9321\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.4235 - accuracy: 0.8569 - binary_crossentropy: 0.4235 - precision: 0.8552 - recall: 0.8623 - auc: 0.9375\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.4154 - accuracy: 0.8562 - binary_crossentropy: 0.4154 - precision: 0.8540 - recall: 0.8623 - auc: 0.9390\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.4027 - accuracy: 0.8701 - binary_crossentropy: 0.4027 - precision: 0.8748 - recall: 0.8664 - auc: 0.9442\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.3964 - accuracy: 0.8764 - binary_crossentropy: 0.3964 - precision: 0.8785 - recall: 0.8760 - auc: 0.9461\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.3782 - accuracy: 0.8896 - binary_crossentropy: 0.3782 - precision: 0.8889 - recall: 0.8926 - auc: 0.9543\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.3720 - accuracy: 0.8896 - binary_crossentropy: 0.3720 - precision: 0.8889 - recall: 0.8926 - auc: 0.9579\n",
      "Loss of Train ......................................\n",
      "[0.7229229211807251, 0.6811431050300598, 0.6497505307197571, 0.6231699585914612, 0.5953635573387146, 0.573959231376648, 0.5465120673179626, 0.5316222310066223, 0.5042744278907776, 0.493071585893631, 0.4706878662109375, 0.45849859714508057, 0.44459009170532227, 0.4324275851249695, 0.4235070049762726, 0.41543400287628174, 0.4026503562927246, 0.3964366614818573, 0.3782155215740204, 0.37202972173690796]\n",
      "Accuracy of Train ......................................\n",
      "[0.511805534362793, 0.5680555701255798, 0.6236110925674438, 0.6722221970558167, 0.6986111402511597, 0.7229166626930237, 0.769444465637207, 0.7749999761581421, 0.8076388835906982, 0.8027777671813965, 0.831250011920929, 0.8326388597488403, 0.8444444537162781, 0.855555534362793, 0.8569444417953491, 0.856249988079071, 0.8701388835906982, 0.8763889074325562, 0.8895833492279053, 0.8895833492279053]\n",
      "Precision of Train ......................................\n",
      "[0.5157318711280823, 0.5716253519058228, 0.6270717978477478, 0.6716216206550598, 0.7022160887718201, 0.7212449312210083, 0.7676630616188049, 0.772357702255249, 0.807113528251648, 0.8027397394180298, 0.8241610527038574, 0.8335626125335693, 0.8428961634635925, 0.8547945022583008, 0.8551912307739258, 0.8540245294570923, 0.8748261332511902, 0.8784530162811279, 0.8888888955116272, 0.8888888955116272]\n",
      "Recall of Train ......................................\n",
      "[0.5192837715148926, 0.5716253519058228, 0.6253443360328674, 0.6845729947090149, 0.6983470916748047, 0.7341597676277161, 0.7782369256019592, 0.7851239442825317, 0.8126721978187561, 0.8071625232696533, 0.8457300066947937, 0.8347107172012329, 0.849862277507782, 0.8595041036605835, 0.8622589707374573, 0.8622589707374573, 0.8663911819458008, 0.8760330677032471, 0.8925619721412659, 0.8925619721412659]\n",
      "AUC of Train ......................................\n",
      "[0.5191255211830139, 0.6018705368041992, 0.6695719361305237, 0.7186590433120728, 0.7630710005760193, 0.7967981696128845, 0.838377058506012, 0.8534340858459473, 0.8845887780189514, 0.8891106843948364, 0.9131633043289185, 0.9162421822547913, 0.9239559173583984, 0.9321249127388, 0.9375168681144714, 0.938963770866394, 0.9441561102867126, 0.946106493473053, 0.9542618989944458, 0.957939863204956]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7777430534362793\n",
      " Loss:0.5058133512735367\n",
      " Precision:0.7777536362409592\n",
      " Recall:0.7829201072454453\n",
      " AUC:0.8449519068002701\n",
      "Score for fold 3: loss of 0.562244176864624; accuracy of 0.7055555582046509%\n",
      "[[136  50]\n",
      " [ 56 118]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 474.9637219 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:136,FN:56,TP:118,FP:50\n",
      "Test of epochs .................................\n",
      " Accuracy:0.7055555555555556\n",
      " Loss:0.562244176864624\n",
      " Precision:0.7023809523809523\n",
      " Recall:0.6781609195402298\n",
      " AUC:0.6932471264367817\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 9s 154ms/step - loss: 0.7152 - accuracy: 0.5396 - binary_crossentropy: 0.7152 - precision: 0.5655 - recall: 0.4231 - auc: 0.5536\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 154ms/step - loss: 0.6713 - accuracy: 0.5910 - binary_crossentropy: 0.6713 - precision: 0.6241 - recall: 0.4993 - auc: 0.6403\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.6363 - accuracy: 0.6472 - binary_crossentropy: 0.6363 - precision: 0.6816 - recall: 0.5796 - auc: 0.6981\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 7s 158ms/step - loss: 0.6050 - accuracy: 0.6736 - binary_crossentropy: 0.6050 - precision: 0.6987 - recall: 0.6340 - auc: 0.7461\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.5823 - accuracy: 0.7090 - binary_crossentropy: 0.5823 - precision: 0.7358 - recall: 0.6707 - auc: 0.7836\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.5567 - accuracy: 0.7479 - binary_crossentropy: 0.5567 - precision: 0.7703 - recall: 0.7211 - auc: 0.8175\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.5367 - accuracy: 0.7778 - binary_crossentropy: 0.5367 - precision: 0.7994 - recall: 0.7537 - auc: 0.8419\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.5117 - accuracy: 0.7861 - binary_crossentropy: 0.5117 - precision: 0.8011 - recall: 0.7728 - auc: 0.8696\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.5006 - accuracy: 0.8000 - binary_crossentropy: 0.5006 - precision: 0.8108 - recall: 0.7932 - auc: 0.8773\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.4813 - accuracy: 0.8021 - binary_crossentropy: 0.4813 - precision: 0.8151 - recall: 0.7918 - auc: 0.8922\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.4620 - accuracy: 0.8319 - binary_crossentropy: 0.4620 - precision: 0.8391 - recall: 0.8299 - auc: 0.9075\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.4461 - accuracy: 0.8382 - binary_crossentropy: 0.4461 - precision: 0.8457 - recall: 0.8354 - auc: 0.9186\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.4450 - accuracy: 0.8389 - binary_crossentropy: 0.4450 - precision: 0.8479 - recall: 0.8340 - auc: 0.9153\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.4300 - accuracy: 0.8493 - binary_crossentropy: 0.4300 - precision: 0.8567 - recall: 0.8463 - auc: 0.9256\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.4111 - accuracy: 0.8625 - binary_crossentropy: 0.4111 - precision: 0.8693 - recall: 0.8599 - auc: 0.9371\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.3974 - accuracy: 0.8792 - binary_crossentropy: 0.3974 - precision: 0.8848 - recall: 0.8776 - auc: 0.9454\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.3822 - accuracy: 0.8708 - binary_crossentropy: 0.3822 - precision: 0.8735 - recall: 0.8735 - auc: 0.9532\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.3793 - accuracy: 0.8750 - binary_crossentropy: 0.3793 - precision: 0.8817 - recall: 0.8721 - auc: 0.9503\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.3748 - accuracy: 0.8708 - binary_crossentropy: 0.3748 - precision: 0.8776 - recall: 0.8680 - auc: 0.9487\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.3612 - accuracy: 0.8903 - binary_crossentropy: 0.3612 - precision: 0.8957 - recall: 0.8884 - auc: 0.9571\n",
      "Loss of Train ......................................\n",
      "[0.7152141332626343, 0.6712688207626343, 0.6363142728805542, 0.6049856543540955, 0.5822626948356628, 0.5567107200622559, 0.5366874933242798, 0.5117310881614685, 0.5005785822868347, 0.48129570484161377, 0.4619859457015991, 0.44612982869148254, 0.44498389959335327, 0.4299713969230652, 0.411051869392395, 0.39742177724838257, 0.382177472114563, 0.37928059697151184, 0.37475332617759705, 0.36121317744255066]\n",
      "Accuracy of Train ......................................\n",
      "[0.5395833253860474, 0.5909722447395325, 0.6472222208976746, 0.6736111044883728, 0.7090277671813965, 0.7479166388511658, 0.7777777910232544, 0.7861111164093018, 0.800000011920929, 0.8020833134651184, 0.831944465637207, 0.8381944298744202, 0.8388888835906982, 0.8493055701255798, 0.862500011920929, 0.8791666626930237, 0.8708333373069763, 0.875, 0.8708333373069763, 0.8902778029441833]\n",
      "Precision of Train ......................................\n",
      "[0.5654545426368713, 0.6241496801376343, 0.6815999746322632, 0.6986506581306458, 0.7358208894729614, 0.770348846912384, 0.7994228005409241, 0.8011283278465271, 0.8108484148979187, 0.8151260614395142, 0.8390646576881409, 0.8457300066947937, 0.8478561639785767, 0.8567492961883545, 0.8693259954452515, 0.8847736716270447, 0.8734694123268127, 0.881705641746521, 0.8775790929794312, 0.8957476019859314]\n",
      "Recall of Train ......................................\n",
      "[0.42312926054000854, 0.49931973218917847, 0.5795918107032776, 0.6340135931968689, 0.6707482933998108, 0.7210884094238281, 0.7537415027618408, 0.7727891206741333, 0.7931972742080688, 0.7918367385864258, 0.8299319744110107, 0.8353741765022278, 0.8340135812759399, 0.8462585210800171, 0.8598639369010925, 0.8775510191917419, 0.8734694123268127, 0.8721088171005249, 0.8680272102355957, 0.8884353637695312]\n",
      "AUC of Train ......................................\n",
      "[0.5536479353904724, 0.6402672529220581, 0.6981444358825684, 0.7460877299308777, 0.783587634563446, 0.8175375461578369, 0.8419414162635803, 0.8696299195289612, 0.8772904872894287, 0.8921629190444946, 0.9075196385383606, 0.918587327003479, 0.9152930974960327, 0.9255753755569458, 0.9370511770248413, 0.9453629851341248, 0.9531760811805725, 0.9503478407859802, 0.9486697912216187, 0.9571486115455627]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7840625017881393\n",
      " Loss:0.4943009227514267\n",
      " Precision:0.7987275868654251\n",
      " Recall:0.7612244874238968\n",
      " AUC:0.8539514601230621\n",
      "Score for fold 4: loss of 0.6951411962509155; accuracy of 0.5555555820465088%\n",
      "[[179  16]\n",
      " [144  21]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 623.6917022 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:179,FN:144,TP:21,FP:16\n",
      "Test of epochs .................................\n",
      " Accuracy:0.5555555555555556\n",
      " Loss:0.6951411962509155\n",
      " Precision:0.5675675675675675\n",
      " Recall:0.12727272727272726\n",
      " AUC:0.34072614691809733\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 9s 150ms/step - loss: 0.6789 - accuracy: 0.5965 - binary_crossentropy: 0.6789 - precision: 0.5691 - recall: 0.7094 - auc: 0.6329\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 153ms/step - loss: 0.6477 - accuracy: 0.6417 - binary_crossentropy: 0.6477 - precision: 0.6129 - recall: 0.7194 - auc: 0.6845\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.6168 - accuracy: 0.6701 - binary_crossentropy: 0.6168 - precision: 0.6396 - recall: 0.7407 - auc: 0.7266\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.5869 - accuracy: 0.7035 - binary_crossentropy: 0.5869 - precision: 0.6738 - recall: 0.7593 - auc: 0.7663\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.5680 - accuracy: 0.7090 - binary_crossentropy: 0.5680 - precision: 0.6850 - recall: 0.7464 - auc: 0.7897\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.5423 - accuracy: 0.7444 - binary_crossentropy: 0.5423 - precision: 0.7227 - recall: 0.7721 - auc: 0.8192\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.5227 - accuracy: 0.7694 - binary_crossentropy: 0.5227 - precision: 0.7460 - recall: 0.7991 - auc: 0.8406\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.5088 - accuracy: 0.7812 - binary_crossentropy: 0.5088 - precision: 0.7583 - recall: 0.8091 - auc: 0.8535\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.4924 - accuracy: 0.7917 - binary_crossentropy: 0.4924 - precision: 0.7702 - recall: 0.8162 - auc: 0.8681\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.4698 - accuracy: 0.8056 - binary_crossentropy: 0.4698 - precision: 0.7898 - recall: 0.8191 - auc: 0.8900\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.4502 - accuracy: 0.8319 - binary_crossentropy: 0.4502 - precision: 0.8194 - recall: 0.8405 - auc: 0.9065\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.4420 - accuracy: 0.8271 - binary_crossentropy: 0.4420 - precision: 0.8098 - recall: 0.8433 - auc: 0.9092\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.4410 - accuracy: 0.8313 - binary_crossentropy: 0.4410 - precision: 0.8140 - recall: 0.8476 - auc: 0.9098\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.4171 - accuracy: 0.8549 - binary_crossentropy: 0.4171 - precision: 0.8372 - recall: 0.8718 - auc: 0.9265\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.4107 - accuracy: 0.8521 - binary_crossentropy: 0.4107 - precision: 0.8401 - recall: 0.8604 - auc: 0.9278\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.4020 - accuracy: 0.8549 - binary_crossentropy: 0.4020 - precision: 0.8381 - recall: 0.8704 - auc: 0.9337\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.3899 - accuracy: 0.8681 - binary_crossentropy: 0.3899 - precision: 0.8616 - recall: 0.8689 - auc: 0.9413\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.3797 - accuracy: 0.8729 - binary_crossentropy: 0.3797 - precision: 0.8619 - recall: 0.8803 - auc: 0.9430\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.3641 - accuracy: 0.8757 - binary_crossentropy: 0.3641 - precision: 0.8709 - recall: 0.8746 - auc: 0.9526\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.3643 - accuracy: 0.8819 - binary_crossentropy: 0.3643 - precision: 0.8674 - recall: 0.8946 - auc: 0.9499\n",
      "Loss of Train ......................................\n",
      "[0.6788903474807739, 0.6477047801017761, 0.6168298721313477, 0.5869013071060181, 0.5679857134819031, 0.5423262715339661, 0.5227365493774414, 0.5087965726852417, 0.49238938093185425, 0.4697747826576233, 0.45021387934684753, 0.4420343041419983, 0.4409826397895813, 0.4170743227005005, 0.41066423058509827, 0.40204712748527527, 0.38986510038375854, 0.37973862886428833, 0.3641166388988495, 0.3643242418766022]\n",
      "Accuracy of Train ......................................\n",
      "[0.5965277552604675, 0.6416666507720947, 0.6701388955116272, 0.7034721970558167, 0.7090277671813965, 0.7444444298744202, 0.769444465637207, 0.78125, 0.7916666865348816, 0.8055555820465088, 0.831944465637207, 0.8270833492279053, 0.831250011920929, 0.8548611402511597, 0.8520833253860474, 0.8548611402511597, 0.8680555820465088, 0.8729166388511658, 0.8756944537162781, 0.8819444179534912]\n",
      "Precision of Train ......................................\n",
      "[0.5691428780555725, 0.612864077091217, 0.6396064162254333, 0.6738305687904358, 0.6849673390388489, 0.7226666808128357, 0.7460106611251831, 0.7583444714546204, 0.7701612710952759, 0.7898351550102234, 0.8194444179534912, 0.8098495006561279, 0.8139534592628479, 0.8372092843055725, 0.8400556445121765, 0.8381344079971313, 0.8615819215774536, 0.8619247078895569, 0.8709219694137573, 0.8674033284187317]\n",
      "Recall of Train ......................................\n",
      "[0.7094017267227173, 0.7193732261657715, 0.7407407164573669, 0.7592592835426331, 0.74643874168396, 0.7720797657966614, 0.7991452813148499, 0.809116780757904, 0.8162392973899841, 0.819088339805603, 0.8404558300971985, 0.8433048725128174, 0.8475783467292786, 0.8717948794364929, 0.8603988885879517, 0.8703703880310059, 0.8689458966255188, 0.8803418874740601, 0.874643862247467, 0.8945869207382202]\n",
      "AUC of Train ......................................\n",
      "[0.632927417755127, 0.6845318078994751, 0.726616382598877, 0.766280472278595, 0.7897171378135681, 0.8191993236541748, 0.8406016230583191, 0.8534839153289795, 0.8680821061134338, 0.8899823427200317, 0.9064750671386719, 0.9091677069664001, 0.9098231196403503, 0.9265435934066772, 0.9277682304382324, 0.9336767196655273, 0.9413281679153442, 0.9430373311042786, 0.9525880217552185, 0.949860692024231]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7881944477558136\n",
      " Loss:0.48476983457803724\n",
      " Precision:0.7693954080343246\n",
      " Recall:0.8171652466058731\n",
      " AUC:0.8585845589637756\n",
      "Score for fold 5: loss of 0.552291989326477; accuracy of 0.7250000238418579%\n",
      "[[ 84  78]\n",
      " [ 21 177]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 771.7001731 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:84,FN:21,TP:177,FP:78\n",
      "Test of epochs .................................\n",
      " Accuracy:0.725\n",
      " Loss:0.552291989326477\n",
      " Precision:0.6941176470588235\n",
      " Recall:0.8939393939393939\n",
      " AUC:0.8469696969696969\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.7628472238779068 - Loss: 0.506608459353447\n",
      "> Fold 1 - Precision: 0.7734414160251617\n",
      "> Fold 1 - Recall: 0.7181690141558648\n",
      "> Fold 1 - AUC: 0.8316791355609894\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.7222222222222222 - Loss: 0.5667403936386108\n",
      "> Fold 1 - Precision: 0.6771653543307087\n",
      "> Fold 1 - Recall: 0.9052631578947369\n",
      "> Fold 1 - AUC: 0.8677259185700099\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.750763887166977 - Loss: 0.5287914276123047\n",
      "> Fold 2 - Precision: 0.7436659023165703\n",
      "> Fold 2 - Recall: 0.7942916035652161\n",
      "> Fold 2 - AUC: 0.811098326742649\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.7388888888888889 - Loss: 0.5585314035415649\n",
      "> Fold 2 - Precision: 0.6787330316742082\n",
      "> Fold 2 - Recall: 0.8670520231213873\n",
      "> Fold 2 - AUC: 0.8507921986110534\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.7777430534362793 - Loss: 0.5058133512735367\n",
      "> Fold 3 - Precision: 0.7777536362409592\n",
      "> Fold 3 - Recall: 0.7829201072454453\n",
      "> Fold 3 - AUC: 0.8449519068002701\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.7055555555555556 - Loss: 0.562244176864624\n",
      "> Fold 3 - Precision: 0.7023809523809523\n",
      "> Fold 3 - Recall: 0.6781609195402298\n",
      "> Fold 3 - AUC: 0.6932471264367817\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.7840625017881393 - Loss: 0.4943009227514267\n",
      "> Fold 4 - Precision: 0.7987275868654251\n",
      "> Fold 4 - Recall: 0.7612244874238968\n",
      "> Fold 4 - AUC: 0.8539514601230621\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.5555555555555556 - Loss: 0.6951411962509155\n",
      "> Fold 4 - Precision: 0.5675675675675675\n",
      "> Fold 4 - Recall: 0.12727272727272726\n",
      "> Fold 4 - AUC: 0.34072614691809733\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.7881944477558136 - Loss: 0.48476983457803724\n",
      "> Fold 5 - Precision: 0.7693954080343246\n",
      "> Fold 5 - Recall: 0.8171652466058731\n",
      "> Fold 5 - AUC: 0.8585845589637756\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.725 - Loss: 0.552291989326477\n",
      "> Fold 5 - Precision: 0.6941176470588235\n",
      "> Fold 5 - Recall: 0.8939393939393939\n",
      "> Fold 5 - AUC: 0.8469696969696969\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.7727222228050232 (+- 0.013949082553158586)\n",
      "> Loss: 0.5040567991137505 (+- 0.014755083307316135)\n",
      "> Precision: 0.7725967898964882 (+- 0.017648626630640495)\n",
      "> Recall: 0.7747540917992592 (+- 0.033561958920079814)\n",
      "> AUC: 0.8400530776381492 (+- 0.017141061042483433)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.6894444444444445 (+- 0.06777777777777777)\n",
      "> Loss: 0.5869898319244384 (+- 0.054282459833513964)\n",
      "> Precision: 0.6639929106024521 (+- 0.04913201139895045)\n",
      "> Recall: 0.694337644353695 (+- 0.29529137946884587)\n",
      "> AUC: 0.7198922175011278 (+- 0.19980748933590553)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 603 FN SUM: 262 TP SUM: 638 FP SUM: 297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176be004",
   "metadata": {},
   "source": [
    "# DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47134923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1920)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 38s 356ms/step - loss: 0.6607 - accuracy: 0.6153 - binary_crossentropy: 0.6607 - precision: 0.6609 - recall: 0.4736 - auc: 0.6595\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6146 - accuracy: 0.6771 - binary_crossentropy: 0.6146 - precision: 0.7225 - recall: 0.5750 - auc: 0.7510\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.5800 - accuracy: 0.7306 - binary_crossentropy: 0.5800 - precision: 0.7602 - recall: 0.6736 - auc: 0.8075\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.5462 - accuracy: 0.7799 - binary_crossentropy: 0.5462 - precision: 0.7994 - recall: 0.7472 - auc: 0.8597\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.5173 - accuracy: 0.8104 - binary_crossentropy: 0.5173 - precision: 0.8126 - recall: 0.8069 - auc: 0.8952\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.5011 - accuracy: 0.8208 - binary_crossentropy: 0.5011 - precision: 0.8254 - recall: 0.8139 - auc: 0.9028\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.4758 - accuracy: 0.8431 - binary_crossentropy: 0.4758 - precision: 0.8302 - recall: 0.8625 - auc: 0.9269\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.4590 - accuracy: 0.8583 - binary_crossentropy: 0.4590 - precision: 0.8564 - recall: 0.8611 - auc: 0.9352\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.4396 - accuracy: 0.8681 - binary_crossentropy: 0.4396 - precision: 0.8660 - recall: 0.8708 - auc: 0.9454\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.4237 - accuracy: 0.8785 - binary_crossentropy: 0.4237 - precision: 0.8769 - recall: 0.8806 - auc: 0.9539\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.4039 - accuracy: 0.9007 - binary_crossentropy: 0.4039 - precision: 0.9001 - recall: 0.9014 - auc: 0.9628\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.3985 - accuracy: 0.9028 - binary_crossentropy: 0.3985 - precision: 0.8994 - recall: 0.9069 - auc: 0.9637\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.3783 - accuracy: 0.9069 - binary_crossentropy: 0.3783 - precision: 0.9047 - recall: 0.9097 - auc: 0.9705\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.3705 - accuracy: 0.9090 - binary_crossentropy: 0.3705 - precision: 0.9062 - recall: 0.9125 - auc: 0.9712\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.3578 - accuracy: 0.9167 - binary_crossentropy: 0.3578 - precision: 0.9237 - recall: 0.9083 - auc: 0.9742\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.3500 - accuracy: 0.9271 - binary_crossentropy: 0.3500 - precision: 0.9301 - recall: 0.9236 - auc: 0.9785\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.3382 - accuracy: 0.9222 - binary_crossentropy: 0.3382 - precision: 0.9258 - recall: 0.9181 - auc: 0.9803\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.3306 - accuracy: 0.9229 - binary_crossentropy: 0.3306 - precision: 0.9223 - recall: 0.9236 - auc: 0.9791\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.3186 - accuracy: 0.9354 - binary_crossentropy: 0.3186 - precision: 0.9372 - recall: 0.9333 - auc: 0.9815\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.3095 - accuracy: 0.9424 - binary_crossentropy: 0.3095 - precision: 0.9369 - recall: 0.9486 - auc: 0.9850\n",
      "Loss of Train ......................................\n",
      "[0.660732090473175, 0.6145612597465515, 0.5800219774246216, 0.5462039709091187, 0.5172919034957886, 0.5011471509933472, 0.47581812739372253, 0.4589584767818451, 0.4395930767059326, 0.4237147569656372, 0.4039241373538971, 0.3985498547554016, 0.37830424308776855, 0.37049102783203125, 0.35779863595962524, 0.3499600887298584, 0.33820077776908875, 0.33057039976119995, 0.3185558617115021, 0.30945658683776855]\n",
      "Accuracy of Train ......................................\n",
      "[0.6152777671813965, 0.6770833134651184, 0.730555534362793, 0.7798610925674438, 0.8104166388511658, 0.8208333253860474, 0.8430555462837219, 0.8583333492279053, 0.8680555820465088, 0.8784722089767456, 0.9006944298744202, 0.9027777910232544, 0.9069444537162781, 0.9090277552604675, 0.9166666865348816, 0.9270833134651184, 0.9222221970558167, 0.9229166507720947, 0.9354166388511658, 0.9423611164093018]\n",
      "Precision of Train ......................................\n",
      "[0.6608527302742004, 0.7225130796432495, 0.760188102722168, 0.7994056344032288, 0.8125874400138855, 0.825352132320404, 0.8302139043807983, 0.8563535809516907, 0.8660221099853516, 0.8769018054008484, 0.9001386761665344, 0.8994490504264832, 0.9046961069107056, 0.9062069058418274, 0.9237288236618042, 0.9300699234008789, 0.9257702827453613, 0.9223300814628601, 0.9372385144233704, 0.9368998408317566]\n",
      "Recall of Train ......................................\n",
      "[0.47361111640930176, 0.574999988079071, 0.6736111044883728, 0.7472222447395325, 0.8069444298744202, 0.8138889074325562, 0.862500011920929, 0.8611111044883728, 0.8708333373069763, 0.8805555701255798, 0.9013888835906982, 0.9069444537162781, 0.9097222089767456, 0.9125000238418579, 0.9083333611488342, 0.9236111044883728, 0.918055534362793, 0.9236111044883728, 0.9333333373069763, 0.9486111402511597]\n",
      "AUC of Train ......................................\n",
      "[0.6595370769500732, 0.7509866952896118, 0.8074729442596436, 0.8596537113189697, 0.8951523900032043, 0.9027555584907532, 0.9268624782562256, 0.9351590871810913, 0.9454079270362854, 0.9538821578025818, 0.9628221988677979, 0.9636921286582947, 0.9704726338386536, 0.971230685710907, 0.9742379784584045, 0.9784751534461975, 0.9802546501159668, 0.9791145920753479, 0.9814910888671875, 0.9849864840507507]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8534027695655823\n",
      " Loss:0.4386927202343941\n",
      " Precision:0.8598459362983704\n",
      " Recall:0.8375694483518601\n",
      " AUC:0.9191823810338974\n",
      "Score for fold 1: loss of 0.3343082070350647; accuracy of 0.9222221970558167%\n",
      "[[169  11]\n",
      " [ 17 163]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 391.9124225 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:169,FN:17,TP:163,FP:11\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9222222222222223\n",
      " Loss:0.3343082070350647\n",
      " Precision:0.9367816091954023\n",
      " Recall:0.9055555555555556\n",
      " AUC:0.907078853046595\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1921      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 31s 360ms/step - loss: 0.6793 - accuracy: 0.5750 - binary_crossentropy: 0.6793 - precision: 0.7216 - recall: 0.2688 - auc: 0.6709\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.6266 - accuracy: 0.6507 - binary_crossentropy: 0.6266 - precision: 0.7556 - recall: 0.4638 - auc: 0.7385\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.5889 - accuracy: 0.6951 - binary_crossentropy: 0.5889 - precision: 0.7692 - recall: 0.5730 - auc: 0.7907\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.5639 - accuracy: 0.7236 - binary_crossentropy: 0.5639 - precision: 0.7778 - recall: 0.6398 - auc: 0.8234\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.5274 - accuracy: 0.7854 - binary_crossentropy: 0.5274 - precision: 0.8174 - recall: 0.7449 - auc: 0.8691\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.5055 - accuracy: 0.7986 - binary_crossentropy: 0.5055 - precision: 0.8142 - recall: 0.7831 - auc: 0.8871\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.4842 - accuracy: 0.8257 - binary_crossentropy: 0.4842 - precision: 0.8366 - recall: 0.8172 - auc: 0.9078\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.4667 - accuracy: 0.8375 - binary_crossentropy: 0.4667 - precision: 0.8470 - recall: 0.8308 - auc: 0.9209\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.4468 - accuracy: 0.8583 - binary_crossentropy: 0.4468 - precision: 0.8679 - recall: 0.8513 - auc: 0.9311\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.4305 - accuracy: 0.8639 - binary_crossentropy: 0.4305 - precision: 0.8623 - recall: 0.8718 - auc: 0.9409\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.4130 - accuracy: 0.8757 - binary_crossentropy: 0.4130 - precision: 0.8805 - recall: 0.8745 - auc: 0.9505\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.4003 - accuracy: 0.8833 - binary_crossentropy: 0.4003 - precision: 0.8802 - recall: 0.8922 - auc: 0.9562\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.3876 - accuracy: 0.8951 - binary_crossentropy: 0.3876 - precision: 0.8975 - recall: 0.8963 - auc: 0.9609\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.3758 - accuracy: 0.9014 - binary_crossentropy: 0.3758 - precision: 0.9031 - recall: 0.9031 - auc: 0.9634\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.3693 - accuracy: 0.9007 - binary_crossentropy: 0.3693 - precision: 0.8933 - recall: 0.9141 - auc: 0.9655\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.3538 - accuracy: 0.9049 - binary_crossentropy: 0.3538 - precision: 0.9005 - recall: 0.9141 - auc: 0.9707\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.3424 - accuracy: 0.9208 - binary_crossentropy: 0.3424 - precision: 0.9199 - recall: 0.9250 - auc: 0.9753\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.3360 - accuracy: 0.9056 - binary_crossentropy: 0.3360 - precision: 0.9039 - recall: 0.9113 - auc: 0.9734\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.3188 - accuracy: 0.9319 - binary_crossentropy: 0.3188 - precision: 0.9332 - recall: 0.9332 - auc: 0.9799\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.3092 - accuracy: 0.9312 - binary_crossentropy: 0.3092 - precision: 0.9249 - recall: 0.9413 - auc: 0.9832\n",
      "Loss of Train ......................................\n",
      "[0.679339587688446, 0.626649796962738, 0.5888713002204895, 0.5639258623123169, 0.5273952484130859, 0.5054940581321716, 0.4841535687446594, 0.46672165393829346, 0.44677379727363586, 0.43045252561569214, 0.4130348265171051, 0.40026482939720154, 0.38759854435920715, 0.3757557272911072, 0.3693300783634186, 0.3537590205669403, 0.3423804044723511, 0.3360011875629425, 0.3187677264213562, 0.3092421591281891]\n",
      "Accuracy of Train ......................................\n",
      "[0.574999988079071, 0.6506944298744202, 0.6951388716697693, 0.7236111164093018, 0.7854166626930237, 0.7986111044883728, 0.8256944417953491, 0.8374999761581421, 0.8583333492279053, 0.8638888597488403, 0.8756944537162781, 0.8833333253860474, 0.8951388597488403, 0.9013888835906982, 0.9006944298744202, 0.9048610925674438, 0.9208333492279053, 0.9055555462837219, 0.9319444298744202, 0.9312499761581421]\n",
      "Precision of Train ......................................\n",
      "[0.721611738204956, 0.7555555701255798, 0.7692307829856873, 0.7777777910232544, 0.817365288734436, 0.8141843676567078, 0.8365921974182129, 0.8470097184181213, 0.8678720593452454, 0.862348198890686, 0.8804945349693298, 0.8802153468132019, 0.8975409865379333, 0.9031378030776978, 0.8933333158493042, 0.9005376100540161, 0.9199457168579102, 0.9039242267608643, 0.9331514239311218, 0.9249329566955566]\n",
      "Recall of Train ......................................\n",
      "[0.26875853538513184, 0.46384719014167786, 0.5729877352714539, 0.639836311340332, 0.7448840141296387, 0.7830832004547119, 0.817189633846283, 0.8308321833610535, 0.851296067237854, 0.8717598915100098, 0.8744884133338928, 0.8922237157821655, 0.8963165283203125, 0.9031378030776978, 0.9140518307685852, 0.9140518307685852, 0.9249659180641174, 0.9113233089447021, 0.9331514239311218, 0.941336989402771]\n",
      "AUC of Train ......................................\n",
      "[0.6709102392196655, 0.7385027408599854, 0.7906985282897949, 0.8233914971351624, 0.8690641522407532, 0.8871120810508728, 0.9077861905097961, 0.9209328889846802, 0.9311098456382751, 0.9409152865409851, 0.9505201578140259, 0.9561759829521179, 0.9608871340751648, 0.9634052515029907, 0.9655027985572815, 0.9707427024841309, 0.975284218788147, 0.9733604192733765, 0.9799423217773438, 0.9832140207290649]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8332291573286057\n",
      " Loss:0.44629559516906736\n",
      " Precision:0.8553380817174911\n",
      " Recall:0.7974761262536049\n",
      " AUC:0.9079729229211807\n",
      "Score for fold 2: loss of 0.315488338470459; accuracy of 0.9222221970558167%\n",
      "[[176  17]\n",
      " [ 11 156]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 771.2931298000001 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:176,FN:11,TP:156,FP:17\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9222222222222223\n",
      " Loss:0.315488338470459\n",
      " Precision:0.9017341040462428\n",
      " Recall:0.9341317365269461\n",
      " AUC:0.9376541035575907\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 31s 361ms/step - loss: 0.7296 - accuracy: 0.4882 - binary_crossentropy: 0.7296 - precision: 0.4795 - recall: 0.6006 - auc: 0.5039\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.6789 - accuracy: 0.5688 - binary_crossentropy: 0.6789 - precision: 0.5514 - recall: 0.6120 - auc: 0.6070\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 17s 390ms/step - loss: 0.6360 - accuracy: 0.6542 - binary_crossentropy: 0.6360 - precision: 0.6370 - recall: 0.6733 - auc: 0.6997\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.6044 - accuracy: 0.6917 - binary_crossentropy: 0.6044 - precision: 0.6812 - recall: 0.6890 - auc: 0.7564\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.5648 - accuracy: 0.7458 - binary_crossentropy: 0.5648 - precision: 0.7460 - recall: 0.7247 - auc: 0.8237\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.5376 - accuracy: 0.7847 - binary_crossentropy: 0.5376 - precision: 0.7888 - recall: 0.7618 - auc: 0.8617\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.5156 - accuracy: 0.8049 - binary_crossentropy: 0.5156 - precision: 0.8182 - recall: 0.7703 - auc: 0.8817\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.4931 - accuracy: 0.8347 - binary_crossentropy: 0.4931 - precision: 0.8502 - recall: 0.8017 - auc: 0.9102\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.4716 - accuracy: 0.8403 - binary_crossentropy: 0.4716 - precision: 0.8563 - recall: 0.8074 - auc: 0.9237\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.4481 - accuracy: 0.8694 - binary_crossentropy: 0.4481 - precision: 0.8880 - recall: 0.8374 - auc: 0.9421\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.4349 - accuracy: 0.8729 - binary_crossentropy: 0.4349 - precision: 0.8854 - recall: 0.8488 - auc: 0.9441\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.4127 - accuracy: 0.8931 - binary_crossentropy: 0.4127 - precision: 0.9100 - recall: 0.8659 - auc: 0.9571\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.3997 - accuracy: 0.9035 - binary_crossentropy: 0.3997 - precision: 0.9232 - recall: 0.8745 - auc: 0.9639\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.3851 - accuracy: 0.9035 - binary_crossentropy: 0.3851 - precision: 0.9271 - recall: 0.8702 - auc: 0.9701\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.3737 - accuracy: 0.9104 - binary_crossentropy: 0.3737 - precision: 0.9294 - recall: 0.8830 - auc: 0.9711\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.3658 - accuracy: 0.9125 - binary_crossentropy: 0.3658 - precision: 0.9297 - recall: 0.8873 - auc: 0.9708\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.3559 - accuracy: 0.9125 - binary_crossentropy: 0.3559 - precision: 0.9285 - recall: 0.8887 - auc: 0.9725\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.3439 - accuracy: 0.9229 - binary_crossentropy: 0.3439 - precision: 0.9456 - recall: 0.8930 - auc: 0.9789\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.3292 - accuracy: 0.9319 - binary_crossentropy: 0.3292 - precision: 0.9507 - recall: 0.9073 - auc: 0.9820\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.3185 - accuracy: 0.9361 - binary_crossentropy: 0.3185 - precision: 0.9552 - recall: 0.9116 - auc: 0.9843\n",
      "Loss of Train ......................................\n",
      "[0.729612410068512, 0.6788659691810608, 0.6360148191452026, 0.6043828129768372, 0.5647739171981812, 0.5376219153404236, 0.5156351327896118, 0.4931195080280304, 0.4716077446937561, 0.44814860820770264, 0.43485400080680847, 0.41269320249557495, 0.3997358977794647, 0.3850894570350647, 0.3736985921859741, 0.3658166527748108, 0.3558781147003174, 0.3439381420612335, 0.32920658588409424, 0.31854861974716187]\n",
      "Accuracy of Train ......................................\n",
      "[0.48819443583488464, 0.5687500238418579, 0.6541666388511658, 0.6916666626930237, 0.7458333373069763, 0.7847222089767456, 0.8048611283302307, 0.8347222208976746, 0.8402777910232544, 0.8694444298744202, 0.8729166388511658, 0.8930555582046509, 0.9034722447395325, 0.9034722447395325, 0.9104166626930237, 0.9125000238418579, 0.9125000238418579, 0.9229166507720947, 0.9319444298744202, 0.9361110925674438]\n",
      "Precision of Train ......................................\n",
      "[0.47949886322021484, 0.551413893699646, 0.6369770765304565, 0.6812412142753601, 0.7459618449211121, 0.7887740135192871, 0.8181818127632141, 0.8502269387245178, 0.8562783598899841, 0.8880484104156494, 0.8854166865348816, 0.9100449681282043, 0.9231927990913391, 0.9270516633987427, 0.9294294118881226, 0.9297459125518799, 0.928464949131012, 0.9456193447113037, 0.9506726264953613, 0.9551569223403931]\n",
      "Recall of Train ......................................\n",
      "[0.6005706191062927, 0.6119828820228577, 0.6733238101005554, 0.6890156865119934, 0.7246790528297424, 0.7617688775062561, 0.7703281044960022, 0.8017118573188782, 0.8074179887771606, 0.8373751640319824, 0.8487874269485474, 0.8659058213233948, 0.8744650483131409, 0.8701854348182678, 0.883024275302887, 0.8873038291931152, 0.8887304067611694, 0.8930099606513977, 0.9072753190994263, 0.9115549325942993]\n",
      "AUC of Train ......................................\n",
      "[0.5038790106773376, 0.6070025563240051, 0.6996963620185852, 0.7563542723655701, 0.8236995935440063, 0.8616522550582886, 0.8816893100738525, 0.9102461338043213, 0.9237297177314758, 0.9421201944351196, 0.9441210627555847, 0.9570978283882141, 0.9638530611991882, 0.9700890779495239, 0.9710697531700134, 0.9708293676376343, 0.9725300669670105, 0.9789089560508728, 0.9820119738578796, 0.9842994213104248]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8190972223877907\n",
      " Loss:0.46996210515499115\n",
      " Precision:0.8290698856115342\n",
      " Recall:0.8054208248853684\n",
      " AUC:0.8802439987659454\n",
      "Score for fold 3: loss of 0.35077860951423645; accuracy of 0.9111111164093018%\n",
      "[[145  16]\n",
      " [ 16 183]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1148.2800462999999 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:145,FN:16,TP:183,FP:16\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9111111111111111\n",
      " Loss:0.35077860951423645\n",
      " Precision:0.9195979899497487\n",
      " Recall:0.9195979899497487\n",
      " AUC:0.9101095539810855\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 30s 365ms/step - loss: 0.7439 - accuracy: 0.5396 - binary_crossentropy: 0.7439 - precision: 0.5260 - recall: 0.9163 - auc: 0.5445\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.6752 - accuracy: 0.5743 - binary_crossentropy: 0.6752 - precision: 0.5504 - recall: 0.8683 - auc: 0.6494\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.6338 - accuracy: 0.6500 - binary_crossentropy: 0.6338 - precision: 0.6079 - recall: 0.8697 - auc: 0.7196\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.5945 - accuracy: 0.7090 - binary_crossentropy: 0.5945 - precision: 0.6674 - recall: 0.8477 - auc: 0.7886\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 18s 391ms/step - loss: 0.5677 - accuracy: 0.7479 - binary_crossentropy: 0.5677 - precision: 0.7084 - recall: 0.8532 - auc: 0.8276\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.5343 - accuracy: 0.7861 - binary_crossentropy: 0.5343 - precision: 0.7497 - recall: 0.8669 - auc: 0.8759\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.5151 - accuracy: 0.8090 - binary_crossentropy: 0.5151 - precision: 0.7845 - recall: 0.8587 - auc: 0.8931\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.4918 - accuracy: 0.8285 - binary_crossentropy: 0.4918 - precision: 0.7975 - recall: 0.8861 - auc: 0.9139\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.4665 - accuracy: 0.8535 - binary_crossentropy: 0.4665 - precision: 0.8304 - recall: 0.8930 - auc: 0.9370\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.4587 - accuracy: 0.8604 - binary_crossentropy: 0.4587 - precision: 0.8465 - recall: 0.8848 - auc: 0.9360\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.4431 - accuracy: 0.8764 - binary_crossentropy: 0.4431 - precision: 0.8611 - recall: 0.9012 - auc: 0.9418\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.4230 - accuracy: 0.8847 - binary_crossentropy: 0.4230 - precision: 0.8748 - recall: 0.9012 - auc: 0.9571\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.4019 - accuracy: 0.9014 - binary_crossentropy: 0.4019 - precision: 0.8887 - recall: 0.9204 - auc: 0.9662\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.3890 - accuracy: 0.9076 - binary_crossentropy: 0.3890 - precision: 0.8995 - recall: 0.9204 - auc: 0.9697\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.3841 - accuracy: 0.9042 - binary_crossentropy: 0.3841 - precision: 0.9020 - recall: 0.9095 - auc: 0.9691\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.3690 - accuracy: 0.9132 - binary_crossentropy: 0.3690 - precision: 0.9070 - recall: 0.9232 - auc: 0.9740\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.3514 - accuracy: 0.9243 - binary_crossentropy: 0.3514 - precision: 0.9189 - recall: 0.9328 - auc: 0.9791\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.3437 - accuracy: 0.9201 - binary_crossentropy: 0.3437 - precision: 0.9205 - recall: 0.9218 - auc: 0.9781\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.3373 - accuracy: 0.9187 - binary_crossentropy: 0.3373 - precision: 0.9135 - recall: 0.9273 - auc: 0.9798\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.3294 - accuracy: 0.9215 - binary_crossentropy: 0.3294 - precision: 0.9196 - recall: 0.9259 - auc: 0.9816\n",
      "Loss of Train ......................................\n",
      "[0.7439274191856384, 0.6752334833145142, 0.6338021755218506, 0.594509482383728, 0.5676965713500977, 0.5342968702316284, 0.515116274356842, 0.4917527139186859, 0.4664549231529236, 0.45865458250045776, 0.4430600106716156, 0.42297834157943726, 0.4019067883491516, 0.38901498913764954, 0.38405415415763855, 0.3690468370914459, 0.35138270258903503, 0.3437122404575348, 0.3373236656188965, 0.32937338948249817]\n",
      "Accuracy of Train ......................................\n",
      "[0.5395833253860474, 0.574305534362793, 0.6499999761581421, 0.7090277671813965, 0.7479166388511658, 0.7861111164093018, 0.8090277910232544, 0.8284721970558167, 0.8534722328186035, 0.8604166507720947, 0.8763889074325562, 0.8847222328186035, 0.9013888835906982, 0.9076389074325562, 0.9041666388511658, 0.9131944179534912, 0.9243055582046509, 0.9201388955116272, 0.918749988079071, 0.9215278029441833]\n",
      "Precision of Train ......................................\n",
      "[0.5259842276573181, 0.5504347681999207, 0.6078619360923767, 0.6673865914344788, 0.7084282636642456, 0.7497034668922424, 0.7844611406326294, 0.7975308895111084, 0.8303571343421936, 0.8464567065238953, 0.861074686050415, 0.8748335838317871, 0.8887417316436768, 0.8994638323783875, 0.9020408391952515, 0.9070081114768982, 0.9189189076423645, 0.9205479621887207, 0.9135135412216187, 0.919618546962738]\n",
      "Recall of Train ......................................\n",
      "[0.916323721408844, 0.8683127760887146, 0.8696845173835754, 0.8477365970611572, 0.8532236218452454, 0.8669410347938538, 0.8587105870246887, 0.8861454129219055, 0.8930041193962097, 0.8847736716270447, 0.9012345671653748, 0.9012345671653748, 0.9204389452934265, 0.9204389452934265, 0.9094650149345398, 0.9231824278831482, 0.9327846169471741, 0.9218106865882874, 0.9272976517677307, 0.9259259104728699]\n",
      "AUC of Train ......................................\n",
      "[0.5445420742034912, 0.6493569016456604, 0.7196128368377686, 0.7886330485343933, 0.8276254534721375, 0.8759374022483826, 0.8930619955062866, 0.9139188528060913, 0.9369693398475647, 0.9360325932502747, 0.9417781233787537, 0.9571354985237122, 0.9662215709686279, 0.9696548581123352, 0.9690934419631958, 0.9739503860473633, 0.9791277647018433, 0.9781070947647095, 0.9798415303230286, 0.9815557599067688]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.821527773141861\n",
      " Loss:0.47266488075256347\n",
      " Precision:0.8037183433771133\n",
      " Recall:0.8964334696531295\n",
      " AUC:0.8891078263521195\n",
      "Score for fold 4: loss of 0.3529476523399353; accuracy of 0.8916666507720947%\n",
      "[[170  19]\n",
      " [ 20 151]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1541.2460397999998 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:170,FN:20,TP:151,FP:19\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8916666666666667\n",
      " Loss:0.3529476523399353\n",
      " Precision:0.888235294117647\n",
      " Recall:0.8830409356725146\n",
      " AUC:0.8888888888888888\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 31s 363ms/step - loss: 0.7148 - accuracy: 0.5139 - binary_crossentropy: 0.7148 - precision: 0.5111 - recall: 0.5481 - auc: 0.5129\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.6713 - accuracy: 0.5854 - binary_crossentropy: 0.6713 - precision: 0.5785 - recall: 0.6165 - auc: 0.6169\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.6365 - accuracy: 0.6431 - binary_crossentropy: 0.6365 - precision: 0.6400 - recall: 0.6471 - auc: 0.6998\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.6014 - accuracy: 0.7035 - binary_crossentropy: 0.6014 - precision: 0.6965 - recall: 0.7169 - auc: 0.7716\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.5743 - accuracy: 0.7389 - binary_crossentropy: 0.5743 - precision: 0.7378 - recall: 0.7378 - auc: 0.8212\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.5474 - accuracy: 0.7833 - binary_crossentropy: 0.5474 - precision: 0.7824 - recall: 0.7824 - auc: 0.8597\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.5231 - accuracy: 0.8201 - binary_crossentropy: 0.5231 - precision: 0.8181 - recall: 0.8215 - auc: 0.8939\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.4997 - accuracy: 0.8382 - binary_crossentropy: 0.4997 - precision: 0.8457 - recall: 0.8257 - auc: 0.9159\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.4791 - accuracy: 0.8549 - binary_crossentropy: 0.4791 - precision: 0.8618 - recall: 0.8438 - auc: 0.9298\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.4630 - accuracy: 0.8667 - binary_crossentropy: 0.4630 - precision: 0.8799 - recall: 0.8480 - auc: 0.9384\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.4427 - accuracy: 0.8785 - binary_crossentropy: 0.4427 - precision: 0.8796 - recall: 0.8759 - auc: 0.9503\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.4275 - accuracy: 0.8965 - binary_crossentropy: 0.4275 - precision: 0.9034 - recall: 0.8870 - auc: 0.9583\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.4128 - accuracy: 0.8986 - binary_crossentropy: 0.4128 - precision: 0.9050 - recall: 0.8898 - auc: 0.9623\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.3990 - accuracy: 0.9028 - binary_crossentropy: 0.3990 - precision: 0.9069 - recall: 0.8968 - auc: 0.9672\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.3856 - accuracy: 0.9194 - binary_crossentropy: 0.3856 - precision: 0.9262 - recall: 0.9107 - auc: 0.9723\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.3738 - accuracy: 0.9146 - binary_crossentropy: 0.3738 - precision: 0.9219 - recall: 0.9052 - auc: 0.9737\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.3605 - accuracy: 0.9278 - binary_crossentropy: 0.3605 - precision: 0.9385 - recall: 0.9149 - auc: 0.9777\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.3472 - accuracy: 0.9264 - binary_crossentropy: 0.3472 - precision: 0.9383 - recall: 0.9121 - auc: 0.9808\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.3444 - accuracy: 0.9236 - binary_crossentropy: 0.3444 - precision: 0.9380 - recall: 0.9066 - auc: 0.9774\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.3311 - accuracy: 0.9361 - binary_crossentropy: 0.3311 - precision: 0.9471 - recall: 0.9233 - auc: 0.9825\n",
      "Loss of Train ......................................\n",
      "[0.7148224115371704, 0.6712662577629089, 0.6364537477493286, 0.6014048457145691, 0.5743337869644165, 0.5474441051483154, 0.5231257081031799, 0.4996556043624878, 0.47909191250801086, 0.4630466103553772, 0.44269439578056335, 0.4274525046348572, 0.4127887189388275, 0.3990150988101959, 0.3855735659599304, 0.3737514615058899, 0.3605022132396698, 0.34723639488220215, 0.3443954586982727, 0.33114174008369446]\n",
      "Accuracy of Train ......................................\n",
      "[0.5138888955116272, 0.5854166746139526, 0.6430555582046509, 0.7034721970558167, 0.7388888597488403, 0.7833333611488342, 0.8201388716697693, 0.8381944298744202, 0.8548611402511597, 0.8666666746139526, 0.8784722089767456, 0.8965277671813965, 0.8986111283302307, 0.9027777910232544, 0.9194444417953491, 0.9145833253860474, 0.9277777671813965, 0.9263888597488403, 0.9236111044883728, 0.9361110925674438]\n",
      "Precision of Train ......................................\n",
      "[0.5110533237457275, 0.5785340070724487, 0.6399999856948853, 0.696476936340332, 0.7377963662147522, 0.7824267745018005, 0.8180555701255798, 0.845714271068573, 0.8618233799934387, 0.8798842430114746, 0.8795518279075623, 0.9034090638160706, 0.9049645662307739, 0.9069111347198486, 0.9262411594390869, 0.921875, 0.9384835362434387, 0.9383070468902588, 0.9379509091377258, 0.9470672607421875]\n",
      "Recall of Train ......................................\n",
      "[0.5481171607971191, 0.616457462310791, 0.6471408605575562, 0.7168758511543274, 0.7377963662147522, 0.7824267745018005, 0.8214783668518066, 0.8256624937057495, 0.8437935709953308, 0.8479776978492737, 0.8758716583251953, 0.8870292901992798, 0.8898186683654785, 0.8967921733856201, 0.9107391834259033, 0.9051603674888611, 0.9149233102798462, 0.9121338725090027, 0.9065551161766052, 0.9232915043830872]\n",
      "AUC of Train ......................................\n",
      "[0.5129197835922241, 0.6169107556343079, 0.6997555494308472, 0.7716172933578491, 0.8212140798568726, 0.8596744537353516, 0.8939169645309448, 0.9159398674964905, 0.9297576546669006, 0.9384402632713318, 0.9502567052841187, 0.9583345055580139, 0.9622803926467896, 0.9672369956970215, 0.9722825288772583, 0.9736945033073425, 0.9776818752288818, 0.9808089137077332, 0.9774379730224609, 0.9825257062911987]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.823611107468605\n",
      " Loss:0.4767598271369934\n",
      " Precision:0.8278263181447982\n",
      " Recall:0.8205020874738693\n",
      " AUC:0.883134338259697\n",
      "Score for fold 5: loss of 0.3391035199165344; accuracy of 0.9138888716697693%\n",
      "[[161  16]\n",
      " [ 15 168]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1941.4506469 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:161,FN:15,TP:168,FP:16\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9138888888888889\n",
      " Loss:0.3391035199165344\n",
      " Precision:0.9130434782608695\n",
      " Recall:0.9180327868852459\n",
      " AUC:0.9164027570789866\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.8534027695655823 - Loss: 0.4386927202343941\n",
      "> Fold 1 - Precision: 0.8598459362983704\n",
      "> Fold 1 - Recall: 0.8375694483518601\n",
      "> Fold 1 - AUC: 0.9191823810338974\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9222222222222223 - Loss: 0.3343082070350647\n",
      "> Fold 1 - Precision: 0.9367816091954023\n",
      "> Fold 1 - Recall: 0.9055555555555556\n",
      "> Fold 1 - AUC: 0.907078853046595\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8332291573286057 - Loss: 0.44629559516906736\n",
      "> Fold 2 - Precision: 0.8553380817174911\n",
      "> Fold 2 - Recall: 0.7974761262536049\n",
      "> Fold 2 - AUC: 0.9079729229211807\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.9222222222222223 - Loss: 0.315488338470459\n",
      "> Fold 2 - Precision: 0.9017341040462428\n",
      "> Fold 2 - Recall: 0.9341317365269461\n",
      "> Fold 2 - AUC: 0.9376541035575907\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.8190972223877907 - Loss: 0.46996210515499115\n",
      "> Fold 3 - Precision: 0.8290698856115342\n",
      "> Fold 3 - Recall: 0.8054208248853684\n",
      "> Fold 3 - AUC: 0.8802439987659454\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9111111111111111 - Loss: 0.35077860951423645\n",
      "> Fold 3 - Precision: 0.9195979899497487\n",
      "> Fold 3 - Recall: 0.9195979899497487\n",
      "> Fold 3 - AUC: 0.9101095539810855\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.821527773141861 - Loss: 0.47266488075256347\n",
      "> Fold 4 - Precision: 0.8037183433771133\n",
      "> Fold 4 - Recall: 0.8964334696531295\n",
      "> Fold 4 - AUC: 0.8891078263521195\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.8916666666666667 - Loss: 0.3529476523399353\n",
      "> Fold 4 - Precision: 0.888235294117647\n",
      "> Fold 4 - Recall: 0.8830409356725146\n",
      "> Fold 4 - AUC: 0.8888888888888888\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.823611107468605 - Loss: 0.4767598271369934\n",
      "> Fold 5 - Precision: 0.8278263181447982\n",
      "> Fold 5 - Recall: 0.8205020874738693\n",
      "> Fold 5 - AUC: 0.883134338259697\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9138888888888889 - Loss: 0.3391035199165344\n",
      "> Fold 5 - Precision: 0.9130434782608695\n",
      "> Fold 5 - Recall: 0.9180327868852459\n",
      "> Fold 5 - AUC: 0.9164027570789866\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.8301736059784888 (+- 0.012565297613575053)\n",
      "> Loss: 0.46087502568960187 (+- 0.015352635488737599)\n",
      "> Precision: 0.8351597130298615 (+- 0.020474377091001413)\n",
      "> Recall: 0.8314803913235664 (+- 0.035247391963921286)\n",
      "> AUC: 0.895928293466568 (+- 0.015113086045137308)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9122222222222222 (+- 0.011194134266449935)\n",
      "> Loss: 0.33852526545524597 (+- 0.013468241525331246)\n",
      "> Precision: 0.9118784951139821 (+- 0.01638915800578248)\n",
      "> Recall: 0.9120718009180022 (+- 0.01711181010085886)\n",
      "> AUC: 0.9120268313106292 (+- 0.015744387126348024)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 821 FN SUM: 79 TP SUM: 821 FP SUM: 79\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2, DenseNet201\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(DenseNet201(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a7987",
   "metadata": {},
   "source": [
    "# MobileNetV2 - (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954e764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 18s 156ms/step - loss: 0.7958 - accuracy: 0.4354 - binary_crossentropy: 0.7958 - precision: 0.4462 - recall: 0.5615 - auc: 0.4000\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.7448 - accuracy: 0.4882 - binary_crossentropy: 0.7448 - precision: 0.4879 - recall: 0.5908 - auc: 0.4821\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.7096 - accuracy: 0.5188 - binary_crossentropy: 0.7096 - precision: 0.5137 - recall: 0.6006 - auc: 0.5460\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.6748 - accuracy: 0.5847 - binary_crossentropy: 0.6748 - precision: 0.5713 - recall: 0.6606 - auc: 0.6199\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.6340 - accuracy: 0.6333 - binary_crossentropy: 0.6340 - precision: 0.6160 - recall: 0.6969 - auc: 0.6951\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.6132 - accuracy: 0.6590 - binary_crossentropy: 0.6132 - precision: 0.6419 - recall: 0.7109 - auc: 0.7307\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.5843 - accuracy: 0.7035 - binary_crossentropy: 0.5843 - precision: 0.6865 - recall: 0.7430 - auc: 0.7798\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.5640 - accuracy: 0.7354 - binary_crossentropy: 0.5640 - precision: 0.7219 - recall: 0.7612 - auc: 0.8109\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.5391 - accuracy: 0.7604 - binary_crossentropy: 0.5391 - precision: 0.7510 - recall: 0.7751 - auc: 0.8435\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.5203 - accuracy: 0.7750 - binary_crossentropy: 0.5203 - precision: 0.7579 - recall: 0.8045 - auc: 0.8652\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.5009 - accuracy: 0.8007 - binary_crossentropy: 0.5009 - precision: 0.7879 - recall: 0.8198 - auc: 0.8834\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.4883 - accuracy: 0.8257 - binary_crossentropy: 0.4883 - precision: 0.8181 - recall: 0.8352 - auc: 0.8967\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.4772 - accuracy: 0.8194 - binary_crossentropy: 0.4772 - precision: 0.8175 - recall: 0.8198 - auc: 0.9026\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.4628 - accuracy: 0.8285 - binary_crossentropy: 0.4628 - precision: 0.8182 - recall: 0.8422 - auc: 0.9104\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.4422 - accuracy: 0.8424 - binary_crossentropy: 0.4422 - precision: 0.8354 - recall: 0.8506 - auc: 0.9267\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.4255 - accuracy: 0.8576 - binary_crossentropy: 0.4255 - precision: 0.8524 - recall: 0.8631 - auc: 0.9382\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.4153 - accuracy: 0.8597 - binary_crossentropy: 0.4153 - precision: 0.8560 - recall: 0.8631 - auc: 0.9407\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.4099 - accuracy: 0.8618 - binary_crossentropy: 0.4099 - precision: 0.8605 - recall: 0.8617 - auc: 0.9400\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.3947 - accuracy: 0.8722 - binary_crossentropy: 0.3947 - precision: 0.8757 - recall: 0.8659 - auc: 0.9498\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.3880 - accuracy: 0.8743 - binary_crossentropy: 0.3880 - precision: 0.8720 - recall: 0.8757 - auc: 0.9527\n",
      "Loss of Train ......................................\n",
      "[0.7958495020866394, 0.7447755336761475, 0.7096080183982849, 0.6748319268226624, 0.6340411901473999, 0.6132427453994751, 0.5843150615692139, 0.5639933943748474, 0.5391317009925842, 0.5203262567520142, 0.5008726119995117, 0.4882759153842926, 0.477242112159729, 0.46283262968063354, 0.4421514868736267, 0.425549179315567, 0.41531163454055786, 0.40990638732910156, 0.3947329521179199, 0.3880111575126648]\n",
      "Accuracy of Train ......................................\n",
      "[0.43541666865348816, 0.48819443583488464, 0.518750011920929, 0.5847222208976746, 0.6333333253860474, 0.6590277552604675, 0.7034721970558167, 0.7354166507720947, 0.7604166865348816, 0.7749999761581421, 0.800694465637207, 0.8256944417953491, 0.8194444179534912, 0.8284721970558167, 0.8423610925674438, 0.8576388955116272, 0.8597221970558167, 0.8618055582046509, 0.8722222447395325, 0.8743055462837219]\n",
      "Precision of Train ......................................\n",
      "[0.4461709260940552, 0.48788926005363464, 0.5137395262718201, 0.5712560415267944, 0.6160494089126587, 0.6418663263320923, 0.6864516139030457, 0.7218543291091919, 0.7510148882865906, 0.75789475440979, 0.7879194617271423, 0.8180574774742126, 0.8175487518310547, 0.8181818127632141, 0.8353909254074097, 0.8524137735366821, 0.8559556603431702, 0.8605299592018127, 0.8757061958312988, 0.8720445036888123]\n",
      "Recall of Train ......................................\n",
      "[0.5614525079727173, 0.590782105922699, 0.6005586385726929, 0.660614550113678, 0.6969273686408997, 0.7108938694000244, 0.74301677942276, 0.7611731886863708, 0.7751396894454956, 0.8044692873954773, 0.8198323845863342, 0.8351955413818359, 0.8198323845863342, 0.8421787619590759, 0.8505586385726929, 0.8631284832954407, 0.8631284832954407, 0.8617318272590637, 0.8659217953681946, 0.8756983280181885]\n",
      "AUC of Train ......................................\n",
      "[0.4000220000743866, 0.4820837676525116, 0.5460035800933838, 0.6198879480361938, 0.6950551867485046, 0.7307440042495728, 0.779813826084137, 0.8109036684036255, 0.8434760570526123, 0.8651559948921204, 0.883416473865509, 0.8966847062110901, 0.9026059508323669, 0.9104360938072205, 0.9267483353614807, 0.938173234462738, 0.9407359957695007, 0.9399990439414978, 0.9498489499092102, 0.9527010321617126]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7368055492639541\n",
      " Loss:0.5392500698566437\n",
      " Precision:0.7293967798352241\n",
      " Recall:0.7701117306947708\n",
      " AUC:0.8007247924804688\n",
      "Score for fold 1: loss of 0.5362801551818848; accuracy of 0.769444465637207%\n",
      "[[164  12]\n",
      " [ 71 113]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 183.1335271 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:164,FN:71,TP:113,FP:12\n",
      "Test of epochs .................................\n",
      " Accuracy:0.7694444444444445\n",
      " Loss:0.5362801551818848\n",
      " Precision:0.904\n",
      " Recall:0.6141304347826086\n",
      " AUC:0.6560013876040702\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_1 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 11s 159ms/step - loss: 0.7765 - accuracy: 0.4715 - binary_crossentropy: 0.7765 - precision: 0.4753 - recall: 0.6901 - auc: 0.4493\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.7281 - accuracy: 0.5264 - binary_crossentropy: 0.7281 - precision: 0.5145 - recall: 0.7014 - auc: 0.5323\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.6851 - accuracy: 0.5819 - binary_crossentropy: 0.6851 - precision: 0.5577 - recall: 0.7352 - auc: 0.6149\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.6571 - accuracy: 0.6146 - binary_crossentropy: 0.6571 - precision: 0.5886 - recall: 0.7254 - auc: 0.6603\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.6192 - accuracy: 0.6597 - binary_crossentropy: 0.6192 - precision: 0.6319 - recall: 0.7423 - auc: 0.7253\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.5923 - accuracy: 0.6958 - binary_crossentropy: 0.5923 - precision: 0.6709 - recall: 0.7521 - auc: 0.7711\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.5632 - accuracy: 0.7236 - binary_crossentropy: 0.5632 - precision: 0.6960 - recall: 0.7803 - auc: 0.8087\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.5487 - accuracy: 0.7410 - binary_crossentropy: 0.5487 - precision: 0.7169 - recall: 0.7845 - auc: 0.8264\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 8s 174ms/step - loss: 0.5245 - accuracy: 0.7604 - binary_crossentropy: 0.5245 - precision: 0.7404 - recall: 0.7915 - auc: 0.8538\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.5085 - accuracy: 0.7889 - binary_crossentropy: 0.5085 - precision: 0.7773 - recall: 0.8014 - auc: 0.8695\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.4853 - accuracy: 0.8042 - binary_crossentropy: 0.4853 - precision: 0.7940 - recall: 0.8141 - auc: 0.8935\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.4746 - accuracy: 0.8139 - binary_crossentropy: 0.4746 - precision: 0.8019 - recall: 0.8268 - auc: 0.8982\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.4581 - accuracy: 0.8319 - binary_crossentropy: 0.4581 - precision: 0.8223 - recall: 0.8408 - auc: 0.9108\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.4403 - accuracy: 0.8431 - binary_crossentropy: 0.4403 - precision: 0.8297 - recall: 0.8577 - auc: 0.9243\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.4341 - accuracy: 0.8438 - binary_crossentropy: 0.4341 - precision: 0.8345 - recall: 0.8521 - auc: 0.9293\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.4181 - accuracy: 0.8521 - binary_crossentropy: 0.4181 - precision: 0.8409 - recall: 0.8634 - auc: 0.9345\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 173ms/step - loss: 0.4139 - accuracy: 0.8528 - binary_crossentropy: 0.4139 - precision: 0.8449 - recall: 0.8592 - auc: 0.9352\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.3998 - accuracy: 0.8681 - binary_crossentropy: 0.3998 - precision: 0.8591 - recall: 0.8761 - auc: 0.9434\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.3865 - accuracy: 0.8701 - binary_crossentropy: 0.3865 - precision: 0.8627 - recall: 0.8761 - auc: 0.9493\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.3712 - accuracy: 0.8958 - binary_crossentropy: 0.3712 - precision: 0.8878 - recall: 0.9028 - auc: 0.9574\n",
      "Loss of Train ......................................\n",
      "[0.776523768901825, 0.7281267046928406, 0.6850757002830505, 0.6570524573326111, 0.6191656589508057, 0.5922709703445435, 0.5631961226463318, 0.5486886501312256, 0.5244975686073303, 0.5084943175315857, 0.4852677285671234, 0.4746052622795105, 0.458108514547348, 0.44030433893203735, 0.43409812450408936, 0.41805005073547363, 0.413862407207489, 0.39979439973831177, 0.38649994134902954, 0.37117719650268555]\n",
      "Accuracy of Train ......................................\n",
      "[0.4715277850627899, 0.5263888835906982, 0.581944465637207, 0.6145833134651184, 0.6597222089767456, 0.6958333253860474, 0.7236111164093018, 0.7409722208976746, 0.7604166865348816, 0.7888888716697693, 0.8041666746139526, 0.8138889074325562, 0.831944465637207, 0.8430555462837219, 0.84375, 0.8520833253860474, 0.8527777791023254, 0.8680555820465088, 0.8701388835906982, 0.8958333134651184]\n",
      "Precision of Train ......................................\n",
      "[0.4752667248249054, 0.5144628286361694, 0.557692289352417, 0.5885714292526245, 0.6318944692611694, 0.6708542704582214, 0.69597989320755, 0.7168596982955933, 0.7404479384422302, 0.7773224115371704, 0.7939560413360596, 0.8019125461578369, 0.8223140239715576, 0.8297002911567688, 0.834482729434967, 0.840877890586853, 0.8448753356933594, 0.8591160178184509, 0.8626906871795654, 0.8878116607666016]\n",
      "Recall of Train ......................................\n",
      "[0.6901408433914185, 0.7014084458351135, 0.7352112531661987, 0.7253521084785461, 0.7422535419464111, 0.7521126866340637, 0.780281662940979, 0.7845070362091064, 0.7915493249893188, 0.8014084696769714, 0.814084529876709, 0.8267605900764465, 0.8408450484275818, 0.8577464818954468, 0.8521126508712769, 0.8633802533149719, 0.8591549396514893, 0.8760563135147095, 0.8760563135147095, 0.902816891670227]\n",
      "AUC of Train ......................................\n",
      "[0.44930732250213623, 0.5322583913803101, 0.614880383014679, 0.6603143811225891, 0.7253144979476929, 0.771074652671814, 0.8086755871772766, 0.8263563513755798, 0.8537545800209045, 0.8694530129432678, 0.8935134410858154, 0.8981708884239197, 0.9107775092124939, 0.9243131875991821, 0.929318904876709, 0.9344897270202637, 0.9351939558982849, 0.9433947205543518, 0.949266791343689, 0.9573615193367004]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7519791677594185\n",
      " Loss:0.5242429941892623\n",
      " Precision:0.7373544588685036\n",
      " Recall:0.8036619693040847\n",
      " AUC:0.819359490275383\n",
      "Score for fold 2: loss of 0.6535331010818481; accuracy of 0.6277777552604675%\n",
      "[[ 38 132]\n",
      " [  2 188]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 342.7835891 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:38,FN:2,TP:188,FP:132\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6277777777777778\n",
      " Loss:0.6535331010818481\n",
      " Precision:0.5875\n",
      " Recall:0.9894736842105263\n",
      " AUC:0.9697368421052631\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 10s 156ms/step - loss: 0.7728 - accuracy: 0.4764 - binary_crossentropy: 0.7728 - precision: 0.4843 - recall: 0.7278 - auc: 0.4754\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.7266 - accuracy: 0.5257 - binary_crossentropy: 0.7266 - precision: 0.5181 - recall: 0.7361 - auc: 0.5506\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.6843 - accuracy: 0.5722 - binary_crossentropy: 0.6843 - precision: 0.5553 - recall: 0.7250 - auc: 0.6220\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.6450 - accuracy: 0.6250 - binary_crossentropy: 0.6450 - precision: 0.6000 - recall: 0.7500 - auc: 0.6896\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.6162 - accuracy: 0.6681 - binary_crossentropy: 0.6162 - precision: 0.6447 - recall: 0.7486 - auc: 0.7324\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.5983 - accuracy: 0.6847 - binary_crossentropy: 0.5983 - precision: 0.6638 - recall: 0.7486 - auc: 0.7582\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.5643 - accuracy: 0.7403 - binary_crossentropy: 0.5643 - precision: 0.7264 - recall: 0.7708 - auc: 0.8078\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.5462 - accuracy: 0.7493 - binary_crossentropy: 0.5462 - precision: 0.7397 - recall: 0.7694 - auc: 0.8268\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.5267 - accuracy: 0.7549 - binary_crossentropy: 0.5267 - precision: 0.7437 - recall: 0.7778 - auc: 0.8449\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.5094 - accuracy: 0.7854 - binary_crossentropy: 0.5094 - precision: 0.7766 - recall: 0.8014 - auc: 0.8651\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 8s 173ms/step - loss: 0.4928 - accuracy: 0.7993 - binary_crossentropy: 0.4928 - precision: 0.7948 - recall: 0.8069 - auc: 0.8788\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.4769 - accuracy: 0.8056 - binary_crossentropy: 0.4769 - precision: 0.8056 - recall: 0.8056 - auc: 0.8932\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 174ms/step - loss: 0.4507 - accuracy: 0.8340 - binary_crossentropy: 0.4507 - precision: 0.8281 - recall: 0.8431 - auc: 0.9121\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.4464 - accuracy: 0.8375 - binary_crossentropy: 0.4464 - precision: 0.8423 - recall: 0.8306 - auc: 0.9134\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.4367 - accuracy: 0.8444 - binary_crossentropy: 0.4367 - precision: 0.8444 - recall: 0.8444 - auc: 0.9194\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 174ms/step - loss: 0.4232 - accuracy: 0.8465 - binary_crossentropy: 0.4232 - precision: 0.8499 - recall: 0.8417 - auc: 0.9277\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.4117 - accuracy: 0.8486 - binary_crossentropy: 0.4117 - precision: 0.8596 - recall: 0.8333 - auc: 0.9331\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 179ms/step - loss: 0.3968 - accuracy: 0.8715 - binary_crossentropy: 0.3968 - precision: 0.8860 - recall: 0.8528 - auc: 0.9430\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.3842 - accuracy: 0.8736 - binary_crossentropy: 0.3842 - precision: 0.8854 - recall: 0.8583 - auc: 0.9487\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 176ms/step - loss: 0.3810 - accuracy: 0.8813 - binary_crossentropy: 0.3810 - precision: 0.8861 - recall: 0.8750 - auc: 0.9489\n",
      "Loss of Train ......................................\n",
      "[0.7728420495986938, 0.7266488075256348, 0.6843011379241943, 0.6450017094612122, 0.6162031292915344, 0.5983441472053528, 0.5643479228019714, 0.5461549162864685, 0.5267108678817749, 0.5093702673912048, 0.492830365896225, 0.4768834710121155, 0.4507361054420471, 0.4463893175125122, 0.43672439455986023, 0.4232058525085449, 0.4117477834224701, 0.39684969186782837, 0.3842185139656067, 0.38098275661468506]\n",
      "Accuracy of Train ......................................\n",
      "[0.4763889014720917, 0.5256944298744202, 0.5722222328186035, 0.625, 0.668055534362793, 0.6847222447395325, 0.7402777671813965, 0.7493055462837219, 0.7548611164093018, 0.7854166626930237, 0.7993055582046509, 0.8055555820465088, 0.8340277671813965, 0.8374999761581421, 0.8444444537162781, 0.8465277552604675, 0.8486111164093018, 0.8715277910232544, 0.8736110925674438, 0.8812500238418579]\n",
      "Precision of Train ......................................\n",
      "[0.48428836464881897, 0.5180840492248535, 0.5553191304206848, 0.6000000238418579, 0.6447368264198303, 0.6637930870056152, 0.7264397740364075, 0.7396528720855713, 0.7436919212341309, 0.7765814065933228, 0.794801652431488, 0.8055555820465088, 0.8281036615371704, 0.8422535061836243, 0.8444444537162781, 0.8499298691749573, 0.8595988750457764, 0.8860028982162476, 0.8853868246078491, 0.8860759735107422]\n",
      "Recall of Train ......................................\n",
      "[0.7277777791023254, 0.7361111044883728, 0.7250000238418579, 0.75, 0.7486110925674438, 0.7486110925674438, 0.7708333134651184, 0.769444465637207, 0.7777777910232544, 0.8013888597488403, 0.8069444298744202, 0.8055555820465088, 0.8430555462837219, 0.8305555582046509, 0.8444444537162781, 0.8416666388511658, 0.8333333134651184, 0.8527777791023254, 0.8583333492279053, 0.875]\n",
      "AUC of Train ......................................\n",
      "[0.47543787956237793, 0.5506163239479065, 0.6219936013221741, 0.6896286606788635, 0.7323977947235107, 0.7582311034202576, 0.807841420173645, 0.8267871737480164, 0.8449469804763794, 0.8650906085968018, 0.8788242936134338, 0.8932445645332336, 0.9120813608169556, 0.9134249687194824, 0.919396162033081, 0.9276793599128723, 0.9331085681915283, 0.9430362582206726, 0.9486863017082214, 0.9489410519599915]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7512152776122093\n",
      " Loss:0.5245246604084969\n",
      " Precision:0.7467370375990867\n",
      " Recall:0.797361108660698\n",
      " AUC:0.8195697218179703\n",
      "Score for fold 3: loss of 0.5886635780334473; accuracy of 0.6861110925674438%\n",
      "[[154  26]\n",
      " [ 87  93]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 504.67035799999996 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:154,FN:87,TP:93,FP:26\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6861111111111111\n",
      " Loss:0.5886635780334473\n",
      " Precision:0.7815126050420168\n",
      " Recall:0.5166666666666667\n",
      " AUC:0.57783540802213\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 158ms/step - loss: 0.7512 - accuracy: 0.5007 - binary_crossentropy: 0.7512 - precision: 0.5029 - recall: 0.5939 - auc: 0.5027\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 167ms/step - loss: 0.6992 - accuracy: 0.5597 - binary_crossentropy: 0.6992 - precision: 0.5551 - recall: 0.6257 - auc: 0.5851\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.6667 - accuracy: 0.5979 - binary_crossentropy: 0.6667 - precision: 0.5901 - recall: 0.6561 - auc: 0.6374\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 8s 175ms/step - loss: 0.6330 - accuracy: 0.6333 - binary_crossentropy: 0.6330 - precision: 0.6266 - recall: 0.6699 - auc: 0.6925\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.5979 - accuracy: 0.6764 - binary_crossentropy: 0.5979 - precision: 0.6637 - recall: 0.7224 - auc: 0.7466\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 178ms/step - loss: 0.5639 - accuracy: 0.7208 - binary_crossentropy: 0.5639 - precision: 0.7147 - recall: 0.7403 - auc: 0.7954\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 8s 178ms/step - loss: 0.5516 - accuracy: 0.7340 - binary_crossentropy: 0.5516 - precision: 0.7326 - recall: 0.7417 - auc: 0.8110\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 174ms/step - loss: 0.5305 - accuracy: 0.7618 - binary_crossentropy: 0.5305 - precision: 0.7599 - recall: 0.7693 - auc: 0.8356\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 8s 176ms/step - loss: 0.5101 - accuracy: 0.7778 - binary_crossentropy: 0.5101 - precision: 0.7813 - recall: 0.7749 - auc: 0.8566\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.4835 - accuracy: 0.8132 - binary_crossentropy: 0.4835 - precision: 0.8112 - recall: 0.8191 - auc: 0.8828\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 8s 184ms/step - loss: 0.4735 - accuracy: 0.8083 - binary_crossentropy: 0.4735 - precision: 0.8146 - recall: 0.8011 - auc: 0.8909\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.4548 - accuracy: 0.8243 - binary_crossentropy: 0.4548 - precision: 0.8213 - recall: 0.8315 - auc: 0.9050\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.4388 - accuracy: 0.8361 - binary_crossentropy: 0.4388 - precision: 0.8408 - recall: 0.8315 - auc: 0.9174\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.4177 - accuracy: 0.8611 - binary_crossentropy: 0.4177 - precision: 0.8629 - recall: 0.8605 - auc: 0.9346\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 176ms/step - loss: 0.4108 - accuracy: 0.8590 - binary_crossentropy: 0.4108 - precision: 0.8643 - recall: 0.8536 - auc: 0.9343\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 174ms/step - loss: 0.3966 - accuracy: 0.8667 - binary_crossentropy: 0.3966 - precision: 0.8736 - recall: 0.8591 - auc: 0.9433\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 181ms/step - loss: 0.3858 - accuracy: 0.8764 - binary_crossentropy: 0.3858 - precision: 0.8856 - recall: 0.8660 - auc: 0.9453\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.3781 - accuracy: 0.8757 - binary_crossentropy: 0.3781 - precision: 0.8811 - recall: 0.8702 - auc: 0.9486\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 178ms/step - loss: 0.3655 - accuracy: 0.8875 - binary_crossentropy: 0.3655 - precision: 0.8958 - recall: 0.8785 - auc: 0.9541\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.3566 - accuracy: 0.8889 - binary_crossentropy: 0.3566 - precision: 0.8928 - recall: 0.8854 - auc: 0.9591\n",
      "Loss of Train ......................................\n",
      "[0.7511759400367737, 0.6992037892341614, 0.6666545867919922, 0.6330434083938599, 0.597928524017334, 0.563899576663971, 0.5515874028205872, 0.530481219291687, 0.5101019144058228, 0.4835154712200165, 0.4734639823436737, 0.454830139875412, 0.43883344531059265, 0.4176930785179138, 0.4108465909957886, 0.39657142758369446, 0.3858218789100647, 0.3781411051750183, 0.3654572367668152, 0.35661715269088745]\n",
      "Accuracy of Train ......................................\n",
      "[0.5006944537162781, 0.5597222447395325, 0.5979166626930237, 0.6333333253860474, 0.6763888597488403, 0.7208333611488342, 0.7340278029441833, 0.761805534362793, 0.7777777910232544, 0.8131944537162781, 0.8083333373069763, 0.824305534362793, 0.8361111283302307, 0.8611111044883728, 0.8590278029441833, 0.8666666746139526, 0.8763889074325562, 0.8756944537162781, 0.887499988079071, 0.8888888955116272]\n",
      "Precision of Train ......................................\n",
      "[0.5029239654541016, 0.5551470518112183, 0.590062141418457, 0.6266149878501892, 0.663705587387085, 0.7146666646003723, 0.7326057553291321, 0.7598908543586731, 0.7813370227813721, 0.8112174868583679, 0.8146067261695862, 0.8212823867797852, 0.840782105922699, 0.8628808856010437, 0.8643356561660767, 0.8735954761505127, 0.8855932354927063, 0.881118893623352, 0.8957746624946594, 0.8927576541900635]\n",
      "Recall of Train ......................................\n",
      "[0.5939226746559143, 0.6256905794143677, 0.6560773253440857, 0.669889509677887, 0.7223756909370422, 0.7403314709663391, 0.7417126893997192, 0.769336998462677, 0.7748618721961975, 0.8190608024597168, 0.8011049628257751, 0.8314917087554932, 0.8314917087554932, 0.860497236251831, 0.8535911440849304, 0.8591160178184509, 0.8660221099853516, 0.8701657652854919, 0.8784530162811279, 0.8853591084480286]\n",
      "AUC of Train ......................................\n",
      "[0.5027238726615906, 0.5850827097892761, 0.6373990774154663, 0.6925262212753296, 0.7466357350349426, 0.7954189777374268, 0.8110445737838745, 0.8356305360794067, 0.8565582036972046, 0.8828349113464355, 0.8908705115318298, 0.9049816131591797, 0.9173730611801147, 0.9346449375152588, 0.9342968463897705, 0.9432987570762634, 0.9452606439590454, 0.9486287832260132, 0.9541112184524536, 0.9591461420059204]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7679861158132553\n",
      " Loss:0.5032933935523033\n",
      " Precision:0.7685449600219727\n",
      " Recall:0.782527619600296\n",
      " AUC:0.8339233666658401\n",
      "Score for fold 4: loss of 0.5949012041091919; accuracy of 0.6777777671813965%\n",
      "[[132  52]\n",
      " [ 64 112]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 670.455199 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:132,FN:64,TP:112,FP:52\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6777777777777778\n",
      " Loss:0.5949012041091919\n",
      " Precision:0.6829268292682927\n",
      " Recall:0.6363636363636364\n",
      " AUC:0.6549165120593692\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 12s 160ms/step - loss: 0.7042 - accuracy: 0.5444 - binary_crossentropy: 0.7042 - precision: 0.5683 - recall: 0.4219 - auc: 0.5704\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.6636 - accuracy: 0.5854 - binary_crossentropy: 0.6636 - precision: 0.6121 - recall: 0.4973 - auc: 0.6445\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 167ms/step - loss: 0.6369 - accuracy: 0.6319 - binary_crossentropy: 0.6369 - precision: 0.6558 - recall: 0.5767 - auc: 0.6913\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.6153 - accuracy: 0.6660 - binary_crossentropy: 0.6153 - precision: 0.6878 - recall: 0.6247 - auc: 0.7301\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.5884 - accuracy: 0.7056 - binary_crossentropy: 0.5884 - precision: 0.7179 - recall: 0.6904 - auc: 0.7712\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.5673 - accuracy: 0.7188 - binary_crossentropy: 0.5673 - precision: 0.7298 - recall: 0.7068 - auc: 0.7970\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 8s 177ms/step - loss: 0.5445 - accuracy: 0.7569 - binary_crossentropy: 0.5445 - precision: 0.7610 - recall: 0.7589 - auc: 0.8291\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 176ms/step - loss: 0.5250 - accuracy: 0.7688 - binary_crossentropy: 0.5250 - precision: 0.7693 - recall: 0.7767 - auc: 0.8496\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.5092 - accuracy: 0.7785 - binary_crossentropy: 0.5092 - precision: 0.7811 - recall: 0.7822 - auc: 0.8634\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.4967 - accuracy: 0.7826 - binary_crossentropy: 0.4967 - precision: 0.7860 - recall: 0.7849 - auc: 0.8760\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.4809 - accuracy: 0.8021 - binary_crossentropy: 0.4809 - precision: 0.7987 - recall: 0.8151 - auc: 0.8863\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 176ms/step - loss: 0.4679 - accuracy: 0.8229 - binary_crossentropy: 0.4679 - precision: 0.8231 - recall: 0.8288 - auc: 0.8980\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 173ms/step - loss: 0.4637 - accuracy: 0.8076 - binary_crossentropy: 0.4637 - precision: 0.8107 - recall: 0.8096 - auc: 0.8991\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 173ms/step - loss: 0.4456 - accuracy: 0.8340 - binary_crossentropy: 0.4456 - precision: 0.8304 - recall: 0.8452 - auc: 0.9137\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.4370 - accuracy: 0.8438 - binary_crossentropy: 0.4370 - precision: 0.8502 - recall: 0.8397 - auc: 0.9174\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 180ms/step - loss: 0.4248 - accuracy: 0.8535 - binary_crossentropy: 0.4248 - precision: 0.8512 - recall: 0.8616 - auc: 0.9252\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 178ms/step - loss: 0.4161 - accuracy: 0.8514 - binary_crossentropy: 0.4161 - precision: 0.8505 - recall: 0.8575 - auc: 0.9317\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.4048 - accuracy: 0.8569 - binary_crossentropy: 0.4048 - precision: 0.8599 - recall: 0.8575 - auc: 0.9353\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.3977 - accuracy: 0.8618 - binary_crossentropy: 0.3977 - precision: 0.8593 - recall: 0.8699 - auc: 0.9374\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.3856 - accuracy: 0.8625 - binary_crossentropy: 0.3856 - precision: 0.8644 - recall: 0.8644 - auc: 0.9428\n",
      "Loss of Train ......................................\n",
      "[0.7042436003684998, 0.6635945439338684, 0.6369276642799377, 0.6152991652488708, 0.5883718729019165, 0.5672944188117981, 0.5444745421409607, 0.5249581336975098, 0.5092488527297974, 0.49669116735458374, 0.4808991253376007, 0.4678753614425659, 0.46370023488998413, 0.44564440846443176, 0.437031626701355, 0.42479950189590454, 0.41613906621932983, 0.4048258066177368, 0.39767196774482727, 0.3855721652507782]\n",
      "Accuracy of Train ......................................\n",
      "[0.5444444417953491, 0.5854166746139526, 0.6319444179534912, 0.6659722328186035, 0.7055555582046509, 0.71875, 0.7569444179534912, 0.768750011920929, 0.7784722447395325, 0.7826389074325562, 0.8020833134651184, 0.8229166865348816, 0.8076388835906982, 0.8340277671813965, 0.84375, 0.8534722328186035, 0.8513888716697693, 0.8569444417953491, 0.8618055582046509, 0.862500011920929]\n",
      "Precision of Train ......................................\n",
      "[0.5682656764984131, 0.6121416687965393, 0.6557632684707642, 0.6877828240394592, 0.7179487347602844, 0.7298443913459778, 0.7609890103340149, 0.769335150718689, 0.7811217308044434, 0.7860082387924194, 0.7986577153205872, 0.8231292366981506, 0.8106995820999146, 0.8304172158241272, 0.850208044052124, 0.8511502146720886, 0.8505434989929199, 0.8598901033401489, 0.8592692613601685, 0.8643835783004761]\n",
      "Recall of Train ......................................\n",
      "[0.42191779613494873, 0.49726027250289917, 0.5767123103141785, 0.6246575117111206, 0.6904109716415405, 0.7068493366241455, 0.7589040994644165, 0.7767123579978943, 0.7821917533874512, 0.784931480884552, 0.8150684833526611, 0.8287671208381653, 0.8095890283584595, 0.8452054858207703, 0.8397260308265686, 0.8616438508033752, 0.8575342297554016, 0.8575342297554016, 0.8698630332946777, 0.8643835783004761]\n",
      "AUC of Train ......................................\n",
      "[0.5703617334365845, 0.6444839239120483, 0.6912550330162048, 0.7300761938095093, 0.7712454199790955, 0.7969959378242493, 0.8291009068489075, 0.8495678305625916, 0.8633648753166199, 0.8759570121765137, 0.8862676024436951, 0.8980426788330078, 0.8990883827209473, 0.913706362247467, 0.9173711538314819, 0.9251582622528076, 0.9317451119422913, 0.9353097677230835, 0.9374426007270813, 0.9427889585494995]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.7667708337306977\n",
      " Loss:0.5087631613016128\n",
      " Precision:0.7733774572610855\n",
      " Recall:0.7534931480884552\n",
      " AUC:0.8404664874076844\n",
      "Score for fold 5: loss of 0.6293343901634216; accuracy of 0.6305555701255798%\n",
      "[[129  61]\n",
      " [ 72  98]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 835.3903991999999 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:129,FN:72,TP:98,FP:61\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6305555555555555\n",
      " Loss:0.6293343901634216\n",
      " Precision:0.6163522012578616\n",
      " Recall:0.5764705882352941\n",
      " AUC:0.6091308165057068\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.7368055492639541 - Loss: 0.5392500698566437\n",
      "> Fold 1 - Precision: 0.7293967798352241\n",
      "> Fold 1 - Recall: 0.7701117306947708\n",
      "> Fold 1 - AUC: 0.8007247924804688\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.7694444444444445 - Loss: 0.5362801551818848\n",
      "> Fold 1 - Precision: 0.904\n",
      "> Fold 1 - Recall: 0.6141304347826086\n",
      "> Fold 1 - AUC: 0.6560013876040702\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.7519791677594185 - Loss: 0.5242429941892623\n",
      "> Fold 2 - Precision: 0.7373544588685036\n",
      "> Fold 2 - Recall: 0.8036619693040847\n",
      "> Fold 2 - AUC: 0.819359490275383\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.6277777777777778 - Loss: 0.6535331010818481\n",
      "> Fold 2 - Precision: 0.5875\n",
      "> Fold 2 - Recall: 0.9894736842105263\n",
      "> Fold 2 - AUC: 0.9697368421052631\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.7512152776122093 - Loss: 0.5245246604084969\n",
      "> Fold 3 - Precision: 0.7467370375990867\n",
      "> Fold 3 - Recall: 0.797361108660698\n",
      "> Fold 3 - AUC: 0.8195697218179703\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.6861111111111111 - Loss: 0.5886635780334473\n",
      "> Fold 3 - Precision: 0.7815126050420168\n",
      "> Fold 3 - Recall: 0.5166666666666667\n",
      "> Fold 3 - AUC: 0.57783540802213\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.7679861158132553 - Loss: 0.5032933935523033\n",
      "> Fold 4 - Precision: 0.7685449600219727\n",
      "> Fold 4 - Recall: 0.782527619600296\n",
      "> Fold 4 - AUC: 0.8339233666658401\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.6777777777777778 - Loss: 0.5949012041091919\n",
      "> Fold 4 - Precision: 0.6829268292682927\n",
      "> Fold 4 - Recall: 0.6363636363636364\n",
      "> Fold 4 - AUC: 0.6549165120593692\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.7667708337306977 - Loss: 0.5087631613016128\n",
      "> Fold 5 - Precision: 0.7733774572610855\n",
      "> Fold 5 - Recall: 0.7534931480884552\n",
      "> Fold 5 - AUC: 0.8404664874076844\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.6305555555555555 - Loss: 0.6293343901634216\n",
      "> Fold 5 - Precision: 0.6163522012578616\n",
      "> Fold 5 - Recall: 0.5764705882352941\n",
      "> Fold 5 - AUC: 0.6091308165057068\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.754951388835907 (+- 0.011503629896423267)\n",
      "> Loss: 0.5200148558616637 (+- 0.012762577172629828)\n",
      "> Precision: 0.7510821387171744 (+- 0.01720241404274862)\n",
      "> Recall: 0.7814311152696609 (+- 0.01820898876740732)\n",
      "> AUC: 0.8228087717294693 (+- 0.013750783758908088)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.6783333333333333 (+- 0.05138213168787498)\n",
      "> Loss: 0.6005424857139587 (+- 0.0398486102897818)\n",
      "> Precision: 0.7144583271136342 (+- 0.11589632095916667)\n",
      "> Recall: 0.6666210020517465 (+- 0.16644399780094)\n",
      "> AUC: 0.6935241932593079 (+- 0.1412077040702135)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 617 FN SUM: 296 TP SUM: 604 FP SUM: 283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/Histology/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9caa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
