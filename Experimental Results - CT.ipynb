{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf72ef0",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efa7a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 103ms/step - loss: 0.6963 - accuracy: 0.5264 - binary_crossentropy: 0.6963 - precision: 0.5299 - recall: 0.5591 - auc: 0.5418\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 105ms/step - loss: 0.6121 - accuracy: 0.6979 - binary_crossentropy: 0.6121 - precision: 0.6930 - recall: 0.7225 - auc: 0.7681\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 106ms/step - loss: 0.5447 - accuracy: 0.7986 - binary_crossentropy: 0.5447 - precision: 0.7936 - recall: 0.8132 - auc: 0.8847\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 107ms/step - loss: 0.4948 - accuracy: 0.8674 - binary_crossentropy: 0.4948 - precision: 0.8755 - recall: 0.8599 - auc: 0.9449\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 107ms/step - loss: 0.4503 - accuracy: 0.8944 - binary_crossentropy: 0.4503 - precision: 0.9034 - recall: 0.8860 - auc: 0.9634\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.4143 - accuracy: 0.9208 - binary_crossentropy: 0.4143 - precision: 0.9348 - recall: 0.9066 - auc: 0.9780\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.3857 - accuracy: 0.9326 - binary_crossentropy: 0.3857 - precision: 0.9388 - recall: 0.9272 - auc: 0.9838\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.3611 - accuracy: 0.9375 - binary_crossentropy: 0.3611 - precision: 0.9443 - recall: 0.9313 - auc: 0.9863\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 108ms/step - loss: 0.3390 - accuracy: 0.9410 - binary_crossentropy: 0.3390 - precision: 0.9410 - recall: 0.9423 - auc: 0.9890\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3195 - accuracy: 0.9479 - binary_crossentropy: 0.3195 - precision: 0.9442 - recall: 0.9533 - auc: 0.9912\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.3023 - accuracy: 0.9500 - binary_crossentropy: 0.3023 - precision: 0.9493 - recall: 0.9519 - auc: 0.9921\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.2877 - accuracy: 0.9604 - binary_crossentropy: 0.2877 - precision: 0.9552 - recall: 0.9670 - auc: 0.9932\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.2744 - accuracy: 0.9590 - binary_crossentropy: 0.2744 - precision: 0.9588 - recall: 0.9602 - auc: 0.9939\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.2629 - accuracy: 0.9618 - binary_crossentropy: 0.2629 - precision: 0.9529 - recall: 0.9725 - auc: 0.9937\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.2520 - accuracy: 0.9604 - binary_crossentropy: 0.2520 - precision: 0.9590 - recall: 0.9629 - auc: 0.9951\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 111ms/step - loss: 0.2423 - accuracy: 0.9667 - binary_crossentropy: 0.2423 - precision: 0.9632 - recall: 0.9712 - auc: 0.9952\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.2332 - accuracy: 0.9667 - binary_crossentropy: 0.2332 - precision: 0.9595 - recall: 0.9753 - auc: 0.9958\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.2259 - accuracy: 0.9722 - binary_crossentropy: 0.2259 - precision: 0.9674 - recall: 0.9780 - auc: 0.9959\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.2175 - accuracy: 0.9688 - binary_crossentropy: 0.2175 - precision: 0.9646 - recall: 0.9739 - auc: 0.9965\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2101 - accuracy: 0.9729 - binary_crossentropy: 0.2101 - precision: 0.9649 - recall: 0.9821 - auc: 0.9969\n",
      "Loss of Train ......................................\n",
      "[0.6963402032852173, 0.6121363639831543, 0.5446904301643372, 0.4947880208492279, 0.45030882954597473, 0.4143143892288208, 0.38566622138023376, 0.3610832095146179, 0.33895379304885864, 0.31949251890182495, 0.30227020382881165, 0.2876940965652466, 0.2743523418903351, 0.2628699541091919, 0.2519688308238983, 0.24230875074863434, 0.23318640887737274, 0.22586959600448608, 0.21750730276107788, 0.21005375683307648]\n",
      "Accuracy of Train ......................................\n",
      "[0.5263888835906982, 0.6979166865348816, 0.7986111044883728, 0.8673611283302307, 0.894444465637207, 0.9208333492279053, 0.9326388835906982, 0.9375, 0.9409722089767456, 0.9479166865348816, 0.949999988079071, 0.9604166746139526, 0.9590277671813965, 0.9618055820465088, 0.9604166746139526, 0.9666666388511658, 0.9666666388511658, 0.9722222089767456, 0.96875, 0.9729166626930237]\n",
      "Precision of Train ......................................\n",
      "[0.5299479365348816, 0.6930171251296997, 0.7935656905174255, 0.8755244612693787, 0.9033613204956055, 0.9348441958427429, 0.9388039112091064, 0.9442896842956543, 0.9410150647163391, 0.9442176818847656, 0.949315071105957, 0.9552238583564758, 0.9588477611541748, 0.9528936743736267, 0.9589603543281555, 0.9632152318954468, 0.9594594836235046, 0.967391312122345, 0.9646258354187012, 0.9649122953414917]\n",
      "Recall of Train ......................................\n",
      "[0.5590659379959106, 0.7225274443626404, 0.8131868243217468, 0.8598901033401489, 0.8859890103340149, 0.906593382358551, 0.9271978139877319, 0.9313187003135681, 0.942307710647583, 0.9532967209815979, 0.9519230723381042, 0.9670329689979553, 0.9601648449897766, 0.9725274443626404, 0.9629120826721191, 0.9711538553237915, 0.9752747416496277, 0.9780219793319702, 0.973901093006134, 0.9821428656578064]\n",
      "AUC of Train ......................................\n",
      "[0.5417750477790833, 0.7681349515914917, 0.884742796421051, 0.9448909759521484, 0.9633798599243164, 0.9779592156410217, 0.9837663173675537, 0.9862781763076782, 0.9890322089195251, 0.991162121295929, 0.9921460747718811, 0.9931897521018982, 0.9938514828681946, 0.9936662316322327, 0.9951363801956177, 0.9952492117881775, 0.9958328604698181, 0.995880126953125, 0.9964926838874817, 0.9968668818473816]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9051736116409301\n",
      " Loss:0.3562927611172199\n",
      " Precision:0.904671597480774\n",
      " Recall:0.909821429848671\n",
      " AUC:0.9489716678857804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 0.22241392731666565; accuracy of 0.9777777791023254%\n",
      "[[181   7]\n",
      " [  1 171]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 111.2147116000001 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:181,FN:1,TP:171,FP:7\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9777777777777777\n",
      " Loss:0.22241392731666565\n",
      " Precision:0.9606741573033708\n",
      " Recall:0.9941860465116279\n",
      " AUC:0.9943457705085612\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 111ms/step - loss: 0.6946 - accuracy: 0.5458 - binary_crossentropy: 0.6946 - precision: 0.5437 - recall: 0.5070 - auc: 0.5619\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 111ms/step - loss: 0.6088 - accuracy: 0.7014 - binary_crossentropy: 0.6088 - precision: 0.7061 - recall: 0.6784 - auc: 0.7757\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 112ms/step - loss: 0.5499 - accuracy: 0.8097 - binary_crossentropy: 0.5499 - precision: 0.8111 - recall: 0.8020 - auc: 0.8797\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.4982 - accuracy: 0.8521 - binary_crossentropy: 0.4982 - precision: 0.8675 - recall: 0.8272 - auc: 0.9300\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.4570 - accuracy: 0.8861 - binary_crossentropy: 0.4570 - precision: 0.8903 - recall: 0.8778 - auc: 0.9568\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.4213 - accuracy: 0.9014 - binary_crossentropy: 0.4213 - precision: 0.9014 - recall: 0.8989 - auc: 0.9690\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.3948 - accuracy: 0.9132 - binary_crossentropy: 0.3948 - precision: 0.9151 - recall: 0.9087 - auc: 0.9766\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.3680 - accuracy: 0.9250 - binary_crossentropy: 0.3680 - precision: 0.9218 - recall: 0.9270 - auc: 0.9804\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.3472 - accuracy: 0.9431 - binary_crossentropy: 0.3472 - precision: 0.9363 - recall: 0.9494 - auc: 0.9850\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.3286 - accuracy: 0.9424 - binary_crossentropy: 0.3286 - precision: 0.9338 - recall: 0.9508 - auc: 0.9867\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.3112 - accuracy: 0.9507 - binary_crossentropy: 0.3112 - precision: 0.9433 - recall: 0.9579 - auc: 0.9889\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2972 - accuracy: 0.9535 - binary_crossentropy: 0.2972 - precision: 0.9448 - recall: 0.9621 - auc: 0.9909\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2835 - accuracy: 0.9590 - binary_crossentropy: 0.2835 - precision: 0.9491 - recall: 0.9691 - auc: 0.9916\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2722 - accuracy: 0.9576 - binary_crossentropy: 0.2722 - precision: 0.9477 - recall: 0.9677 - auc: 0.9916\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2608 - accuracy: 0.9625 - binary_crossentropy: 0.2608 - precision: 0.9507 - recall: 0.9747 - auc: 0.9927\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2514 - accuracy: 0.9639 - binary_crossentropy: 0.2514 - precision: 0.9521 - recall: 0.9761 - auc: 0.9933\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2422 - accuracy: 0.9688 - binary_crossentropy: 0.2422 - precision: 0.9575 - recall: 0.9803 - auc: 0.9936\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2335 - accuracy: 0.9708 - binary_crossentropy: 0.2335 - precision: 0.9614 - recall: 0.9803 - auc: 0.9945\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2255 - accuracy: 0.9743 - binary_crossentropy: 0.2255 - precision: 0.9630 - recall: 0.9860 - auc: 0.9947\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2180 - accuracy: 0.9743 - binary_crossentropy: 0.2180 - precision: 0.9630 - recall: 0.9860 - auc: 0.9951\n",
      "Loss of Train ......................................\n",
      "[0.6946024298667908, 0.6087841987609863, 0.5498612523078918, 0.49819856882095337, 0.4569724500179291, 0.42132657766342163, 0.39477455615997314, 0.368019700050354, 0.34716278314590454, 0.32862573862075806, 0.3112403452396393, 0.29719507694244385, 0.2835173010826111, 0.2721524238586426, 0.26079389452934265, 0.2513994574546814, 0.24218600988388062, 0.23350217938423157, 0.2254645824432373, 0.21795453131198883]\n",
      "Accuracy of Train ......................................\n",
      "[0.5458333492279053, 0.7013888955116272, 0.8097222447395325, 0.8520833253860474, 0.8861111402511597, 0.9013888835906982, 0.9131944179534912, 0.925000011920929, 0.9430555701255798, 0.9423611164093018, 0.9506944417953491, 0.9534721970558167, 0.9590277671813965, 0.9576388597488403, 0.9624999761581421, 0.9638888835906982, 0.96875, 0.9708333611488342, 0.9743055701255798, 0.9743055701255798]\n",
      "Precision of Train ......................................\n",
      "[0.5436747074127197, 0.7061403393745422, 0.8110795617103577, 0.8674521446228027, 0.8903133869171143, 0.9014084339141846, 0.9151343703269958, 0.9217877388000488, 0.9362881183624268, 0.9337931275367737, 0.9432918429374695, 0.9448275566101074, 0.9491059184074402, 0.9477304220199585, 0.9506849050521851, 0.9520547986030579, 0.957476019859314, 0.9614325165748596, 0.9629629850387573, 0.9629629850387573]\n",
      "Recall of Train ......................................\n",
      "[0.507022500038147, 0.6783707737922668, 0.8019663095474243, 0.8272472023963928, 0.8778089880943298, 0.898876428604126, 0.908707857131958, 0.9269663095474243, 0.949438214302063, 0.9508426785469055, 0.9578651785850525, 0.9620786309242249, 0.9691011309623718, 0.9676966071128845, 0.9747191071510315, 0.976123571395874, 0.9803370833396912, 0.9803370833396912, 0.9859550595283508, 0.9859550595283508]\n",
      "AUC of Train ......................................\n",
      "[0.5618681907653809, 0.7756918668746948, 0.8797333240509033, 0.9299778342247009, 0.9567962884902954, 0.9690104126930237, 0.9765741229057312, 0.9803785681724548, 0.9849701523780823, 0.9867354035377502, 0.9889454245567322, 0.9908930659294128, 0.9916289448738098, 0.9915788769721985, 0.9926726818084717, 0.9932939410209656, 0.9936131834983826, 0.9944813251495361, 0.9946666359901428, 0.9951363205909729]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9027777791023255\n",
      " Loss:0.3631867028772831\n",
      " Precision:0.8979800939559937\n",
      " Recall:0.903370788693428\n",
      " AUC:0.9464323282241821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 0.22041645646095276; accuracy of 0.9583333134651184%\n",
      "[[159  13]\n",
      " [  2 186]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 222.93717030000016 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:159,FN:2,TP:186,FP:13\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9583333333333334\n",
      " Loss:0.22041645646095276\n",
      " Precision:0.9346733668341709\n",
      " Recall:0.9893617021276596\n",
      " AUC:0.9884696709396061\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 111ms/step - loss: 0.6840 - accuracy: 0.5708 - binary_crossentropy: 0.6840 - precision: 0.5756 - recall: 0.5661 - auc: 0.5862\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 111ms/step - loss: 0.6030 - accuracy: 0.7333 - binary_crossentropy: 0.6030 - precision: 0.7298 - recall: 0.7479 - auc: 0.8067\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.5363 - accuracy: 0.8313 - binary_crossentropy: 0.5363 - precision: 0.8268 - recall: 0.8416 - auc: 0.9170\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.4896 - accuracy: 0.8785 - binary_crossentropy: 0.4896 - precision: 0.8718 - recall: 0.8898 - auc: 0.9497\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.4459 - accuracy: 0.9076 - binary_crossentropy: 0.4459 - precision: 0.9045 - recall: 0.9132 - auc: 0.9695\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.4100 - accuracy: 0.9264 - binary_crossentropy: 0.4100 - precision: 0.9167 - recall: 0.9394 - auc: 0.9804\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.3835 - accuracy: 0.9312 - binary_crossentropy: 0.3835 - precision: 0.9336 - recall: 0.9298 - auc: 0.9841\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.3590 - accuracy: 0.9431 - binary_crossentropy: 0.3590 - precision: 0.9411 - recall: 0.9463 - auc: 0.9871\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.3373 - accuracy: 0.9528 - binary_crossentropy: 0.3373 - precision: 0.9446 - recall: 0.9628 - auc: 0.9902\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.3190 - accuracy: 0.9549 - binary_crossentropy: 0.3190 - precision: 0.9509 - recall: 0.9601 - auc: 0.9917\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.3029 - accuracy: 0.9604 - binary_crossentropy: 0.3029 - precision: 0.9576 - recall: 0.9642 - auc: 0.9922\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2879 - accuracy: 0.9549 - binary_crossentropy: 0.2879 - precision: 0.9497 - recall: 0.9614 - auc: 0.9931\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2760 - accuracy: 0.9625 - binary_crossentropy: 0.2760 - precision: 0.9578 - recall: 0.9683 - auc: 0.9942\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2630 - accuracy: 0.9625 - binary_crossentropy: 0.2630 - precision: 0.9578 - recall: 0.9683 - auc: 0.9947\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2531 - accuracy: 0.9646 - binary_crossentropy: 0.2531 - precision: 0.9604 - recall: 0.9697 - auc: 0.9950\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2426 - accuracy: 0.9681 - binary_crossentropy: 0.2426 - precision: 0.9645 - recall: 0.9725 - auc: 0.9951\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2339 - accuracy: 0.9688 - binary_crossentropy: 0.2339 - precision: 0.9608 - recall: 0.9780 - auc: 0.9961\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2259 - accuracy: 0.9701 - binary_crossentropy: 0.2259 - precision: 0.9634 - recall: 0.9780 - auc: 0.9964\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2185 - accuracy: 0.9694 - binary_crossentropy: 0.2185 - precision: 0.9658 - recall: 0.9738 - auc: 0.9968\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2115 - accuracy: 0.9743 - binary_crossentropy: 0.2115 - precision: 0.9662 - recall: 0.9835 - auc: 0.9970\n",
      "Loss of Train ......................................\n",
      "[0.6840472221374512, 0.6029983162879944, 0.5362894535064697, 0.4896126091480255, 0.44591009616851807, 0.4099721610546112, 0.38352033495903015, 0.35902848839759827, 0.33733150362968445, 0.3189851939678192, 0.302880197763443, 0.28788408637046814, 0.2759828269481659, 0.2629750370979309, 0.25311264395713806, 0.24256861209869385, 0.2339267134666443, 0.22591647505760193, 0.21851395070552826, 0.2115354686975479]\n",
      "Accuracy of Train ......................................\n",
      "[0.5708333253860474, 0.7333333492279053, 0.831250011920929, 0.8784722089767456, 0.9076389074325562, 0.9263888597488403, 0.9312499761581421, 0.9430555701255798, 0.9527778029441833, 0.9548611044883728, 0.9604166746139526, 0.9548611044883728, 0.9624999761581421, 0.9624999761581421, 0.9645833373069763, 0.9680555462837219, 0.96875, 0.9701389074325562, 0.9694444537162781, 0.9743055701255798]\n",
      "Precision of Train ......................................\n",
      "[0.575630247592926, 0.7298387289047241, 0.8267929553985596, 0.8717948794364929, 0.9045020341873169, 0.9166666865348816, 0.9336099624633789, 0.9410958886146545, 0.9445946216583252, 0.9508867859840393, 0.9575923681259155, 0.9496598839759827, 0.9577656388282776, 0.9577656388282776, 0.9604365825653076, 0.9644808769226074, 0.9607577919960022, 0.9633650183677673, 0.9658470153808594, 0.9661704897880554]\n",
      "Recall of Train ......................................\n",
      "[0.56611567735672, 0.7479338645935059, 0.8415977954864502, 0.8898071646690369, 0.913223147392273, 0.939393937587738, 0.9297520518302917, 0.9462810158729553, 0.9628099203109741, 0.9600551128387451, 0.9641873240470886, 0.9614325165748596, 0.9683195352554321, 0.9683195352554321, 0.9696969985961914, 0.9724518060684204, 0.9779614210128784, 0.9779614210128784, 0.9738292098045349, 0.9834710955619812]\n",
      "AUC of Train ......................................\n",
      "[0.5862453579902649, 0.8067400455474854, 0.9170447587966919, 0.9496878981590271, 0.9694751501083374, 0.9803555011749268, 0.9841327667236328, 0.9870853424072266, 0.9901622533798218, 0.9917200803756714, 0.9921599626541138, 0.9930859208106995, 0.9941942691802979, 0.9947257041931152, 0.995004415512085, 0.9951173067092896, 0.9960915446281433, 0.9964484572410583, 0.9968159794807434, 0.9969625473022461]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9142708331346512\n",
      " Loss:0.35414956957101823\n",
      " Precision:0.9099627047777176\n",
      " Recall:0.9207300275564194\n",
      " AUC:0.9556627631187439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 0.2123553603887558; accuracy of 0.9722222089767456%\n",
      "[[178   8]\n",
      " [  2 172]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 335.6893140000002 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:178,FN:2,TP:172,FP:8\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9722222222222222\n",
      " Loss:0.2123553603887558\n",
      " Precision:0.9555555555555556\n",
      " Recall:0.9885057471264368\n",
      " AUC:0.9886973180076628\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 115ms/step - loss: 0.6687 - accuracy: 0.5896 - binary_crossentropy: 0.6687 - precision: 0.5837 - recall: 0.6089 - auc: 0.6264\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.5893 - accuracy: 0.7326 - binary_crossentropy: 0.5893 - precision: 0.7430 - recall: 0.7067 - auc: 0.8201\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.5267 - accuracy: 0.8521 - binary_crossentropy: 0.5267 - precision: 0.8578 - recall: 0.8422 - auc: 0.9277\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.4763 - accuracy: 0.9007 - binary_crossentropy: 0.4763 - precision: 0.8919 - recall: 0.9106 - auc: 0.9640\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.4392 - accuracy: 0.9146 - binary_crossentropy: 0.4392 - precision: 0.9218 - recall: 0.9050 - auc: 0.9779\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.4035 - accuracy: 0.9486 - binary_crossentropy: 0.4035 - precision: 0.9521 - recall: 0.9441 - auc: 0.9876\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.3753 - accuracy: 0.9528 - binary_crossentropy: 0.3753 - precision: 0.9525 - recall: 0.9525 - auc: 0.9897\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.3511 - accuracy: 0.9528 - binary_crossentropy: 0.3511 - precision: 0.9451 - recall: 0.9609 - auc: 0.9917\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.3311 - accuracy: 0.9604 - binary_crossentropy: 0.3311 - precision: 0.9545 - recall: 0.9665 - auc: 0.9935\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.3116 - accuracy: 0.9625 - binary_crossentropy: 0.3116 - precision: 0.9584 - recall: 0.9665 - auc: 0.9941\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2954 - accuracy: 0.9681 - binary_crossentropy: 0.2954 - precision: 0.9614 - recall: 0.9749 - auc: 0.9955\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2814 - accuracy: 0.9694 - binary_crossentropy: 0.2814 - precision: 0.9615 - recall: 0.9777 - auc: 0.9956\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2681 - accuracy: 0.9708 - binary_crossentropy: 0.2681 - precision: 0.9604 - recall: 0.9818 - auc: 0.9967\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2580 - accuracy: 0.9722 - binary_crossentropy: 0.2580 - precision: 0.9630 - recall: 0.9818 - auc: 0.9965\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2461 - accuracy: 0.9757 - binary_crossentropy: 0.2461 - precision: 0.9645 - recall: 0.9874 - auc: 0.9970\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2379 - accuracy: 0.9750 - binary_crossentropy: 0.2379 - precision: 0.9670 - recall: 0.9832 - auc: 0.9974\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2281 - accuracy: 0.9764 - binary_crossentropy: 0.2281 - precision: 0.9697 - recall: 0.9832 - auc: 0.9979\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2208 - accuracy: 0.9785 - binary_crossentropy: 0.2208 - precision: 0.9698 - recall: 0.9874 - auc: 0.9978\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2136 - accuracy: 0.9840 - binary_crossentropy: 0.2136 - precision: 0.9740 - recall: 0.9944 - auc: 0.9980\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2063 - accuracy: 0.9799 - binary_crossentropy: 0.2063 - precision: 0.9712 - recall: 0.9888 - auc: 0.9982\n",
      "Loss of Train ......................................\n",
      "[0.668689489364624, 0.589262068271637, 0.5267047882080078, 0.4762701690196991, 0.43917837738990784, 0.4034701883792877, 0.3753490746021271, 0.35106968879699707, 0.33109182119369507, 0.3116059899330139, 0.29539257287979126, 0.28135770559310913, 0.26814156770706177, 0.2580033242702484, 0.2460794299840927, 0.23788301646709442, 0.2281239628791809, 0.2208346724510193, 0.21358227729797363, 0.20626847445964813]\n",
      "Accuracy of Train ......................................\n",
      "[0.5895833373069763, 0.7326388955116272, 0.8520833253860474, 0.9006944298744202, 0.9145833253860474, 0.9486111402511597, 0.9527778029441833, 0.9527778029441833, 0.9604166746139526, 0.9624999761581421, 0.9680555462837219, 0.9694444537162781, 0.9708333611488342, 0.9722222089767456, 0.9756944179534912, 0.9750000238418579, 0.9763888716697693, 0.9784722328186035, 0.9840278029441833, 0.9798611402511597]\n",
      "Precision of Train ......................................\n",
      "[0.5836679935455322, 0.7430249452590942, 0.8577525019645691, 0.8919288516044617, 0.9217638969421387, 0.9521126747131348, 0.9525139927864075, 0.9450549483299255, 0.9544827342033386, 0.9584487676620483, 0.9614325165748596, 0.9615384340286255, 0.9603825211524963, 0.9630137085914612, 0.9645293354988098, 0.9670329689979553, 0.9696969985961914, 0.9698216915130615, 0.9740082025527954, 0.9711934328079224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of Train ......................................\n",
      "[0.6089385747909546, 0.7067039012908936, 0.8421787619590759, 0.910614550113678, 0.9050279259681702, 0.9441340565681458, 0.9525139927864075, 0.9608938694000244, 0.9664804339408875, 0.9664804339408875, 0.9748603105545044, 0.9776536226272583, 0.9818435907363892, 0.9818435907363892, 0.9874301552772522, 0.9832402467727661, 0.9832402467727661, 0.9874301552772522, 0.994413435459137, 0.9888268113136292]\n",
      "AUC of Train ......................................\n",
      "[0.6264217495918274, 0.8201199173927307, 0.9277474880218506, 0.9639938473701477, 0.977914035320282, 0.9876066446304321, 0.989702582359314, 0.9917126297950745, 0.9935259819030762, 0.9941105246543884, 0.9954608678817749, 0.9955815076828003, 0.9967408180236816, 0.9964976906776428, 0.9969597458839417, 0.9973851442337036, 0.9978722333908081, 0.9978442788124084, 0.9980467557907104, 0.9981789588928223]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9258333384990692\n",
      " Loss:0.3464179329574108\n",
      " Precision:0.9211700558662415\n",
      " Recall:0.9302374333143234\n",
      " AUC:0.9621711701154709\n",
      "Score for fold 4: loss of 0.20922309160232544; accuracy of 0.9722222089767456%\n",
      "[[169   7]\n",
      " [  3 181]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 448.1233207 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:169,FN:3,TP:181,FP:7\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9722222222222222\n",
      " Loss:0.20922309160232544\n",
      " Precision:0.9627659574468085\n",
      " Recall:0.9836956521739131\n",
      " AUC:0.9831268958543984\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 116ms/step - loss: 0.6634 - accuracy: 0.5958 - binary_crossentropy: 0.6634 - precision: 0.5916 - recall: 0.6114 - auc: 0.6358\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.5851 - accuracy: 0.7431 - binary_crossentropy: 0.5851 - precision: 0.7417 - recall: 0.7437 - auc: 0.8252\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.5214 - accuracy: 0.8375 - binary_crossentropy: 0.5214 - precision: 0.8399 - recall: 0.8329 - auc: 0.9157\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.4732 - accuracy: 0.8861 - binary_crossentropy: 0.4732 - precision: 0.8957 - recall: 0.8733 - auc: 0.9534\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.4320 - accuracy: 0.9139 - binary_crossentropy: 0.4320 - precision: 0.9148 - recall: 0.9123 - auc: 0.9725\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.3994 - accuracy: 0.9292 - binary_crossentropy: 0.3994 - precision: 0.9278 - recall: 0.9304 - auc: 0.9818\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.3716 - accuracy: 0.9410 - binary_crossentropy: 0.3716 - precision: 0.9366 - recall: 0.9457 - auc: 0.9873\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.3456 - accuracy: 0.9500 - binary_crossentropy: 0.3456 - precision: 0.9486 - recall: 0.9513 - auc: 0.9898\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.3254 - accuracy: 0.9514 - binary_crossentropy: 0.3254 - precision: 0.9438 - recall: 0.9596 - auc: 0.9914\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.3068 - accuracy: 0.9590 - binary_crossentropy: 0.3068 - precision: 0.9483 - recall: 0.9708 - auc: 0.9929\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2919 - accuracy: 0.9632 - binary_crossentropy: 0.2919 - precision: 0.9524 - recall: 0.9749 - auc: 0.9939\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2778 - accuracy: 0.9674 - binary_crossentropy: 0.2778 - precision: 0.9590 - recall: 0.9763 - auc: 0.9948\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2649 - accuracy: 0.9681 - binary_crossentropy: 0.2649 - precision: 0.9590 - recall: 0.9777 - auc: 0.9947\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2532 - accuracy: 0.9674 - binary_crossentropy: 0.2532 - precision: 0.9565 - recall: 0.9791 - auc: 0.9955\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2432 - accuracy: 0.9715 - binary_crossentropy: 0.2432 - precision: 0.9631 - recall: 0.9805 - auc: 0.9954\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2343 - accuracy: 0.9715 - binary_crossentropy: 0.2343 - precision: 0.9593 - recall: 0.9847 - auc: 0.9963\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2250 - accuracy: 0.9771 - binary_crossentropy: 0.2250 - precision: 0.9673 - recall: 0.9875 - auc: 0.9967\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2177 - accuracy: 0.9750 - binary_crossentropy: 0.2177 - precision: 0.9596 - recall: 0.9916 - auc: 0.9966\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2102 - accuracy: 0.9757 - binary_crossentropy: 0.2102 - precision: 0.9596 - recall: 0.9930 - auc: 0.9968\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2034 - accuracy: 0.9785 - binary_crossentropy: 0.2034 - precision: 0.9661 - recall: 0.9916 - auc: 0.9970\n",
      "Loss of Train ......................................\n",
      "[0.6634311676025391, 0.5850666761398315, 0.5214011073112488, 0.47321853041648865, 0.43200811743736267, 0.3993673026561737, 0.37157005071640015, 0.3456113040447235, 0.3253591060638428, 0.3068230450153351, 0.2919349670410156, 0.2777765393257141, 0.2649342715740204, 0.2532113790512085, 0.2432248443365097, 0.23425012826919556, 0.2249632030725479, 0.21773995459079742, 0.21017248928546906, 0.2033906728029251]\n",
      "Accuracy of Train ......................................\n",
      "[0.5958333611488342, 0.7430555820465088, 0.8374999761581421, 0.8861111402511597, 0.9138888716697693, 0.9291666746139526, 0.9409722089767456, 0.949999988079071, 0.9513888955116272, 0.9590277671813965, 0.9631944298744202, 0.9673610925674438, 0.9680555462837219, 0.9673610925674438, 0.9715277552604675, 0.9715277552604675, 0.9770833253860474, 0.9750000238418579, 0.9756944179534912, 0.9784722328186035]\n",
      "Precision of Train ......................................\n",
      "[0.5916442275047302, 0.7416666746139526, 0.8398876190185547, 0.895714282989502, 0.9148044586181641, 0.9277777671813965, 0.9365517497062683, 0.9486111402511597, 0.9438356161117554, 0.9482993483543396, 0.9523809552192688, 0.9589603543281555, 0.9590163826942444, 0.956462562084198, 0.9630643129348755, 0.9592944383621216, 0.9672578573226929, 0.9595687389373779, 0.9596231579780579, 0.9660786986351013]\n",
      "Recall of Train ......................................\n",
      "[0.6114206314086914, 0.7437325716018677, 0.8328690528869629, 0.8732590675354004, 0.9122562408447266, 0.9303621053695679, 0.9456824660301208, 0.9512534737586975, 0.9596100449562073, 0.9707520604133606, 0.9749303460121155, 0.976323127746582, 0.9777158498764038, 0.9791086316108704, 0.9805014133453369, 0.984679639339447, 0.9874652028083801, 0.9916434288024902, 0.9930362105369568, 0.9916434288024902]\n",
      "AUC of Train ......................................\n",
      "[0.6358035206794739, 0.8252059817314148, 0.9157342314720154, 0.9533869624137878, 0.9724997282028198, 0.9818025231361389, 0.9873175621032715, 0.9897955060005188, 0.9914466738700867, 0.9928509593009949, 0.9939466714859009, 0.9947588443756104, 0.9947279691696167, 0.9955323338508606, 0.9954186081886292, 0.9963146448135376, 0.9966551065444946, 0.9966455101966858, 0.9968094229698181, 0.9970273375511169]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9211111068725586\n",
      " Loss:0.34227274283766745\n",
      " Precision:0.9145250171422958\n",
      " Recall:0.9284122496843338\n",
      " AUC:0.9601840049028396\n",
      "Score for fold 5: loss of 0.21426211297512054; accuracy of 0.9722222089767456%\n",
      "[[170   8]\n",
      " [  2 180]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 561.6525196000002 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:170,FN:2,TP:180,FP:8\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9722222222222222\n",
      " Loss:0.21426211297512054\n",
      " Precision:0.9574468085106383\n",
      " Recall:0.989010989010989\n",
      " AUC:0.9886915410171224\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9051736116409301 - Loss: 0.3562927611172199\n",
      "> Fold 1 - Precision: 0.904671597480774\n",
      "> Fold 1 - Recall: 0.909821429848671\n",
      "> Fold 1 - AUC: 0.9489716678857804\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9777777777777777 - Loss: 0.22241392731666565\n",
      "> Fold 1 - Precision: 0.9606741573033708\n",
      "> Fold 1 - Recall: 0.9941860465116279\n",
      "> Fold 1 - AUC: 0.9943457705085612\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.9027777791023255 - Loss: 0.3631867028772831\n",
      "> Fold 2 - Precision: 0.8979800939559937\n",
      "> Fold 2 - Recall: 0.903370788693428\n",
      "> Fold 2 - AUC: 0.9464323282241821\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.9583333333333334 - Loss: 0.22041645646095276\n",
      "> Fold 2 - Precision: 0.9346733668341709\n",
      "> Fold 2 - Recall: 0.9893617021276596\n",
      "> Fold 2 - AUC: 0.9884696709396061\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9142708331346512 - Loss: 0.35414956957101823\n",
      "> Fold 3 - Precision: 0.9099627047777176\n",
      "> Fold 3 - Recall: 0.9207300275564194\n",
      "> Fold 3 - AUC: 0.9556627631187439\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9722222222222222 - Loss: 0.2123553603887558\n",
      "> Fold 3 - Precision: 0.9555555555555556\n",
      "> Fold 3 - Recall: 0.9885057471264368\n",
      "> Fold 3 - AUC: 0.9886973180076628\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9258333384990692 - Loss: 0.3464179329574108\n",
      "> Fold 4 - Precision: 0.9211700558662415\n",
      "> Fold 4 - Recall: 0.9302374333143234\n",
      "> Fold 4 - AUC: 0.9621711701154709\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9722222222222222 - Loss: 0.20922309160232544\n",
      "> Fold 4 - Precision: 0.9627659574468085\n",
      "> Fold 4 - Recall: 0.9836956521739131\n",
      "> Fold 4 - AUC: 0.9831268958543984\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9211111068725586 - Loss: 0.34227274283766745\n",
      "> Fold 5 - Precision: 0.9145250171422958\n",
      "> Fold 5 - Recall: 0.9284122496843338\n",
      "> Fold 5 - AUC: 0.9601840049028396\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9722222222222222 - Loss: 0.21426211297512054\n",
      "> Fold 5 - Precision: 0.9574468085106383\n",
      "> Fold 5 - Recall: 0.989010989010989\n",
      "> Fold 5 - AUC: 0.9886915410171224\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.913833333849907 (+- 0.008881143810193838)\n",
      "> Loss: 0.35246394187211993 (+- 0.007387740692273336)\n",
      "> Precision: 0.9096618938446046 (+- 0.007969262889109437)\n",
      "> Recall: 0.9185143858194351 (+- 0.010442247242682912)\n",
      "> AUC: 0.9546843868494035 (+- 0.006131664896952318)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9705555555555556 (+- 0.006478835438716978)\n",
      "> Loss: 0.21573418974876404 (+- 0.004950159845585134)\n",
      "> Precision: 0.9542231691301089 (+- 0.010089166019926338)\n",
      "> Recall: 0.9889520273901253 (+- 0.0033285105532334255)\n",
      "> AUC: 0.9886662392654703 (+- 0.003549130759513309)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 857 FN SUM: 10 TP SUM: 890 FP SUM: 43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  model = VGG16()\n",
    "  model_2 = Sequential()\n",
    "  for layer in model.layers[:-3]:\n",
    "    model_2.add(layer)\n",
    "\n",
    "  # Freeze the layers\n",
    "  for layer in model_2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(Dense(1,activation='sigmoid'))\n",
    "  model_2.summary()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abec875",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b8b2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 120ms/step - loss: 0.7072 - accuracy: 0.5097 - binary_crossentropy: 0.7072 - precision: 0.5136 - recall: 0.5447 - auc: 0.5206\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 121ms/step - loss: 0.6583 - accuracy: 0.6049 - binary_crossentropy: 0.6583 - precision: 0.6059 - recall: 0.6217 - auc: 0.6512\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 122ms/step - loss: 0.6144 - accuracy: 0.6979 - binary_crossentropy: 0.6144 - precision: 0.6931 - recall: 0.7208 - auc: 0.7620\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 122ms/step - loss: 0.5760 - accuracy: 0.7563 - binary_crossentropy: 0.5760 - precision: 0.7429 - recall: 0.7909 - auc: 0.8407\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 123ms/step - loss: 0.5477 - accuracy: 0.7819 - binary_crossentropy: 0.5477 - precision: 0.7721 - recall: 0.8061 - auc: 0.8714\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 123ms/step - loss: 0.5204 - accuracy: 0.8222 - binary_crossentropy: 0.5204 - precision: 0.8153 - recall: 0.8377 - auc: 0.8969\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 124ms/step - loss: 0.4928 - accuracy: 0.8451 - binary_crossentropy: 0.4928 - precision: 0.8290 - recall: 0.8735 - auc: 0.9299\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 124ms/step - loss: 0.4699 - accuracy: 0.8653 - binary_crossentropy: 0.4699 - precision: 0.8539 - recall: 0.8845 - auc: 0.9414\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 124ms/step - loss: 0.4506 - accuracy: 0.8757 - binary_crossentropy: 0.4506 - precision: 0.8713 - recall: 0.8845 - auc: 0.9513\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 125ms/step - loss: 0.4308 - accuracy: 0.8819 - binary_crossentropy: 0.4308 - precision: 0.8769 - recall: 0.8913 - auc: 0.9613\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 125ms/step - loss: 0.4136 - accuracy: 0.8986 - binary_crossentropy: 0.4136 - precision: 0.8996 - recall: 0.8996 - auc: 0.9682\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 0.4026 - accuracy: 0.9062 - binary_crossentropy: 0.4026 - precision: 0.9055 - recall: 0.9092 - auc: 0.9706\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.3865 - accuracy: 0.9139 - binary_crossentropy: 0.3865 - precision: 0.9091 - recall: 0.9216 - auc: 0.9761\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.3715 - accuracy: 0.9201 - binary_crossentropy: 0.3715 - precision: 0.9135 - recall: 0.9298 - auc: 0.9780\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3594 - accuracy: 0.9271 - binary_crossentropy: 0.3594 - precision: 0.9203 - recall: 0.9367 - auc: 0.9808\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3505 - accuracy: 0.9278 - binary_crossentropy: 0.3505 - precision: 0.9297 - recall: 0.9271 - auc: 0.9828\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3395 - accuracy: 0.9292 - binary_crossentropy: 0.3395 - precision: 0.9206 - recall: 0.9409 - auc: 0.9840\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.3308 - accuracy: 0.9333 - binary_crossentropy: 0.3308 - precision: 0.9304 - recall: 0.9381 - auc: 0.9854\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.3212 - accuracy: 0.9347 - binary_crossentropy: 0.3212 - precision: 0.9354 - recall: 0.9354 - auc: 0.9873\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 129ms/step - loss: 0.3130 - accuracy: 0.9333 - binary_crossentropy: 0.3130 - precision: 0.9293 - recall: 0.9395 - auc: 0.9886\n",
      "Loss of Train ......................................\n",
      "[0.707201361656189, 0.6583348512649536, 0.6144044399261475, 0.5759619474411011, 0.5476504564285278, 0.5204097032546997, 0.49276453256607056, 0.46993234753608704, 0.45063528418540955, 0.43084436655044556, 0.41362157464027405, 0.4025987982749939, 0.3864864706993103, 0.3715346157550812, 0.35942888259887695, 0.3504684567451477, 0.3394933342933655, 0.33081120252609253, 0.3212438225746155, 0.31295353174209595]\n",
      "Accuracy of Train ......................................\n",
      "[0.5097222328186035, 0.6048611402511597, 0.6979166865348816, 0.7562500238418579, 0.7819444537162781, 0.8222222328186035, 0.8451389074325562, 0.8652777671813965, 0.8756944537162781, 0.8819444179534912, 0.8986111283302307, 0.90625, 0.9138888716697693, 0.9201388955116272, 0.9270833134651184, 0.9277777671813965, 0.9291666746139526, 0.9333333373069763, 0.9347222447395325, 0.9333333373069763]\n",
      "Precision of Train ......................................\n",
      "[0.5136186480522156, 0.6058981418609619, 0.6931216716766357, 0.7428940534591675, 0.7720685005187988, 0.8152610659599304, 0.8289816975593567, 0.85391765832901, 0.8712736964225769, 0.8768606185913086, 0.8995873332023621, 0.9054794311523438, 0.9090909361839294, 0.9135135412216187, 0.9202702641487122, 0.9296551942825317, 0.920592188835144, 0.9304229021072388, 0.935350775718689, 0.9292517304420471]\n",
      "Recall of Train ......................................\n",
      "[0.544704258441925, 0.6217331290245056, 0.7207702994346619, 0.7909215688705444, 0.8060522675514221, 0.8376891613006592, 0.8734525442123413, 0.8844566941261292, 0.8844566941261292, 0.8913342356681824, 0.8995873332023621, 0.9092159271240234, 0.921595573425293, 0.9298486709594727, 0.9367262721061707, 0.9270976781845093, 0.9408528208732605, 0.9381017684936523, 0.935350775718689, 0.9394773244857788]\n",
      "AUC of Train ......................................\n",
      "[0.520592212677002, 0.6512084007263184, 0.7620009779930115, 0.8406996130943298, 0.8714027404785156, 0.896884560585022, 0.9299268126487732, 0.9413968324661255, 0.9513399600982666, 0.9613128900527954, 0.9681663513183594, 0.9705594778060913, 0.9760943651199341, 0.9779898524284363, 0.9808402061462402, 0.9827848076820374, 0.9839953780174255, 0.9854133725166321, 0.9873454570770264, 0.988593578338623]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8432638943195343\n",
      " Loss:0.45283899903297425\n",
      " Precision:0.8383555024862289\n",
      " Recall:0.8566712498664856\n",
      " AUC:0.9064273923635483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 0.3458716571331024; accuracy of 0.8999999761581421%\n",
      "[[169  18]\n",
      " [ 18 155]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 134.2540082 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:169,FN:18,TP:155,FP:18\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9\n",
      " Loss:0.3458716571331024\n",
      " Precision:0.8959537572254336\n",
      " Recall:0.8959537572254336\n",
      " AUC:0.8998485363667275\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 125ms/step - loss: 0.6736 - accuracy: 0.5924 - binary_crossentropy: 0.6736 - precision: 0.5893 - recall: 0.6466 - auc: 0.6136\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 126ms/step - loss: 0.6311 - accuracy: 0.6764 - binary_crossentropy: 0.6311 - precision: 0.6701 - recall: 0.7123 - auc: 0.7264\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.5947 - accuracy: 0.7243 - binary_crossentropy: 0.5947 - precision: 0.7148 - recall: 0.7589 - auc: 0.7980\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.5611 - accuracy: 0.7861 - binary_crossentropy: 0.5611 - precision: 0.7784 - recall: 0.8082 - auc: 0.8626\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.5314 - accuracy: 0.8222 - binary_crossentropy: 0.5314 - precision: 0.8078 - recall: 0.8521 - auc: 0.9012\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.5095 - accuracy: 0.8424 - binary_crossentropy: 0.5095 - precision: 0.8296 - recall: 0.8671 - auc: 0.9246\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.4809 - accuracy: 0.8681 - binary_crossentropy: 0.4809 - precision: 0.8668 - recall: 0.8740 - auc: 0.9448\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.4621 - accuracy: 0.8875 - binary_crossentropy: 0.4621 - precision: 0.8777 - recall: 0.9041 - auc: 0.9529\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4418 - accuracy: 0.8951 - binary_crossentropy: 0.4418 - precision: 0.8855 - recall: 0.9110 - auc: 0.9616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.4245 - accuracy: 0.8993 - binary_crossentropy: 0.4245 - precision: 0.8947 - recall: 0.9082 - auc: 0.9658\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.4097 - accuracy: 0.9062 - binary_crossentropy: 0.4097 - precision: 0.8993 - recall: 0.9178 - auc: 0.9709\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.3959 - accuracy: 0.9208 - binary_crossentropy: 0.3959 - precision: 0.9151 - recall: 0.9301 - auc: 0.9770\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3804 - accuracy: 0.9181 - binary_crossentropy: 0.3804 - precision: 0.9135 - recall: 0.9260 - auc: 0.9781\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3681 - accuracy: 0.9319 - binary_crossentropy: 0.3681 - precision: 0.9317 - recall: 0.9342 - auc: 0.9815\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 129ms/step - loss: 0.3582 - accuracy: 0.9312 - binary_crossentropy: 0.3582 - precision: 0.9269 - recall: 0.9384 - auc: 0.9833\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.3483 - accuracy: 0.9382 - binary_crossentropy: 0.3483 - precision: 0.9361 - recall: 0.9425 - auc: 0.9849\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.3360 - accuracy: 0.9396 - binary_crossentropy: 0.3360 - precision: 0.9398 - recall: 0.9411 - auc: 0.9859\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3275 - accuracy: 0.9410 - binary_crossentropy: 0.3275 - precision: 0.9412 - recall: 0.9425 - auc: 0.9880\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.3178 - accuracy: 0.9486 - binary_crossentropy: 0.3178 - precision: 0.9481 - recall: 0.9507 - auc: 0.9884\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 129ms/step - loss: 0.3113 - accuracy: 0.9444 - binary_crossentropy: 0.3113 - precision: 0.9440 - recall: 0.9466 - auc: 0.9895\n",
      "Loss of Train ......................................\n",
      "[0.6736199855804443, 0.6311464309692383, 0.5946755409240723, 0.5611377954483032, 0.5314474701881409, 0.5094634294509888, 0.48092833161354065, 0.46213263273239136, 0.4418077766895294, 0.4245210886001587, 0.40974846482276917, 0.39589041471481323, 0.38041383028030396, 0.3681146502494812, 0.3582090139389038, 0.3483443856239319, 0.33604922890663147, 0.3274877667427063, 0.3178204596042633, 0.31125324964523315]\n",
      "Accuracy of Train ......................................\n",
      "[0.5923610925674438, 0.6763888597488403, 0.7243055701255798, 0.7861111164093018, 0.8222222328186035, 0.8423610925674438, 0.8680555820465088, 0.887499988079071, 0.8951388597488403, 0.8993055820465088, 0.90625, 0.9208333492279053, 0.918055534362793, 0.9319444298744202, 0.9312499761581421, 0.9381944537162781, 0.9395833611488342, 0.9409722089767456, 0.9486111402511597, 0.9444444179534912]\n",
      "Precision of Train ......................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5892634391784668, 0.6701030731201172, 0.7148386836051941, 0.7783641219139099, 0.8077921867370605, 0.8296199440956116, 0.866847813129425, 0.8776595592498779, 0.8854860067367554, 0.8947368264198303, 0.899328887462616, 0.9150943160057068, 0.9135135412216187, 0.931693971157074, 0.9269282817840576, 0.9360544085502625, 0.9398084878921509, 0.9411764740943909, 0.9480874538421631, 0.943989098072052]\n",
      "Recall of Train ......................................\n",
      "[0.6465753316879272, 0.7123287916183472, 0.7589040994644165, 0.8082191944122314, 0.8520547747612, 0.8671233057975769, 0.8739725947380066, 0.9041095972061157, 0.9109588861465454, 0.9082191586494446, 0.9178082346916199, 0.9301369786262512, 0.9260274171829224, 0.9342465996742249, 0.9383561611175537, 0.9424657821655273, 0.9410958886146545, 0.9424657821655273, 0.9506849050521851, 0.9465753436088562]\n",
      "AUC of Train ......................................\n",
      "[0.6136070489883423, 0.726388156414032, 0.7980445623397827, 0.8625631928443909, 0.9011962413787842, 0.9246267080307007, 0.9448052048683167, 0.9529404044151306, 0.9616013765335083, 0.9658257365226746, 0.9709164500236511, 0.9770422577857971, 0.9781256318092346, 0.9814557433128357, 0.9832587838172913, 0.9848650097846985, 0.98591548204422, 0.9880166053771973, 0.9884189367294312, 0.9894838333129883]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8656944423913956\n",
      " Loss:0.44321059733629226\n",
      " Precision:0.8605193287134171\n",
      " Recall:0.8806164413690567\n",
      " AUC:0.9239548683166504\n",
      "Score for fold 2: loss of 0.2969905436038971; accuracy of 0.9361110925674438%\n",
      "[[182   8]\n",
      " [ 15 155]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 258.6862173 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:182,FN:15,TP:155,FP:8\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9361111111111111\n",
      " Loss:0.2969905436038971\n",
      " Precision:0.950920245398773\n",
      " Recall:0.9117647058823529\n",
      " AUC:0.9178112869513287\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 131ms/step - loss: 0.6893 - accuracy: 0.5403 - binary_crossentropy: 0.6893 - precision: 0.5401 - recall: 0.4902 - auc: 0.5645\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.6468 - accuracy: 0.6340 - binary_crossentropy: 0.6468 - precision: 0.6369 - recall: 0.6092 - auc: 0.6850\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.6036 - accuracy: 0.7125 - binary_crossentropy: 0.6036 - precision: 0.7143 - recall: 0.7003 - auc: 0.7900\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.5701 - accuracy: 0.7771 - binary_crossentropy: 0.5701 - precision: 0.7869 - recall: 0.7549 - auc: 0.8488\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.5375 - accuracy: 0.8097 - binary_crossentropy: 0.5375 - precision: 0.8343 - recall: 0.7689 - auc: 0.9013\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.5138 - accuracy: 0.8326 - binary_crossentropy: 0.5138 - precision: 0.8393 - recall: 0.8193 - auc: 0.9161\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.4877 - accuracy: 0.8660 - binary_crossentropy: 0.4877 - precision: 0.8554 - recall: 0.8782 - auc: 0.9417\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.4697 - accuracy: 0.8694 - binary_crossentropy: 0.4697 - precision: 0.8725 - recall: 0.8627 - auc: 0.9457\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4480 - accuracy: 0.8868 - binary_crossentropy: 0.4480 - precision: 0.8832 - recall: 0.8894 - auc: 0.9605\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.4292 - accuracy: 0.8958 - binary_crossentropy: 0.4292 - precision: 0.8939 - recall: 0.8964 - auc: 0.9657\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.4170 - accuracy: 0.8931 - binary_crossentropy: 0.4170 - precision: 0.8825 - recall: 0.9048 - auc: 0.9675\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.3999 - accuracy: 0.9146 - binary_crossentropy: 0.3999 - precision: 0.9121 - recall: 0.9160 - auc: 0.9740\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.3839 - accuracy: 0.9201 - binary_crossentropy: 0.3839 - precision: 0.9131 - recall: 0.9272 - auc: 0.9779\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3746 - accuracy: 0.9194 - binary_crossentropy: 0.3746 - precision: 0.9223 - recall: 0.9146 - auc: 0.9797\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.3617 - accuracy: 0.9285 - binary_crossentropy: 0.3617 - precision: 0.9261 - recall: 0.9300 - auc: 0.9832\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.3510 - accuracy: 0.9285 - binary_crossentropy: 0.3510 - precision: 0.9179 - recall: 0.9398 - auc: 0.9839\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3394 - accuracy: 0.9319 - binary_crossentropy: 0.3394 - precision: 0.9314 - recall: 0.9314 - auc: 0.9856\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3313 - accuracy: 0.9368 - binary_crossentropy: 0.3313 - precision: 0.9273 - recall: 0.9468 - auc: 0.9868\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.3219 - accuracy: 0.9410 - binary_crossentropy: 0.3219 - precision: 0.9399 - recall: 0.9412 - auc: 0.9876\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.3143 - accuracy: 0.9444 - binary_crossentropy: 0.3143 - precision: 0.9427 - recall: 0.9454 - auc: 0.9899\n",
      "Loss of Train ......................................\n",
      "[0.6893324255943298, 0.646806001663208, 0.6035980582237244, 0.5701243877410889, 0.5375487804412842, 0.5137972235679626, 0.4876749813556671, 0.4696650505065918, 0.4479585289955139, 0.4291977882385254, 0.4170300364494324, 0.39993566274642944, 0.38388872146606445, 0.3745604157447815, 0.36172592639923096, 0.35100099444389343, 0.33944374322891235, 0.3312772214412689, 0.3219378888607025, 0.3143119812011719]\n",
      "Accuracy of Train ......................................\n",
      "[0.5402777791023254, 0.6340277791023254, 0.7124999761581421, 0.7770833373069763, 0.8097222447395325, 0.8326388597488403, 0.8659722208976746, 0.8694444298744202, 0.886805534362793, 0.8958333134651184, 0.8930555582046509, 0.9145833253860474, 0.9201388955116272, 0.9194444417953491, 0.9284722208976746, 0.9284722208976746, 0.9319444298744202, 0.9368055462837219, 0.9409722089767456, 0.9444444179534912]\n",
      "Precision of Train ......................................\n",
      "[0.540123462677002, 0.6368960738182068, 0.7142857313156128, 0.7868613004684448, 0.8343465328216553, 0.8393113613128662, 0.8553888201713562, 0.8725212216377258, 0.8831710815429688, 0.8938547372817993, 0.8825136423110962, 0.9121338725090027, 0.913103461265564, 0.9223163723945618, 0.9260808825492859, 0.9179206490516663, 0.9313725233078003, 0.9272976517677307, 0.9398601651191711, 0.9427374005317688]\n",
      "Recall of Train ......................................\n",
      "[0.4901960790157318, 0.6092436909675598, 0.7002801299095154, 0.7549019455909729, 0.7689075469970703, 0.819327712059021, 0.8781512379646301, 0.8627451062202454, 0.8893557190895081, 0.8963585495948792, 0.9047619104385376, 0.9159663915634155, 0.9271708726882935, 0.9145658016204834, 0.9299719929695129, 0.9397758841514587, 0.9313725233078003, 0.9467787146568298, 0.9411764740943909, 0.9453781247138977]\n",
      "AUC of Train ......................................\n",
      "[0.5644981265068054, 0.6849550008773804, 0.7899670004844666, 0.8488012552261353, 0.9013482332229614, 0.9160580039024353, 0.9417493939399719, 0.9457312226295471, 0.9604737162590027, 0.965747058391571, 0.9675122499465942, 0.9739999175071716, 0.977936327457428, 0.9797333478927612, 0.9831884503364563, 0.983892560005188, 0.9855748414993286, 0.9867814779281616, 0.9875829815864563, 0.989867091178894]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8541319370269775\n",
      " Loss:0.4495407909154892\n",
      " Precision:0.8536048471927643\n",
      " Recall:0.8483193203806877\n",
      " AUC:0.9167699128389358\n",
      "Score for fold 3: loss of 0.31268277764320374; accuracy of 0.9555555582046509%\n",
      "[[162  12]\n",
      " [  4 182]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 385.46925699999997 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:162,FN:4,TP:182,FP:12\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9555555555555556\n",
      " Loss:0.31268277764320374\n",
      " Precision:0.9381443298969072\n",
      " Recall:0.978494623655914\n",
      " AUC:0.9771991190568727\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 7s 130ms/step - loss: 0.7516 - accuracy: 0.4229 - binary_crossentropy: 0.7516 - precision: 0.4051 - recall: 0.3567 - auc: 0.3913\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.6975 - accuracy: 0.5236 - binary_crossentropy: 0.6975 - precision: 0.5176 - recall: 0.5379 - auc: 0.5360\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.6424 - accuracy: 0.6431 - binary_crossentropy: 0.6424 - precision: 0.6478 - recall: 0.6096 - auc: 0.7075\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.6025 - accuracy: 0.7444 - binary_crossentropy: 0.6025 - precision: 0.7552 - recall: 0.7149 - auc: 0.8292\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.5628 - accuracy: 0.8069 - binary_crossentropy: 0.5628 - precision: 0.8006 - recall: 0.8118 - auc: 0.8969\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 131ms/step - loss: 0.5308 - accuracy: 0.8556 - binary_crossentropy: 0.5308 - precision: 0.8433 - recall: 0.8694 - auc: 0.9361\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.5060 - accuracy: 0.8806 - binary_crossentropy: 0.5060 - precision: 0.8868 - recall: 0.8694 - auc: 0.9537\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.4822 - accuracy: 0.8785 - binary_crossentropy: 0.4822 - precision: 0.8776 - recall: 0.8764 - auc: 0.9573\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.4583 - accuracy: 0.9049 - binary_crossentropy: 0.4583 - precision: 0.9044 - recall: 0.9031 - auc: 0.9703\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.4386 - accuracy: 0.9083 - binary_crossentropy: 0.4386 - precision: 0.9050 - recall: 0.9101 - auc: 0.9746\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.4199 - accuracy: 0.9292 - binary_crossentropy: 0.4199 - precision: 0.9213 - recall: 0.9368 - auc: 0.9800\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.4046 - accuracy: 0.9285 - binary_crossentropy: 0.4046 - precision: 0.9247 - recall: 0.9312 - auc: 0.9842\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.3890 - accuracy: 0.9354 - binary_crossentropy: 0.3890 - precision: 0.9293 - recall: 0.9410 - auc: 0.9846\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3752 - accuracy: 0.9403 - binary_crossentropy: 0.3752 - precision: 0.9421 - recall: 0.9368 - auc: 0.9874\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.3628 - accuracy: 0.9382 - binary_crossentropy: 0.3628 - precision: 0.9285 - recall: 0.9480 - auc: 0.9875\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.3521 - accuracy: 0.9417 - binary_crossentropy: 0.3521 - precision: 0.9349 - recall: 0.9480 - auc: 0.9897\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.3417 - accuracy: 0.9424 - binary_crossentropy: 0.3417 - precision: 0.9350 - recall: 0.9494 - auc: 0.9903\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.3301 - accuracy: 0.9451 - binary_crossentropy: 0.3301 - precision: 0.9427 - recall: 0.9466 - auc: 0.9898\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3217 - accuracy: 0.9493 - binary_crossentropy: 0.3217 - precision: 0.9395 - recall: 0.9593 - auc: 0.9912\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3118 - accuracy: 0.9535 - binary_crossentropy: 0.3118 - precision: 0.9473 - recall: 0.9593 - auc: 0.9929\n",
      "Loss of Train ......................................\n",
      "[0.7516027688980103, 0.6974924802780151, 0.6424274444580078, 0.6025012135505676, 0.562807023525238, 0.530788779258728, 0.5060457587242126, 0.48222532868385315, 0.4582795798778534, 0.4386458098888397, 0.41988399624824524, 0.4045557975769043, 0.38901442289352417, 0.3752042055130005, 0.36284127831459045, 0.3520757555961609, 0.34168004989624023, 0.33010149002075195, 0.32171565294265747, 0.31176742911338806]\n",
      "Accuracy of Train ......................................\n",
      "[0.4229166805744171, 0.5236111283302307, 0.6430555582046509, 0.7444444298744202, 0.8069444298744202, 0.855555534362793, 0.8805555701255798, 0.8784722089767456, 0.9048610925674438, 0.9083333611488342, 0.9291666746139526, 0.9284722208976746, 0.9354166388511658, 0.9402777552604675, 0.9381944537162781, 0.9416666626930237, 0.9423611164093018, 0.9451388716697693, 0.949305534362793, 0.9534721970558167]\n",
      "Precision of Train ......................................\n",
      "[0.4051036536693573, 0.5175675749778748, 0.6477611660957336, 0.7551928758621216, 0.8005540370941162, 0.8433242440223694, 0.8868194818496704, 0.8776371479034424, 0.9043600559234619, 0.9050279259681702, 0.9212707281112671, 0.9246861934661865, 0.9292649030685425, 0.9420903921127319, 0.928473174571991, 0.9349030256271362, 0.9349930882453918, 0.9426573514938354, 0.9394773244857788, 0.9472954273223877]\n",
      "Recall of Train ......................................\n",
      "[0.3567415773868561, 0.5379213690757751, 0.6095505356788635, 0.7148876190185547, 0.8117977380752563, 0.8693820238113403, 0.8693820238113403, 0.8764045238494873, 0.9030898809432983, 0.9101123809814453, 0.9367977380752563, 0.9311797618865967, 0.9410112500190735, 0.9367977380752563, 0.9480336904525757, 0.9480336904525757, 0.949438214302063, 0.9466292262077332, 0.959269642829895, 0.959269642829895]\n",
      "AUC of Train ......................................\n",
      "[0.39127224683761597, 0.5359940528869629, 0.7074975967407227, 0.8291764259338379, 0.8969095945358276, 0.9361186623573303, 0.9536777138710022, 0.9573066234588623, 0.9703223705291748, 0.9746111035346985, 0.980021595954895, 0.9842003583908081, 0.9845553040504456, 0.9874125123023987, 0.987531304359436, 0.9897489547729492, 0.9902698397636414, 0.9897566437721252, 0.9912315607070923, 0.9928810596466064]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8486111059784889\n",
      " Loss:0.46408281326293943\n",
      " Precision:0.8444229885935783\n",
      " Recall:0.8457865133881569\n",
      " AUC:0.9015247762203217\n",
      "Score for fold 4: loss of 0.32491686940193176; accuracy of 0.9277777671813965%\n",
      "[[155  17]\n",
      " [  9 179]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 512.3194092 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:155,FN:9,TP:179,FP:17\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9277777777777778\n",
      " Loss:0.32491686940193176\n",
      " Precision:0.9132653061224489\n",
      " Recall:0.9521276595744681\n",
      " AUC:0.9486248053969901\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,574,337\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 132ms/step - loss: 0.7115 - accuracy: 0.5174 - binary_crossentropy: 0.7115 - precision: 0.5144 - recall: 0.5467 - auc: 0.5180\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.6532 - accuracy: 0.6132 - binary_crossentropy: 0.6532 - precision: 0.6136 - recall: 0.6025 - auc: 0.6657\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.6127 - accuracy: 0.6979 - binary_crossentropy: 0.6127 - precision: 0.6958 - recall: 0.6987 - auc: 0.7795\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.5726 - accuracy: 0.7674 - binary_crossentropy: 0.5726 - precision: 0.7877 - recall: 0.7294 - auc: 0.8546\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.5442 - accuracy: 0.8153 - binary_crossentropy: 0.5442 - precision: 0.8145 - recall: 0.8145 - auc: 0.9042\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.5153 - accuracy: 0.8562 - binary_crossentropy: 0.5153 - precision: 0.8561 - recall: 0.8550 - auc: 0.9342\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.4925 - accuracy: 0.8681 - binary_crossentropy: 0.4925 - precision: 0.8791 - recall: 0.8522 - auc: 0.9412\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.4698 - accuracy: 0.8903 - binary_crossentropy: 0.4698 - precision: 0.8953 - recall: 0.8828 - auc: 0.9557\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.4495 - accuracy: 0.8972 - binary_crossentropy: 0.4495 - precision: 0.8913 - recall: 0.9038 - auc: 0.9656\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.4306 - accuracy: 0.9035 - binary_crossentropy: 0.4306 - precision: 0.9036 - recall: 0.9024 - auc: 0.9694\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.4156 - accuracy: 0.9174 - binary_crossentropy: 0.4156 - precision: 0.9176 - recall: 0.9163 - auc: 0.9723\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3989 - accuracy: 0.9243 - binary_crossentropy: 0.3989 - precision: 0.9234 - recall: 0.9247 - auc: 0.9790\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.3866 - accuracy: 0.9271 - binary_crossentropy: 0.3866 - precision: 0.9238 - recall: 0.9303 - auc: 0.9797\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.3741 - accuracy: 0.9333 - binary_crossentropy: 0.3741 - precision: 0.9331 - recall: 0.9331 - auc: 0.9825\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.3630 - accuracy: 0.9306 - binary_crossentropy: 0.3630 - precision: 0.9267 - recall: 0.9344 - auc: 0.9830\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.3521 - accuracy: 0.9368 - binary_crossentropy: 0.3521 - precision: 0.9421 - recall: 0.9303 - auc: 0.9850\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.3419 - accuracy: 0.9403 - binary_crossentropy: 0.3419 - precision: 0.9352 - recall: 0.9456 - auc: 0.9864\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 0.3326 - accuracy: 0.9444 - binary_crossentropy: 0.3326 - precision: 0.9442 - recall: 0.9442 - auc: 0.9874\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.3232 - accuracy: 0.9424 - binary_crossentropy: 0.3232 - precision: 0.9427 - recall: 0.9414 - auc: 0.9884\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.3143 - accuracy: 0.9465 - binary_crossentropy: 0.3143 - precision: 0.9457 - recall: 0.9470 - auc: 0.9891\n",
      "Loss of Train ......................................\n",
      "[0.711500883102417, 0.6531808376312256, 0.6127132177352905, 0.5725781917572021, 0.5441983938217163, 0.5153389573097229, 0.49253615736961365, 0.4697916805744171, 0.4495086669921875, 0.43055081367492676, 0.4155656695365906, 0.3988652527332306, 0.38661351799964905, 0.3741157054901123, 0.3630181550979614, 0.35206303000450134, 0.34193411469459534, 0.33257773518562317, 0.3231751620769501, 0.31432613730430603]\n",
      "Accuracy of Train ......................................\n",
      "[0.5173611044883728, 0.613194465637207, 0.6979166865348816, 0.7673611044883728, 0.8152777552604675, 0.856249988079071, 0.8680555820465088, 0.8902778029441833, 0.8972222208976746, 0.9034722447395325, 0.9173611402511597, 0.9243055582046509, 0.9270833134651184, 0.9333333373069763, 0.9305555820465088, 0.9368055462837219, 0.9402777552604675, 0.9444444179534912, 0.9423611164093018, 0.9465277791023254]\n",
      "Precision of Train ......................................\n",
      "[0.5144357085227966, 0.6136363744735718, 0.6958333253860474, 0.7876505851745605, 0.814504861831665, 0.8561452627182007, 0.8791366815567017, 0.895332396030426, 0.8913342356681824, 0.9036312699317932, 0.917597770690918, 0.9233983159065247, 0.9238227009773254, 0.9330543875694275, 0.9266943335533142, 0.9420903921127319, 0.935172438621521, 0.944212019443512, 0.9427374005317688, 0.9456824660301208]\n",
      "Recall of Train ......................................\n",
      "[0.5467224717140198, 0.6025104522705078, 0.6987447738647461, 0.7294281721115112, 0.814504861831665, 0.8549512028694153, 0.8521617650985718, 0.8828451633453369, 0.9037656784057617, 0.9023709893226624, 0.9163179993629456, 0.9246861934661865, 0.9302650094032288, 0.9330543875694275, 0.9344490766525269, 0.9302650094032288, 0.9456067085266113, 0.944212019443512, 0.9414225816726685, 0.9470013976097107]\n",
      "AUC of Train ......................................\n",
      "[0.5180057287216187, 0.6657290458679199, 0.7794522047042847, 0.8545972108840942, 0.9042189717292786, 0.934179961681366, 0.9411699175834656, 0.9557390809059143, 0.9656215310096741, 0.9694352149963379, 0.9722999334335327, 0.9789618253707886, 0.9796842336654663, 0.9824948310852051, 0.9830262660980225, 0.98496013879776, 0.9863577485084534, 0.9874149560928345, 0.9884353280067444, 0.9891356825828552]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8584722250699997\n",
      " Loss:0.45270761400461196\n",
      " Precision:0.8593051463365555\n",
      " Recall:0.8567642956972122\n",
      " AUC:0.9160459905862808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 0.30728572607040405; accuracy of 0.9472222328186035%\n",
      "[[173   4]\n",
      " [ 15 168]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 640.3517654000001 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:173,FN:15,TP:168,FP:4\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9472222222222222\n",
      " Loss:0.30728572607040405\n",
      " Precision:0.9767441860465116\n",
      " Recall:0.9180327868852459\n",
      " AUC:0.9191227764213463\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.8432638943195343 - Loss: 0.45283899903297425\n",
      "> Fold 1 - Precision: 0.8383555024862289\n",
      "> Fold 1 - Recall: 0.8566712498664856\n",
      "> Fold 1 - AUC: 0.9064273923635483\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9 - Loss: 0.3458716571331024\n",
      "> Fold 1 - Precision: 0.8959537572254336\n",
      "> Fold 1 - Recall: 0.8959537572254336\n",
      "> Fold 1 - AUC: 0.8998485363667275\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8656944423913956 - Loss: 0.44321059733629226\n",
      "> Fold 2 - Precision: 0.8605193287134171\n",
      "> Fold 2 - Recall: 0.8806164413690567\n",
      "> Fold 2 - AUC: 0.9239548683166504\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.9361111111111111 - Loss: 0.2969905436038971\n",
      "> Fold 2 - Precision: 0.950920245398773\n",
      "> Fold 2 - Recall: 0.9117647058823529\n",
      "> Fold 2 - AUC: 0.9178112869513287\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.8541319370269775 - Loss: 0.4495407909154892\n",
      "> Fold 3 - Precision: 0.8536048471927643\n",
      "> Fold 3 - Recall: 0.8483193203806877\n",
      "> Fold 3 - AUC: 0.9167699128389358\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9555555555555556 - Loss: 0.31268277764320374\n",
      "> Fold 3 - Precision: 0.9381443298969072\n",
      "> Fold 3 - Recall: 0.978494623655914\n",
      "> Fold 3 - AUC: 0.9771991190568727\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.8486111059784889 - Loss: 0.46408281326293943\n",
      "> Fold 4 - Precision: 0.8444229885935783\n",
      "> Fold 4 - Recall: 0.8457865133881569\n",
      "> Fold 4 - AUC: 0.9015247762203217\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9277777777777778 - Loss: 0.32491686940193176\n",
      "> Fold 4 - Precision: 0.9132653061224489\n",
      "> Fold 4 - Recall: 0.9521276595744681\n",
      "> Fold 4 - AUC: 0.9486248053969901\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.8584722250699997 - Loss: 0.45270761400461196\n",
      "> Fold 5 - Precision: 0.8593051463365555\n",
      "> Fold 5 - Recall: 0.8567642956972122\n",
      "> Fold 5 - AUC: 0.9160459905862808\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9472222222222222 - Loss: 0.30728572607040405\n",
      "> Fold 5 - Precision: 0.9767441860465116\n",
      "> Fold 5 - Recall: 0.9180327868852459\n",
      "> Fold 5 - AUC: 0.9191227764213463\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.8540347209572792 (+- 0.0077598492708856855)\n",
      "> Loss: 0.45247616291046133 (+- 0.0067729855488338)\n",
      "> Precision: 0.8512415626645089 (+- 0.008593333899423218)\n",
      "> Recall: 0.8576315641403198 (+- 0.012304487396370236)\n",
      "> AUC: 0.9129445880651474 (+- 0.007979524056281212)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9333333333333333 (+- 0.019164653678511487)\n",
      "> Loss: 0.3175495147705078 (+- 0.01678167718941363)\n",
      "> Precision: 0.9350055649380149 (+- 0.028294607014984565)\n",
      "> Recall: 0.9312747066446828 (+- 0.02989355865392423)\n",
      "> AUC: 0.932521304838653 (+- 0.02727212790804908)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 841 FN SUM: 61 TP SUM: 839 FP SUM: 59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  model = VGG19()\n",
    "  model_2 = Sequential()\n",
    "  for layer in model.layers[:-3]:\n",
    "    model_2.add(layer)\n",
    "\n",
    "  # Freeze the layers\n",
    "  for layer in model_2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(layers.Dense(4096))\n",
    "  model_2.add(Dense(1,activation='sigmoid'))\n",
    "  model_2.summary()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408035f4",
   "metadata": {},
   "source": [
    "# ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a1ceec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 33s 417ms/step - loss: 0.7097 - accuracy: 0.5250 - binary_crossentropy: 0.7097 - precision: 0.5265 - recall: 0.7151 - auc: 0.5406\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.6670 - accuracy: 0.5979 - binary_crossentropy: 0.6670 - precision: 0.5782 - recall: 0.7924 - auc: 0.6394\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.6205 - accuracy: 0.6597 - binary_crossentropy: 0.6205 - precision: 0.6310 - recall: 0.8073 - auc: 0.7353\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.5922 - accuracy: 0.7132 - binary_crossentropy: 0.5922 - precision: 0.6757 - recall: 0.8453 - auc: 0.7911\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.5584 - accuracy: 0.7681 - binary_crossentropy: 0.5584 - precision: 0.7319 - recall: 0.8630 - auc: 0.8489\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.5327 - accuracy: 0.7910 - binary_crossentropy: 0.5327 - precision: 0.7541 - recall: 0.8779 - auc: 0.8843\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.5077 - accuracy: 0.8292 - binary_crossentropy: 0.5077 - precision: 0.7947 - recall: 0.8982 - auc: 0.9125\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.4823 - accuracy: 0.8528 - binary_crossentropy: 0.4823 - precision: 0.8221 - recall: 0.9091 - auc: 0.9425\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.4652 - accuracy: 0.8729 - binary_crossentropy: 0.4652 - precision: 0.8445 - recall: 0.9213 - auc: 0.9502\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.4401 - accuracy: 0.8882 - binary_crossentropy: 0.4401 - precision: 0.8692 - recall: 0.9199 - auc: 0.9606\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.4176 - accuracy: 0.9139 - binary_crossentropy: 0.4176 - precision: 0.9028 - recall: 0.9322 - auc: 0.9760\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.4096 - accuracy: 0.9167 - binary_crossentropy: 0.4096 - precision: 0.9012 - recall: 0.9403 - auc: 0.9749\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.3889 - accuracy: 0.9285 - binary_crossentropy: 0.3889 - precision: 0.9128 - recall: 0.9512 - auc: 0.9811\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.3708 - accuracy: 0.9424 - binary_crossentropy: 0.3708 - precision: 0.9325 - recall: 0.9566 - auc: 0.9879\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.3604 - accuracy: 0.9361 - binary_crossentropy: 0.3604 - precision: 0.9272 - recall: 0.9498 - auc: 0.9887\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.3485 - accuracy: 0.9493 - binary_crossentropy: 0.3485 - precision: 0.9403 - recall: 0.9620 - auc: 0.9913\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.3327 - accuracy: 0.9618 - binary_crossentropy: 0.3327 - precision: 0.9499 - recall: 0.9769 - auc: 0.9938\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.3138 - accuracy: 0.9611 - binary_crossentropy: 0.3138 - precision: 0.9595 - recall: 0.9647 - auc: 0.9956\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.3021 - accuracy: 0.9681 - binary_crossentropy: 0.3021 - precision: 0.9650 - recall: 0.9729 - auc: 0.9967\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2992 - accuracy: 0.9743 - binary_crossentropy: 0.2992 - precision: 0.9704 - recall: 0.9796 - auc: 0.9974\n",
      "Loss of Train ......................................\n",
      "[0.7096551060676575, 0.6669501662254333, 0.6204603910446167, 0.5921586155891418, 0.5584174990653992, 0.5327078700065613, 0.5077276229858398, 0.48231032490730286, 0.46517083048820496, 0.44010692834854126, 0.41758719086647034, 0.40957117080688477, 0.3888964056968689, 0.37075474858283997, 0.36036020517349243, 0.348474383354187, 0.33271634578704834, 0.31379812955856323, 0.3020611107349396, 0.29919371008872986]\n",
      "Accuracy of Train ......................................\n",
      "[0.5249999761581421, 0.5979166626930237, 0.6597222089767456, 0.7131944298744202, 0.7680555582046509, 0.7909722328186035, 0.8291666507720947, 0.8527777791023254, 0.8729166388511658, 0.8881944417953491, 0.9138888716697693, 0.9166666865348816, 0.9284722208976746, 0.9423611164093018, 0.9361110925674438, 0.949305534362793, 0.9618055820465088, 0.9611111283302307, 0.9680555462837219, 0.9743055701255798]\n",
      "Precision of Train ......................................\n",
      "[0.5264735221862793, 0.5782178044319153, 0.630964994430542, 0.6757050156593323, 0.7318757176399231, 0.754079282283783, 0.7947179079055786, 0.8220859169960022, 0.8445273637771606, 0.8692307472229004, 0.9027595520019531, 0.9011703729629517, 0.9127604365348816, 0.932539701461792, 0.9271523356437683, 0.9403182864189148, 0.9498680830001831, 0.9595141410827637, 0.9650067090988159, 0.9704301357269287]\n",
      "Recall of Train ......................................\n",
      "[0.7150610685348511, 0.7924016118049622, 0.8073269724845886, 0.8453188538551331, 0.8629579544067383, 0.8778833150863647, 0.898236095905304, 0.9090909361839294, 0.9213025569915771, 0.9199457168579102, 0.9321573972702026, 0.9402984976768494, 0.9511533379554749, 0.9565807580947876, 0.9497964978218079, 0.9620081186294556, 0.9769335389137268, 0.9647218585014343, 0.972862958908081, 0.9796472191810608]\n",
      "AUC of Train ......................................\n",
      "[0.5406302809715271, 0.6393687725067139, 0.7353231310844421, 0.7910591959953308, 0.848917543888092, 0.8842805624008179, 0.9124916791915894, 0.9425248503684998, 0.9501641392707825, 0.960638701915741, 0.9760177731513977, 0.9749069213867188, 0.9811410903930664, 0.9879426956176758, 0.9887080192565918, 0.991348385810852, 0.9938044548034668, 0.9955530762672424, 0.9966802597045898, 0.997403085231781]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8474999964237213\n",
      " Loss:0.45595393776893617\n",
      " Precision:0.8294699013233184\n",
      " Recall:0.9067842632532119\n",
      " AUC:0.904445230960846\n",
      "Score for fold 1: loss of 0.34189754724502563; accuracy of 0.9222221970558167%\n",
      "[[183  14]\n",
      " [ 14 149]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 419.2229792 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:183,FN:14,TP:149,FP:14\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9222222222222223\n",
      " Loss:0.34189754724502563\n",
      " Precision:0.9141104294478528\n",
      " Recall:0.9141104294478528\n",
      " AUC:0.9215222198000685\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 2049      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 28s 436ms/step - loss: 0.6670 - accuracy: 0.5861 - binary_crossentropy: 0.6670 - precision: 0.6085 - recall: 0.4798 - auc: 0.6337\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.6308 - accuracy: 0.6604 - binary_crossentropy: 0.6308 - precision: 0.6962 - recall: 0.5675 - auc: 0.7176\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.5955 - accuracy: 0.7153 - binary_crossentropy: 0.5955 - precision: 0.7373 - recall: 0.6676 - auc: 0.7806\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.5637 - accuracy: 0.7549 - binary_crossentropy: 0.5637 - precision: 0.7731 - recall: 0.7204 - auc: 0.8375\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.5338 - accuracy: 0.8028 - binary_crossentropy: 0.5338 - precision: 0.8166 - recall: 0.7803 - auc: 0.8777\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.4994 - accuracy: 0.8389 - binary_crossentropy: 0.4994 - precision: 0.8444 - recall: 0.8303 - auc: 0.9176\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.4788 - accuracy: 0.8556 - binary_crossentropy: 0.4788 - precision: 0.8495 - recall: 0.8637 - auc: 0.9376\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.4478 - accuracy: 0.8972 - binary_crossentropy: 0.4478 - precision: 0.8927 - recall: 0.9026 - auc: 0.9623\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.4296 - accuracy: 0.9125 - binary_crossentropy: 0.4296 - precision: 0.9045 - recall: 0.9221 - auc: 0.9679\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.4146 - accuracy: 0.9201 - binary_crossentropy: 0.4146 - precision: 0.9048 - recall: 0.9388 - auc: 0.9726\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.3970 - accuracy: 0.9326 - binary_crossentropy: 0.3970 - precision: 0.9237 - recall: 0.9430 - auc: 0.9786\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.3750 - accuracy: 0.9403 - binary_crossentropy: 0.3750 - precision: 0.9318 - recall: 0.9499 - auc: 0.9837\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.3592 - accuracy: 0.9507 - binary_crossentropy: 0.3592 - precision: 0.9378 - recall: 0.9652 - auc: 0.9876\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.3383 - accuracy: 0.9583 - binary_crossentropy: 0.3383 - precision: 0.9459 - recall: 0.9722 - auc: 0.9925\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.3242 - accuracy: 0.9590 - binary_crossentropy: 0.3242 - precision: 0.9472 - recall: 0.9722 - auc: 0.9937\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.3104 - accuracy: 0.9632 - binary_crossentropy: 0.3104 - precision: 0.9512 - recall: 0.9764 - auc: 0.9949\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.3025 - accuracy: 0.9743 - binary_crossentropy: 0.3025 - precision: 0.9684 - recall: 0.9805 - auc: 0.9945\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.2865 - accuracy: 0.9715 - binary_crossentropy: 0.2865 - precision: 0.9644 - recall: 0.9791 - auc: 0.9959\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.2763 - accuracy: 0.9750 - binary_crossentropy: 0.2763 - precision: 0.9634 - recall: 0.9875 - auc: 0.9970\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.2704 - accuracy: 0.9771 - binary_crossentropy: 0.2704 - precision: 0.9699 - recall: 0.9847 - auc: 0.9975\n",
      "Loss of Train ......................................\n",
      "[0.6670291423797607, 0.6307782530784607, 0.5954573154449463, 0.5636661648750305, 0.533814013004303, 0.49939554929733276, 0.4787520468235016, 0.4478260576725006, 0.42955461144447327, 0.4146014451980591, 0.39697855710983276, 0.37495800852775574, 0.3592446744441986, 0.33831489086151123, 0.32417261600494385, 0.3103615939617157, 0.3024536669254303, 0.28654757142066956, 0.27632173895835876, 0.27038541436195374]\n",
      "Accuracy of Train ......................................\n",
      "[0.5861111283302307, 0.6604166626930237, 0.7152777910232544, 0.7548611164093018, 0.8027777671813965, 0.8388888835906982, 0.855555534362793, 0.8972222208976746, 0.9125000238418579, 0.9201388955116272, 0.9326388835906982, 0.9402777552604675, 0.9506944417953491, 0.9583333134651184, 0.9590277671813965, 0.9631944298744202, 0.9743055701255798, 0.9715277552604675, 0.9750000238418579, 0.9770833253860474]\n",
      "Precision of Train ......................................\n",
      "[0.6084656119346619, 0.6962457299232483, 0.7373272180557251, 0.7731343507766724, 0.8165938854217529, 0.8444130420684814, 0.8495212197303772, 0.8927097916603088, 0.9045020341873169, 0.904825747013092, 0.9237056970596313, 0.9317871928215027, 0.9378378391265869, 0.9458727836608887, 0.9471544623374939, 0.9512194991111755, 0.968406617641449, 0.9643835425376892, 0.9633650183677673, 0.9698629975318909]\n",
      "Recall of Train ......................................\n",
      "[0.47983309626579285, 0.5674548149108887, 0.6675938963890076, 0.7204450368881226, 0.7802503705024719, 0.830319881439209, 0.8636995553970337, 0.902642548084259, 0.9221140742301941, 0.9388039112091064, 0.9429763555526733, 0.9499304294586182, 0.9652295112609863, 0.9721835851669312, 0.9721835851669312, 0.976356029510498, 0.9805285334587097, 0.9791377186775208, 0.9874826073646545, 0.9847009778022766]\n",
      "AUC of Train ......................................\n",
      "[0.6336885094642639, 0.7175602912902832, 0.780587911605835, 0.8374688029289246, 0.8777022361755371, 0.9175664186477661, 0.9376281499862671, 0.9622858166694641, 0.9678818583488464, 0.9725751876831055, 0.9786332845687866, 0.9837403297424316, 0.9876060485839844, 0.992541491985321, 0.9937094449996948, 0.9948996901512146, 0.9944994449615479, 0.9959423542022705, 0.9970225691795349, 0.9974690675735474]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.877291664481163\n",
      " Loss:0.4250306665897369\n",
      " Precision:0.8765667140483856\n",
      " Recall:0.8691933259367943\n",
      " AUC:0.9260504454374313\n",
      "Score for fold 2: loss of 0.30964043736457825; accuracy of 0.9611111283302307%\n",
      "[[176   3]\n",
      " [ 11 170]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 846.9312431 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:176,FN:11,TP:170,FP:3\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9611111111111111\n",
      " Loss:0.30964043736457825\n",
      " Precision:0.9826589595375722\n",
      " Recall:0.9392265193370166\n",
      " AUC:0.940201494962626\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 28s 431ms/step - loss: 0.6644 - accuracy: 0.5958 - binary_crossentropy: 0.6644 - precision: 0.5790 - recall: 0.6982 - auc: 0.6429\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.6274 - accuracy: 0.6576 - binary_crossentropy: 0.6274 - precision: 0.6329 - recall: 0.7483 - auc: 0.7123\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.5851 - accuracy: 0.7243 - binary_crossentropy: 0.5851 - precision: 0.6973 - recall: 0.7914 - auc: 0.7891\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.5444 - accuracy: 0.7722 - binary_crossentropy: 0.5444 - precision: 0.7381 - recall: 0.8428 - auc: 0.8533\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.5148 - accuracy: 0.7979 - binary_crossentropy: 0.5148 - precision: 0.7723 - recall: 0.8442 - auc: 0.8863\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.4840 - accuracy: 0.8465 - binary_crossentropy: 0.4840 - precision: 0.8251 - recall: 0.8790 - auc: 0.9211\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.4552 - accuracy: 0.8660 - binary_crossentropy: 0.4552 - precision: 0.8479 - recall: 0.8915 - auc: 0.9431\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.4279 - accuracy: 0.8910 - binary_crossentropy: 0.4279 - precision: 0.8737 - recall: 0.9138 - auc: 0.9602\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.4081 - accuracy: 0.8986 - binary_crossentropy: 0.4081 - precision: 0.8835 - recall: 0.9179 - auc: 0.9680\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.3875 - accuracy: 0.9271 - binary_crossentropy: 0.3875 - precision: 0.9137 - recall: 0.9430 - auc: 0.9771\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.3598 - accuracy: 0.9410 - binary_crossentropy: 0.3598 - precision: 0.9319 - recall: 0.9513 - auc: 0.9858\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.3474 - accuracy: 0.9472 - binary_crossentropy: 0.3474 - precision: 0.9410 - recall: 0.9541 - auc: 0.9876\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.3310 - accuracy: 0.9597 - binary_crossentropy: 0.3310 - precision: 0.9571 - recall: 0.9624 - auc: 0.9906\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.3145 - accuracy: 0.9583 - binary_crossentropy: 0.3145 - precision: 0.9532 - recall: 0.9638 - auc: 0.9930\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.3017 - accuracy: 0.9639 - binary_crossentropy: 0.3017 - precision: 0.9600 - recall: 0.9680 - auc: 0.9936\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.2907 - accuracy: 0.9708 - binary_crossentropy: 0.2907 - precision: 0.9708 - recall: 0.9708 - auc: 0.9947\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.2764 - accuracy: 0.9750 - binary_crossentropy: 0.2764 - precision: 0.9723 - recall: 0.9777 - auc: 0.9964\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.2649 - accuracy: 0.9812 - binary_crossentropy: 0.2649 - precision: 0.9832 - recall: 0.9791 - auc: 0.9979\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.2618 - accuracy: 0.9743 - binary_crossentropy: 0.2618 - precision: 0.9736 - recall: 0.9750 - auc: 0.9958\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.2475 - accuracy: 0.9840 - binary_crossentropy: 0.2475 - precision: 0.9833 - recall: 0.9847 - auc: 0.9981\n",
      "Loss of Train ......................................\n",
      "[0.6643784642219543, 0.627418577671051, 0.5851272344589233, 0.5444175004959106, 0.5148366093635559, 0.4839822053909302, 0.4552161395549774, 0.42791619896888733, 0.4081449806690216, 0.3874695301055908, 0.3597804307937622, 0.34743234515190125, 0.33100491762161255, 0.3144882321357727, 0.30174949765205383, 0.29073506593704224, 0.2763623297214508, 0.2648935914039612, 0.2617509365081787, 0.24748145043849945]\n",
      "Accuracy of Train ......................................\n",
      "[0.5958333611488342, 0.6576389074325562, 0.7243055701255798, 0.7722222208976746, 0.7979166507720947, 0.8465277552604675, 0.8659722208976746, 0.8909721970558167, 0.8986111283302307, 0.9270833134651184, 0.9409722089767456, 0.9472222328186035, 0.9597222208976746, 0.9583333134651184, 0.9638888835906982, 0.9708333611488342, 0.9750000238418579, 0.981249988079071, 0.9743055701255798, 0.9840278029441833]\n",
      "Precision of Train ......................................\n",
      "[0.5790081024169922, 0.6329411864280701, 0.6973039507865906, 0.7381242513656616, 0.7722646594047546, 0.8250652551651001, 0.8478835821151733, 0.873670220375061, 0.8835341334342957, 0.9137466549873352, 0.9318801164627075, 0.9410150647163391, 0.9571231007575989, 0.95323246717453, 0.9599999785423279, 0.9707927703857422, 0.9723374843597412, 0.9832402467727661, 0.9736111164093018, 0.9833333492279053]\n",
      "Recall of Train ......................................\n",
      "[0.6981919407844543, 0.7482614517211914, 0.7913768887519836, 0.8428372740745544, 0.8442280888557434, 0.8789986371994019, 0.8915159702301025, 0.9137691259384155, 0.9179415702819824, 0.9429763555526733, 0.9513213038444519, 0.9541029334068298, 0.9624478220939636, 0.9638386368751526, 0.9680111408233643, 0.9707927703857422, 0.977746844291687, 0.9791377186775208, 0.9749652147293091, 0.9847009778022766]\n",
      "AUC of Train ......................................\n",
      "[0.6428609490394592, 0.7122940421104431, 0.7891449332237244, 0.8532886505126953, 0.8863067030906677, 0.9210810661315918, 0.9430757761001587, 0.9601542353630066, 0.9680285453796387, 0.9771084189414978, 0.9857928156852722, 0.9876341223716736, 0.9905883073806763, 0.9929794073104858, 0.9935763478279114, 0.9947038292884827, 0.9963927268981934, 0.9979060888290405, 0.9958015084266663, 0.9980931878089905]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8816319465637207\n",
      " Loss:0.4047293119132519\n",
      " Precision:0.8695053845643997\n",
      " Recall:0.90785813331604\n",
      " AUC:0.9293405830860137\n",
      "Score for fold 3: loss of 0.30649664998054504; accuracy of 0.9361110925674438%\n",
      "[[163  16]\n",
      " [  7 174]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1264.7491926 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:163,FN:7,TP:174,FP:16\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9361111111111111\n",
      " Loss:0.30649664998054504\n",
      " Precision:0.9157894736842105\n",
      " Recall:0.9613259668508287\n",
      " AUC:0.9600747481312968\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 28s 433ms/step - loss: 0.6618 - accuracy: 0.6069 - binary_crossentropy: 0.6618 - precision: 0.6434 - recall: 0.4448 - auc: 0.6488\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.6075 - accuracy: 0.6778 - binary_crossentropy: 0.6075 - precision: 0.7208 - recall: 0.5595 - auc: 0.7581\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.5709 - accuracy: 0.7424 - binary_crossentropy: 0.5709 - precision: 0.7873 - recall: 0.6501 - auc: 0.8238\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.5436 - accuracy: 0.7847 - binary_crossentropy: 0.5436 - precision: 0.8173 - recall: 0.7224 - auc: 0.8635\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 20s 438ms/step - loss: 0.5142 - accuracy: 0.8292 - binary_crossentropy: 0.5142 - precision: 0.8538 - recall: 0.7861 - auc: 0.9009\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.4882 - accuracy: 0.8465 - binary_crossentropy: 0.4882 - precision: 0.8725 - recall: 0.8045 - auc: 0.9257\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.4646 - accuracy: 0.8729 - binary_crossentropy: 0.4646 - precision: 0.8897 - recall: 0.8456 - auc: 0.9409\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.4377 - accuracy: 0.8993 - binary_crossentropy: 0.4377 - precision: 0.9107 - recall: 0.8810 - auc: 0.9615\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.4154 - accuracy: 0.9076 - binary_crossentropy: 0.4154 - precision: 0.9146 - recall: 0.8952 - auc: 0.9737\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.4005 - accuracy: 0.9174 - binary_crossentropy: 0.4005 - precision: 0.9272 - recall: 0.9023 - auc: 0.9757\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.3833 - accuracy: 0.9187 - binary_crossentropy: 0.3833 - precision: 0.9274 - recall: 0.9051 - auc: 0.9820\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.3607 - accuracy: 0.9424 - binary_crossentropy: 0.3607 - precision: 0.9369 - recall: 0.9462 - auc: 0.9883\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.3470 - accuracy: 0.9563 - binary_crossentropy: 0.3470 - precision: 0.9653 - recall: 0.9448 - auc: 0.9914\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.3292 - accuracy: 0.9549 - binary_crossentropy: 0.3292 - precision: 0.9546 - recall: 0.9533 - auc: 0.9935\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.3166 - accuracy: 0.9667 - binary_crossentropy: 0.3166 - precision: 0.9687 - recall: 0.9632 - auc: 0.9945\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.3033 - accuracy: 0.9722 - binary_crossentropy: 0.3033 - precision: 0.9703 - recall: 0.9731 - auc: 0.9959\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.2939 - accuracy: 0.9694 - binary_crossentropy: 0.2939 - precision: 0.9715 - recall: 0.9660 - auc: 0.9966\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.2864 - accuracy: 0.9715 - binary_crossentropy: 0.2864 - precision: 0.9677 - recall: 0.9745 - auc: 0.9957\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.2726 - accuracy: 0.9722 - binary_crossentropy: 0.2726 - precision: 0.9677 - recall: 0.9759 - auc: 0.9978\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.2599 - accuracy: 0.9819 - binary_crossentropy: 0.2599 - precision: 0.9789 - recall: 0.9844 - auc: 0.9988\n",
      "Loss of Train ......................................\n",
      "[0.6618124842643738, 0.6075437068939209, 0.570917546749115, 0.543607771396637, 0.51421719789505, 0.4881904125213623, 0.46464425325393677, 0.43768543004989624, 0.41541022062301636, 0.40053486824035645, 0.38327428698539734, 0.36068296432495117, 0.34700533747673035, 0.32923686504364014, 0.3166073262691498, 0.3032788336277008, 0.2938597500324249, 0.28640928864479065, 0.27260321378707886, 0.25991737842559814]\n",
      "Accuracy of Train ......................................\n",
      "[0.6069444417953491, 0.6777777671813965, 0.7423611283302307, 0.7847222089767456, 0.8291666507720947, 0.8465277552604675, 0.8729166388511658, 0.8993055820465088, 0.9076389074325562, 0.9173611402511597, 0.918749988079071, 0.9423611164093018, 0.956250011920929, 0.9548611044883728, 0.9666666388511658, 0.9722222089767456, 0.9694444537162781, 0.9715277552604675, 0.9722222089767456, 0.9819444417953491]\n",
      "Precision of Train ......................................\n",
      "[0.6434426307678223, 0.720802903175354, 0.7873070240020752, 0.817307710647583, 0.8538461327552795, 0.8725038170814514, 0.8897168636322021, 0.9106881618499756, 0.9146165251731873, 0.927219808101654, 0.927431046962738, 0.9368863701820374, 0.9652677178382874, 0.9546099305152893, 0.9686609506607056, 0.9703390002250671, 0.9715099930763245, 0.9676511883735657, 0.9676966071128845, 0.9788732528686523]\n",
      "Recall of Train ......................................\n",
      "[0.44475921988487244, 0.5594900846481323, 0.6501416563987732, 0.7223796248435974, 0.7861189842224121, 0.8045325875282288, 0.8456090688705444, 0.8810198307037354, 0.8951841592788696, 0.902266263961792, 0.9050991535186768, 0.9461756348609924, 0.94475919008255, 0.9532577991485596, 0.9631727933883667, 0.9730878472328186, 0.9660056829452515, 0.9745042324066162, 0.9759206771850586, 0.9844192862510681]\n",
      "AUC of Train ......................................\n",
      "[0.6487676501274109, 0.7581068873405457, 0.8238116502761841, 0.8634514808654785, 0.9008874893188477, 0.9256720542907715, 0.9408957958221436, 0.9615248441696167, 0.9736889600753784, 0.9757431745529175, 0.9820042252540588, 0.9883009791374207, 0.9914299845695496, 0.9934581518173218, 0.9944781064987183, 0.9958713054656982, 0.996595025062561, 0.9957227110862732, 0.9978097677230835, 0.9988189339637756]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8845486074686051\n",
      " Loss:0.41287195682525635\n",
      " Precision:0.8973188817501068\n",
      " Recall:0.8538951888680458\n",
      " AUC:0.9353519588708877\n",
      "Score for fold 4: loss of 0.3173096776008606; accuracy of 0.9416666626930237%\n",
      "[[153  13]\n",
      " [  8 186]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1685.758374 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:153,FN:8,TP:186,FP:13\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9416666666666667\n",
      " Loss:0.3173096776008606\n",
      " Precision:0.9346733668341709\n",
      " Recall:0.9587628865979382\n",
      " AUC:0.9545367228020747\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,333,697\n",
      "Trainable params: 58,189,953\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 28s 429ms/step - loss: 0.7379 - accuracy: 0.5014 - binary_crossentropy: 0.7379 - precision: 0.5005 - recall: 0.7636 - auc: 0.5157\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.6742 - accuracy: 0.5854 - binary_crossentropy: 0.6742 - precision: 0.5580 - recall: 0.8164 - auc: 0.6483\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.6299 - accuracy: 0.6576 - binary_crossentropy: 0.6299 - precision: 0.6112 - recall: 0.8637 - auc: 0.7334\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.5938 - accuracy: 0.7076 - binary_crossentropy: 0.5938 - precision: 0.6562 - recall: 0.8707 - auc: 0.8017\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.5608 - accuracy: 0.7521 - binary_crossentropy: 0.5608 - precision: 0.6989 - recall: 0.8846 - auc: 0.8516\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.5200 - accuracy: 0.8056 - binary_crossentropy: 0.5200 - precision: 0.7486 - recall: 0.9193 - auc: 0.9055\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.4946 - accuracy: 0.8438 - binary_crossentropy: 0.4946 - precision: 0.7920 - recall: 0.9318 - auc: 0.9297\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.4693 - accuracy: 0.8715 - binary_crossentropy: 0.4693 - precision: 0.8272 - recall: 0.9388 - auc: 0.9491\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.4460 - accuracy: 0.8924 - binary_crossentropy: 0.4460 - precision: 0.8552 - recall: 0.9444 - auc: 0.9629\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.4210 - accuracy: 0.9125 - binary_crossentropy: 0.4210 - precision: 0.8758 - recall: 0.9611 - auc: 0.9745\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.4025 - accuracy: 0.9292 - binary_crossentropy: 0.4025 - precision: 0.9075 - recall: 0.9555 - auc: 0.9809\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.3807 - accuracy: 0.9389 - binary_crossentropy: 0.3807 - precision: 0.9212 - recall: 0.9597 - auc: 0.9858\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.3662 - accuracy: 0.9563 - binary_crossentropy: 0.3662 - precision: 0.9385 - recall: 0.9764 - auc: 0.9905\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.3529 - accuracy: 0.9479 - binary_crossentropy: 0.3529 - precision: 0.9282 - recall: 0.9708 - auc: 0.9910\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.3376 - accuracy: 0.9583 - binary_crossentropy: 0.3376 - precision: 0.9423 - recall: 0.9764 - auc: 0.9940\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.3157 - accuracy: 0.9681 - binary_crossentropy: 0.3157 - precision: 0.9529 - recall: 0.9847 - auc: 0.9955\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.3042 - accuracy: 0.9757 - binary_crossentropy: 0.3042 - precision: 0.9698 - recall: 0.9819 - auc: 0.9976\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.2955 - accuracy: 0.9750 - binary_crossentropy: 0.2955 - precision: 0.9697 - recall: 0.9805 - auc: 0.9972\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.2814 - accuracy: 0.9778 - binary_crossentropy: 0.2814 - precision: 0.9764 - recall: 0.9791 - auc: 0.9978\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.2685 - accuracy: 0.9854 - binary_crossentropy: 0.2685 - precision: 0.9768 - recall: 0.9944 - auc: 0.9983\n",
      "Loss of Train ......................................\n",
      "[0.7378664016723633, 0.6742250919342041, 0.6298980116844177, 0.5937597155570984, 0.560795783996582, 0.5200362801551819, 0.4945957660675049, 0.4692922830581665, 0.4459858238697052, 0.42098426818847656, 0.40246692299842834, 0.38066917657852173, 0.36615511775016785, 0.35290589928627014, 0.3375643491744995, 0.3157115578651428, 0.30422624945640564, 0.295452743768692, 0.2813893258571625, 0.2684519588947296]\n",
      "Accuracy of Train ......................................\n",
      "[0.5013889074325562, 0.5854166746139526, 0.6576389074325562, 0.7076388597488403, 0.7520833611488342, 0.8055555820465088, 0.84375, 0.8715277910232544, 0.8923611044883728, 0.9125000238418579, 0.9291666746139526, 0.9388889074325562, 0.956250011920929, 0.9479166865348816, 0.9583333134651184, 0.9680555462837219, 0.9756944179534912, 0.9750000238418579, 0.9777777791023254, 0.9854166507720947]\n",
      "Precision of Train ......................................\n",
      "[0.5004557967185974, 0.5579847693443298, 0.6112204790115356, 0.6561844944953918, 0.6989011168479919, 0.7485843896865845, 0.7919621467590332, 0.8272058963775635, 0.8551637530326843, 0.8757921457290649, 0.9075297117233276, 0.921228289604187, 0.9385026693344116, 0.9281914830207825, 0.9422819018363953, 0.9528936743736267, 0.9697802066802979, 0.9697386622428894, 0.9764216542243958, 0.9767759442329407]\n",
      "Recall of Train ......................................\n",
      "[0.7635604739189148, 0.8164116740226746, 0.8636995553970337, 0.8706536889076233, 0.8845618963241577, 0.9193323850631714, 0.9318497776985168, 0.9388039112091064, 0.9443671703338623, 0.9610570073127747, 0.9554937481880188, 0.9596661925315857, 0.976356029510498, 0.9707927703857422, 0.976356029510498, 0.9847009778022766, 0.9819193482398987, 0.9805285334587097, 0.9791377186775208, 0.9944367408752441]\n",
      "AUC of Train ......................................\n",
      "[0.5156790614128113, 0.6483355164527893, 0.7334282994270325, 0.8017097115516663, 0.8515545129776001, 0.9055418968200684, 0.9297066330909729, 0.9490768313407898, 0.9629136919975281, 0.9745032787322998, 0.9809288382530212, 0.985805332660675, 0.9905276298522949, 0.9910416007041931, 0.9940094351768494, 0.995539128780365, 0.9975540637969971, 0.9972260594367981, 0.9977546334266663, 0.9982571601867676]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8571180611848831\n",
      " Loss:0.442621636390686\n",
      " Precision:0.8303399592638016\n",
      " Recall:0.9326842814683914\n",
      " AUC:0.9100546658039093\n",
      "Score for fold 5: loss of 0.31706297397613525; accuracy of 0.9638888835906982%\n",
      "[[170   9]\n",
      " [  4 177]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 2106.4328802 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:170,FN:4,TP:177,FP:9\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9638888888888889\n",
      " Loss:0.31706297397613525\n",
      " Precision:0.9516129032258065\n",
      " Recall:0.9779005524861878\n",
      " AUC:0.9774560233695306\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.8474999964237213 - Loss: 0.45595393776893617\n",
      "> Fold 1 - Precision: 0.8294699013233184\n",
      "> Fold 1 - Recall: 0.9067842632532119\n",
      "> Fold 1 - AUC: 0.904445230960846\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9222222222222223 - Loss: 0.34189754724502563\n",
      "> Fold 1 - Precision: 0.9141104294478528\n",
      "> Fold 1 - Recall: 0.9141104294478528\n",
      "> Fold 1 - AUC: 0.9215222198000685\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.877291664481163 - Loss: 0.4250306665897369\n",
      "> Fold 2 - Precision: 0.8765667140483856\n",
      "> Fold 2 - Recall: 0.8691933259367943\n",
      "> Fold 2 - AUC: 0.9260504454374313\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.9611111111111111 - Loss: 0.30964043736457825\n",
      "> Fold 2 - Precision: 0.9826589595375722\n",
      "> Fold 2 - Recall: 0.9392265193370166\n",
      "> Fold 2 - AUC: 0.940201494962626\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.8816319465637207 - Loss: 0.4047293119132519\n",
      "> Fold 3 - Precision: 0.8695053845643997\n",
      "> Fold 3 - Recall: 0.90785813331604\n",
      "> Fold 3 - AUC: 0.9293405830860137\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9361111111111111 - Loss: 0.30649664998054504\n",
      "> Fold 3 - Precision: 0.9157894736842105\n",
      "> Fold 3 - Recall: 0.9613259668508287\n",
      "> Fold 3 - AUC: 0.9600747481312968\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.8845486074686051 - Loss: 0.41287195682525635\n",
      "> Fold 4 - Precision: 0.8973188817501068\n",
      "> Fold 4 - Recall: 0.8538951888680458\n",
      "> Fold 4 - AUC: 0.9353519588708877\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9416666666666667 - Loss: 0.3173096776008606\n",
      "> Fold 4 - Precision: 0.9346733668341709\n",
      "> Fold 4 - Recall: 0.9587628865979382\n",
      "> Fold 4 - AUC: 0.9545367228020747\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.8571180611848831 - Loss: 0.442621636390686\n",
      "> Fold 5 - Precision: 0.8303399592638016\n",
      "> Fold 5 - Recall: 0.9326842814683914\n",
      "> Fold 5 - AUC: 0.9100546658039093\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9638888888888889 - Loss: 0.31706297397613525\n",
      "> Fold 5 - Precision: 0.9516129032258065\n",
      "> Fold 5 - Recall: 0.9779005524861878\n",
      "> Fold 5 - AUC: 0.9774560233695306\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.8696180552244186 (+- 0.014639655942361893)\n",
      "> Loss: 0.42824150189757343 (+- 0.01883678755482083)\n",
      "> Precision: 0.8606401681900022 (+- 0.026710534065345706)\n",
      "> Recall: 0.8940830385684967 (+- 0.028550626457739394)\n",
      "> AUC: 0.9210485768318175 (+- 0.011788977638656562)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.945 (+- 0.015654447559561517)\n",
      "> Loss: 0.31848145723342897 (+- 0.012437826746662089)\n",
      "> Precision: 0.9397690265459225 (+- 0.025452591519227196)\n",
      "> Recall: 0.9502652709439647 (+- 0.02185078420704201)\n",
      "> AUC: 0.9507582418131193 (+- 0.018868151132569323)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 845 FN SUM: 44 TP SUM: 856 FP SUM: 55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(ResNet152V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b18c6",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "950bf43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 23s 353ms/step - loss: 0.6834 - accuracy: 0.5556 - binary_crossentropy: 0.6834 - precision: 0.5389 - recall: 0.7694 - auc: 0.5968\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 16s 347ms/step - loss: 0.6800 - accuracy: 0.5590 - binary_crossentropy: 0.6800 - precision: 0.5422 - recall: 0.7583 - auc: 0.6147\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 15s 343ms/step - loss: 0.6778 - accuracy: 0.5882 - binary_crossentropy: 0.6778 - precision: 0.5638 - recall: 0.7792 - auc: 0.6314\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 16s 349ms/step - loss: 0.6753 - accuracy: 0.5924 - binary_crossentropy: 0.6753 - precision: 0.5688 - recall: 0.7639 - auc: 0.6416\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.6724 - accuracy: 0.6042 - binary_crossentropy: 0.6724 - precision: 0.5780 - recall: 0.7722 - auc: 0.6578\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 16s 364ms/step - loss: 0.6700 - accuracy: 0.6222 - binary_crossentropy: 0.6700 - precision: 0.5909 - recall: 0.7944 - auc: 0.6734\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.6671 - accuracy: 0.6257 - binary_crossentropy: 0.6671 - precision: 0.5944 - recall: 0.7917 - auc: 0.6820\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.6648 - accuracy: 0.6306 - binary_crossentropy: 0.6648 - precision: 0.5983 - recall: 0.7944 - auc: 0.6964\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.6627 - accuracy: 0.6382 - binary_crossentropy: 0.6627 - precision: 0.6066 - recall: 0.7861 - auc: 0.7071\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.6585 - accuracy: 0.6583 - binary_crossentropy: 0.6585 - precision: 0.6218 - recall: 0.8083 - auc: 0.7279\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.6548 - accuracy: 0.6757 - binary_crossentropy: 0.6548 - precision: 0.6368 - recall: 0.8181 - auc: 0.7450\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.6529 - accuracy: 0.6771 - binary_crossentropy: 0.6529 - precision: 0.6387 - recall: 0.8153 - auc: 0.7520\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.6525 - accuracy: 0.6743 - binary_crossentropy: 0.6525 - precision: 0.6378 - recall: 0.8069 - auc: 0.7529\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.6486 - accuracy: 0.6875 - binary_crossentropy: 0.6486 - precision: 0.6493 - recall: 0.8153 - auc: 0.7668\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.6443 - accuracy: 0.7049 - binary_crossentropy: 0.6443 - precision: 0.6663 - recall: 0.8208 - auc: 0.7847\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.6423 - accuracy: 0.7104 - binary_crossentropy: 0.6423 - precision: 0.6693 - recall: 0.8319 - auc: 0.7916\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.6419 - accuracy: 0.7076 - binary_crossentropy: 0.6419 - precision: 0.6689 - recall: 0.8222 - auc: 0.7896\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.6386 - accuracy: 0.7167 - binary_crossentropy: 0.6386 - precision: 0.6769 - recall: 0.8292 - auc: 0.8034\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.6357 - accuracy: 0.7417 - binary_crossentropy: 0.6357 - precision: 0.6991 - recall: 0.8486 - auc: 0.8167\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.6330 - accuracy: 0.7486 - binary_crossentropy: 0.6330 - precision: 0.7025 - recall: 0.8625 - auc: 0.8292\n",
      "Loss of Train ......................................\n",
      "[0.6834231615066528, 0.6800113916397095, 0.6777921915054321, 0.6752678155899048, 0.6723807454109192, 0.670025110244751, 0.6671308875083923, 0.6647771000862122, 0.6627041697502136, 0.658536970615387, 0.6547938585281372, 0.6528548002243042, 0.6524884104728699, 0.6486150026321411, 0.6443395018577576, 0.6422896385192871, 0.6418567895889282, 0.6386316418647766, 0.6356984376907349, 0.6330141425132751]\n",
      "Accuracy of Train ......................................\n",
      "[0.5555555820465088, 0.5590277910232544, 0.5881944298744202, 0.5923610925674438, 0.6041666865348816, 0.6222222447395325, 0.6256944537162781, 0.6305555701255798, 0.6381944417953491, 0.6583333611488342, 0.675694465637207, 0.6770833134651184, 0.6743055582046509, 0.6875, 0.7048611044883728, 0.7104166746139526, 0.7076388597488403, 0.7166666388511658, 0.7416666746139526, 0.7486110925674438]\n",
      "Precision of Train ......................................\n",
      "[0.5389105081558228, 0.5422045588493347, 0.5638191103935242, 0.5687693953514099, 0.5779625773429871, 0.5909090638160706, 0.594369113445282, 0.5983263850212097, 0.6066452264785767, 0.6217948794364929, 0.6367567777633667, 0.6387377381324768, 0.6377606987953186, 0.6493362784385681, 0.6662908792495728, 0.6692737340927124, 0.6689265370368958, 0.6768707633018494, 0.6990846395492554, 0.7024886608123779]\n",
      "Recall of Train ......................................\n",
      "[0.769444465637207, 0.7583333253860474, 0.7791666388511658, 0.7638888955116272, 0.7722222208976746, 0.7944444417953491, 0.7916666865348816, 0.7944444417953491, 0.7861111164093018, 0.8083333373069763, 0.8180555701255798, 0.8152777552604675, 0.8069444298744202, 0.8152777552604675, 0.8208333253860474, 0.831944465637207, 0.8222222328186035, 0.8291666507720947, 0.8486111164093018, 0.862500011920929]\n",
      "AUC of Train ......................................\n",
      "[0.5967930555343628, 0.6147337555885315, 0.6313532590866089, 0.6415894627571106, 0.6577700972557068, 0.6734423041343689, 0.6819627285003662, 0.6964341998100281, 0.707149863243103, 0.7278723120689392, 0.7449951171875, 0.7519956231117249, 0.7528877854347229, 0.7668218612670898, 0.7847328186035156, 0.7916319370269775, 0.7895717620849609, 0.8034336566925049, 0.8167380690574646, 0.8291898369789124]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.6559375017881394\n",
      " Loss:0.6578315883874893\n",
      " Precision:0.6224618762731552\n",
      " Recall:0.8044444441795349\n",
      " AUC:0.723054975271225\n",
      "Score for fold 1: loss of 0.6376878619194031; accuracy of 0.6972222328186035%\n",
      "[[ 97  83]\n",
      " [ 26 154]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 359.57322639999995 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:97,FN:26,TP:154,FP:83\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6972222222222222\n",
      " Loss:0.6376878619194031\n",
      " Precision:0.6497890295358649\n",
      " Recall:0.8555555555555555\n",
      " AUC:0.8220867208672087\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 19s 363ms/step - loss: 0.6839 - accuracy: 0.5417 - binary_crossentropy: 0.6839 - precision: 0.5526 - recall: 0.5361 - auc: 0.5786\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.6804 - accuracy: 0.5736 - binary_crossentropy: 0.6804 - precision: 0.5832 - recall: 0.5769 - auc: 0.6032\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.6772 - accuracy: 0.5813 - binary_crossentropy: 0.6772 - precision: 0.5899 - recall: 0.5891 - auc: 0.6147\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.6736 - accuracy: 0.5986 - binary_crossentropy: 0.6736 - precision: 0.6037 - recall: 0.6218 - auc: 0.6384\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.6734 - accuracy: 0.5917 - binary_crossentropy: 0.6734 - precision: 0.5984 - recall: 0.6082 - auc: 0.6377\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.6692 - accuracy: 0.6174 - binary_crossentropy: 0.6692 - precision: 0.6237 - recall: 0.6313 - auc: 0.6620\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.6659 - accuracy: 0.6132 - binary_crossentropy: 0.6659 - precision: 0.6156 - recall: 0.6449 - auc: 0.6735\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.6634 - accuracy: 0.6326 - binary_crossentropy: 0.6634 - precision: 0.6307 - recall: 0.6762 - auc: 0.6884\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.6615 - accuracy: 0.6431 - binary_crossentropy: 0.6615 - precision: 0.6418 - recall: 0.6803 - auc: 0.6959\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.6568 - accuracy: 0.6653 - binary_crossentropy: 0.6568 - precision: 0.6595 - recall: 0.7116 - auc: 0.7240\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.6540 - accuracy: 0.6687 - binary_crossentropy: 0.6540 - precision: 0.6671 - recall: 0.7007 - auc: 0.7350\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.6519 - accuracy: 0.6771 - binary_crossentropy: 0.6519 - precision: 0.6675 - recall: 0.7320 - auc: 0.7437\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.6497 - accuracy: 0.6889 - binary_crossentropy: 0.6497 - precision: 0.6810 - recall: 0.7347 - auc: 0.7556\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.6447 - accuracy: 0.7056 - binary_crossentropy: 0.6447 - precision: 0.6966 - recall: 0.7497 - auc: 0.7750\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.6423 - accuracy: 0.6910 - binary_crossentropy: 0.6423 - precision: 0.6812 - recall: 0.7415 - auc: 0.7856\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.6407 - accuracy: 0.7028 - binary_crossentropy: 0.6407 - precision: 0.6902 - recall: 0.7578 - auc: 0.7881\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.6395 - accuracy: 0.7188 - binary_crossentropy: 0.6395 - precision: 0.7022 - recall: 0.7796 - auc: 0.7917\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.6354 - accuracy: 0.7306 - binary_crossentropy: 0.6354 - precision: 0.7171 - recall: 0.7796 - auc: 0.8060\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.6318 - accuracy: 0.7347 - binary_crossentropy: 0.6318 - precision: 0.7193 - recall: 0.7878 - auc: 0.8201\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.6298 - accuracy: 0.7458 - binary_crossentropy: 0.6298 - precision: 0.7309 - recall: 0.7946 - auc: 0.8263\n",
      "Loss of Train ......................................\n",
      "[0.6838779449462891, 0.6803878545761108, 0.6772493720054626, 0.6735622882843018, 0.6734151840209961, 0.6692498326301575, 0.6659320592880249, 0.6633681058883667, 0.6615038514137268, 0.6567999124526978, 0.6539747714996338, 0.6519027948379517, 0.6496701836585999, 0.6446680426597595, 0.6422563195228577, 0.6407195329666138, 0.6395067572593689, 0.635379433631897, 0.6318277716636658, 0.6297751069068909]\n",
      "Accuracy of Train ......................................\n",
      "[0.5416666865348816, 0.5736111402511597, 0.581250011920929, 0.5986111164093018, 0.5916666388511658, 0.6173611283302307, 0.613194465637207, 0.6326388716697693, 0.6430555582046509, 0.6652777791023254, 0.668749988079071, 0.6770833134651184, 0.6888889074325562, 0.7055555582046509, 0.6909722089767456, 0.7027778029441833, 0.71875, 0.730555534362793, 0.7347221970558167, 0.7458333373069763]\n",
      "Precision of Train ......................................\n",
      "[0.5525946617126465, 0.5832186937332153, 0.5899182558059692, 0.6036987900733948, 0.5983935594558716, 0.6236559152603149, 0.6155844330787659, 0.6307106614112854, 0.6418485045433044, 0.6595208048820496, 0.6670984625816345, 0.6674938201904297, 0.6809583902359009, 0.6965866088867188, 0.6812499761581421, 0.6902106404304504, 0.7022058963775635, 0.7171464562416077, 0.7192546725273132, 0.7309136390686035]\n",
      "Recall of Train ......................................\n",
      "[0.5360544323921204, 0.5768707394599915, 0.5891156196594238, 0.6217687129974365, 0.6081632375717163, 0.6312925219535828, 0.6448979377746582, 0.6761904954910278, 0.680272102355957, 0.7115646004676819, 0.7006802558898926, 0.7319728136062622, 0.7346938848495483, 0.7496598362922668, 0.7414966225624084, 0.75782310962677, 0.7795918583869934, 0.7795918583869934, 0.7877551317214966, 0.7945578098297119]\n",
      "AUC of Train ......................................\n",
      "[0.5785680413246155, 0.6032286286354065, 0.6146533489227295, 0.6384387612342834, 0.6376802921295166, 0.6619548797607422, 0.6734983921051025, 0.6883987188339233, 0.695902943611145, 0.7239562273025513, 0.7350306510925293, 0.7437101602554321, 0.7556279301643372, 0.7750383615493774, 0.7856149673461914, 0.7881362438201904, 0.791742205619812, 0.8060105443000793, 0.8201119899749756, 0.8263125419616699]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.6561111122369766\n",
      " Loss:0.6562513560056686\n",
      " Precision:0.6526131421327591\n",
      " Recall:0.691700679063797\n",
      " AUC:0.7171807914972306\n",
      "Score for fold 2: loss of 0.6340036988258362; accuracy of 0.7527777552604675%\n",
      "[[139  56]\n",
      " [ 33 132]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 714.5834226000001 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:139,FN:33,TP:132,FP:56\n",
      "Test of epochs .................................\n",
      " Accuracy:0.7527777777777778\n",
      " Loss:0.6340036988258362\n",
      " Precision:0.7021276595744681\n",
      " Recall:0.8\n",
      " AUC:0.8040697674418604\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 21s 414ms/step - loss: 0.7228 - accuracy: 0.4229 - binary_crossentropy: 0.7228 - precision: 0.4193 - recall: 0.4340 - auc: 0.3695\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.7194 - accuracy: 0.4306 - binary_crossentropy: 0.7194 - precision: 0.4260 - recall: 0.4368 - auc: 0.3876\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.7161 - accuracy: 0.4326 - binary_crossentropy: 0.7161 - precision: 0.4293 - recall: 0.4480 - auc: 0.4026\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.7126 - accuracy: 0.4437 - binary_crossentropy: 0.7126 - precision: 0.4386 - recall: 0.4466 - auc: 0.4239\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.7126 - accuracy: 0.4500 - binary_crossentropy: 0.7126 - precision: 0.4455 - recall: 0.4593 - auc: 0.4210\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.7077 - accuracy: 0.4681 - binary_crossentropy: 0.7077 - precision: 0.4633 - recall: 0.4789 - auc: 0.4458\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.7055 - accuracy: 0.4819 - binary_crossentropy: 0.7055 - precision: 0.4768 - recall: 0.4916 - auc: 0.4600\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.7026 - accuracy: 0.4875 - binary_crossentropy: 0.7026 - precision: 0.4821 - recall: 0.4916 - auc: 0.4781\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.7005 - accuracy: 0.5014 - binary_crossentropy: 0.7005 - precision: 0.4958 - recall: 0.5014 - auc: 0.4906\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.6953 - accuracy: 0.5174 - binary_crossentropy: 0.6953 - precision: 0.5116 - recall: 0.5267 - auc: 0.5202\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.6943 - accuracy: 0.5139 - binary_crossentropy: 0.6943 - precision: 0.5083 - recall: 0.5183 - auc: 0.5239\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.6913 - accuracy: 0.5312 - binary_crossentropy: 0.6913 - precision: 0.5255 - recall: 0.5351 - auc: 0.5459\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.6870 - accuracy: 0.5500 - binary_crossentropy: 0.6870 - precision: 0.5432 - recall: 0.5646 - auc: 0.5682\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.6857 - accuracy: 0.5542 - binary_crossentropy: 0.6857 - precision: 0.5482 - recall: 0.5590 - auc: 0.5766\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.6829 - accuracy: 0.5667 - binary_crossentropy: 0.6829 - precision: 0.5608 - recall: 0.5702 - auc: 0.5931\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.6802 - accuracy: 0.5743 - binary_crossentropy: 0.6802 - precision: 0.5694 - recall: 0.5702 - auc: 0.6068\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.6771 - accuracy: 0.5785 - binary_crossentropy: 0.6771 - precision: 0.5720 - recall: 0.5857 - auc: 0.6199\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.6740 - accuracy: 0.6056 - binary_crossentropy: 0.6740 - precision: 0.5984 - recall: 0.6152 - auc: 0.6402\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.6728 - accuracy: 0.6021 - binary_crossentropy: 0.6728 - precision: 0.5943 - recall: 0.6152 - auc: 0.6493\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.6711 - accuracy: 0.6160 - binary_crossentropy: 0.6711 - precision: 0.6103 - recall: 0.6180 - auc: 0.6562\n",
      "Loss of Train ......................................\n",
      "[0.7228164076805115, 0.7193754315376282, 0.7160525918006897, 0.7126284241676331, 0.7125870585441589, 0.707713782787323, 0.7055088877677917, 0.7025816440582275, 0.7004839777946472, 0.6952775716781616, 0.6943342685699463, 0.6913269758224487, 0.6869670748710632, 0.6856616735458374, 0.6829186081886292, 0.6801977157592773, 0.6770557165145874, 0.6739739179611206, 0.672849178314209, 0.671114444732666]\n",
      "Accuracy of Train ......................................\n",
      "[0.4229166805744171, 0.4305555522441864, 0.43263888359069824, 0.4437499940395355, 0.44999998807907104, 0.4680555462837219, 0.4819444417953491, 0.48750001192092896, 0.5013889074325562, 0.5173611044883728, 0.5138888955116272, 0.53125, 0.550000011920929, 0.5541666746139526, 0.5666666626930237, 0.574305534362793, 0.5784721970558167, 0.605555534362793, 0.6020833253860474, 0.6159722208976746]\n",
      "Precision of Train ......................................\n",
      "[0.41926729679107666, 0.4260273873806, 0.42934051156044006, 0.4386206865310669, 0.4455040991306305, 0.4633152186870575, 0.47683924436569214, 0.4820936620235443, 0.4958333373069763, 0.5115962028503418, 0.5082644820213318, 0.5255172252655029, 0.5432432293891907, 0.5482093691825867, 0.560773491859436, 0.5694249868392944, 0.5720164775848389, 0.5983606576919556, 0.5943012237548828, 0.6102635264396667]\n",
      "Recall of Train ......................................\n",
      "[0.4339887499809265, 0.43679773807525635, 0.44803372025489807, 0.44662922620773315, 0.4592696726322174, 0.47893258929252625, 0.4915730357170105, 0.4915730357170105, 0.5014045238494873, 0.5266854166984558, 0.5182584524154663, 0.5351123809814453, 0.5646067261695862, 0.5589887499809265, 0.5702247023582458, 0.5702247023582458, 0.5856741666793823, 0.6151685118675232, 0.6151685118675232, 0.617977499961853]\n",
      "AUC of Train ......................................\n",
      "[0.36950743198394775, 0.38757675886154175, 0.40258151292800903, 0.4238640367984772, 0.420968234539032, 0.44582661986351013, 0.46003463864326477, 0.4781164824962616, 0.490633487701416, 0.5201693177223206, 0.523876428604126, 0.5459479689598083, 0.568200945854187, 0.5765728950500488, 0.5930564403533936, 0.6068129539489746, 0.6198527812957764, 0.6401870846748352, 0.6493056416511536, 0.6561998128890991]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.5164236083626748\n",
      " Loss:0.6955712676048279\n",
      " Precision:0.5109406158328056\n",
      " Recall:0.523314605653286\n",
      " AUC:0.5189645737409592\n",
      "Score for fold 3: loss of 0.6649588942527771; accuracy of 0.6388888955116272%\n",
      "[[105  67]\n",
      " [ 63 125]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1081.9786896 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:105,FN:63,TP:125,FP:67\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6388888888888888\n",
      " Loss:0.6649588942527771\n",
      " Precision:0.6510416666666666\n",
      " Recall:0.6648936170212766\n",
      " AUC:0.6449468085106382\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 21s 408ms/step - loss: 0.7141 - accuracy: 0.4382 - binary_crossentropy: 0.7141 - precision: 0.4555 - recall: 0.7221 - auc: 0.4174\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.7114 - accuracy: 0.4583 - binary_crossentropy: 0.7114 - precision: 0.4675 - recall: 0.7207 - auc: 0.4341\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.7059 - accuracy: 0.4722 - binary_crossentropy: 0.7059 - precision: 0.4762 - recall: 0.7207 - auc: 0.4685\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.7042 - accuracy: 0.4826 - binary_crossentropy: 0.7042 - precision: 0.4829 - recall: 0.7165 - auc: 0.4782\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 18s 395ms/step - loss: 0.7013 - accuracy: 0.4840 - binary_crossentropy: 0.7013 - precision: 0.4841 - recall: 0.7306 - auc: 0.4916\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.6967 - accuracy: 0.5000 - binary_crossentropy: 0.6967 - precision: 0.4948 - recall: 0.7405 - auc: 0.5170\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.6954 - accuracy: 0.5181 - binary_crossentropy: 0.6954 - precision: 0.5071 - recall: 0.7532 - auc: 0.5281\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.6920 - accuracy: 0.5069 - binary_crossentropy: 0.6920 - precision: 0.4995 - recall: 0.7250 - auc: 0.5454\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.6876 - accuracy: 0.5285 - binary_crossentropy: 0.6876 - precision: 0.5145 - recall: 0.7489 - auc: 0.5747\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.6861 - accuracy: 0.5361 - binary_crossentropy: 0.6861 - precision: 0.5202 - recall: 0.7461 - auc: 0.5815\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.6825 - accuracy: 0.5576 - binary_crossentropy: 0.6825 - precision: 0.5357 - recall: 0.7616 - auc: 0.6030\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.6817 - accuracy: 0.5549 - binary_crossentropy: 0.6817 - precision: 0.5341 - recall: 0.7504 - auc: 0.6033\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.6779 - accuracy: 0.5743 - binary_crossentropy: 0.6779 - precision: 0.5486 - recall: 0.7645 - auc: 0.6269\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.6749 - accuracy: 0.5806 - binary_crossentropy: 0.6749 - precision: 0.5536 - recall: 0.7645 - auc: 0.6448\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.6717 - accuracy: 0.6132 - binary_crossentropy: 0.6717 - precision: 0.5793 - recall: 0.7828 - auc: 0.6699\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.6706 - accuracy: 0.6104 - binary_crossentropy: 0.6706 - precision: 0.5764 - recall: 0.7870 - auc: 0.6711\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.6673 - accuracy: 0.6215 - binary_crossentropy: 0.6673 - precision: 0.5863 - recall: 0.7856 - auc: 0.6897\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.6647 - accuracy: 0.6319 - binary_crossentropy: 0.6647 - precision: 0.5945 - recall: 0.7941 - auc: 0.7040\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.6625 - accuracy: 0.6410 - binary_crossentropy: 0.6625 - precision: 0.6015 - recall: 0.8025 - auc: 0.7137\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.6581 - accuracy: 0.6562 - binary_crossentropy: 0.6581 - precision: 0.6131 - recall: 0.8181 - auc: 0.7390\n",
      "Loss of Train ......................................\n",
      "[0.7141464352607727, 0.711366593837738, 0.7059310078620911, 0.7042093276977539, 0.7012733817100525, 0.696664571762085, 0.6954352259635925, 0.692001223564148, 0.6875897645950317, 0.6860824823379517, 0.68248450756073, 0.6816967725753784, 0.6779115796089172, 0.6749120354652405, 0.6717249155044556, 0.670569121837616, 0.6673429012298584, 0.6647170186042786, 0.6625164747238159, 0.658121645450592]\n",
      "Accuracy of Train ......................................\n",
      "[0.4381944537162781, 0.4583333432674408, 0.4722222089767456, 0.4826388955116272, 0.48402777314186096, 0.5, 0.5180555582046509, 0.5069444179534912, 0.5284722447395325, 0.5361111164093018, 0.5576388835906982, 0.5548611283302307, 0.574305534362793, 0.5805555582046509, 0.613194465637207, 0.6104166507720947, 0.6215277910232544, 0.6319444179534912, 0.6409721970558167, 0.65625]\n",
      "Precision of Train ......................................\n",
      "[0.4555160105228424, 0.4675205945968628, 0.4762348532676697, 0.48288974165916443, 0.4841121435165405, 0.49481621384620667, 0.5071225166320801, 0.499514102935791, 0.5145348906517029, 0.5201573371887207, 0.5357142686843872, 0.5341365337371826, 0.5485829710960388, 0.5536261200904846, 0.5793319344520569, 0.5764462947845459, 0.5863158106803894, 0.594508945941925, 0.6014798879623413, 0.6131078004837036]\n",
      "Recall of Train ......................................\n",
      "[0.7221438884735107, 0.7207334041595459, 0.7207334041595459, 0.7165021300315857, 0.7306064963340759, 0.7404795289039612, 0.7531734704971313, 0.7249647378921509, 0.7489421963691711, 0.7461212873458862, 0.7616360783576965, 0.7503526210784912, 0.7644569873809814, 0.7644569873809814, 0.7827926874160767, 0.7870239615440369, 0.7856135368347168, 0.794076144695282, 0.8025388121604919, 0.8180536031723022]\n",
      "AUC of Train ......................................\n",
      "[0.41739973425865173, 0.43413296341896057, 0.4684928357601166, 0.47816237807273865, 0.4915653467178345, 0.5170285105705261, 0.5280852913856506, 0.5453510880470276, 0.5746943354606628, 0.5815274715423584, 0.6029946804046631, 0.6033034324645996, 0.6269094347953796, 0.6448466777801514, 0.6699142456054688, 0.6710999011993408, 0.6897106170654297, 0.7039981484413147, 0.7137218117713928, 0.7389639616012573]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.5483333319425583\n",
      " Loss:0.685334849357605\n",
      " Precision:0.5312834486365319\n",
      " Recall:0.7567700982093811\n",
      " AUC:0.5850951433181762\n",
      "Score for fold 4: loss of 0.6620333194732666; accuracy of 0.6416666507720947%\n",
      "[[ 88  81]\n",
      " [ 48 143]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1452.2885747 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:88,FN:48,TP:143,FP:81\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6416666666666667\n",
      " Loss:0.6620333194732666\n",
      " Precision:0.6383928571428571\n",
      " Recall:0.7486910994764397\n",
      " AUC:0.6978749615029258\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 21s 402ms/step - loss: 0.7218 - accuracy: 0.4875 - binary_crossentropy: 0.7218 - precision: 0.3542 - recall: 0.0235 - auc: 0.4798\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.7174 - accuracy: 0.4951 - binary_crossentropy: 0.7174 - precision: 0.4795 - recall: 0.0483 - auc: 0.4851\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.7119 - accuracy: 0.4882 - binary_crossentropy: 0.7119 - precision: 0.3860 - recall: 0.0304 - auc: 0.5106\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.7053 - accuracy: 0.4882 - binary_crossentropy: 0.7053 - precision: 0.4198 - recall: 0.0470 - auc: 0.5377\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.7025 - accuracy: 0.4958 - binary_crossentropy: 0.7025 - precision: 0.4878 - recall: 0.0552 - auc: 0.5466\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.6953 - accuracy: 0.5042 - binary_crossentropy: 0.6953 - precision: 0.5521 - recall: 0.0732 - auc: 0.5819\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.6903 - accuracy: 0.5146 - binary_crossentropy: 0.6903 - precision: 0.6087 - recall: 0.0967 - auc: 0.6025\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.6872 - accuracy: 0.5160 - binary_crossentropy: 0.6872 - precision: 0.6047 - recall: 0.1077 - auc: 0.6143\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.6823 - accuracy: 0.5264 - binary_crossentropy: 0.6823 - precision: 0.6419 - recall: 0.1312 - auc: 0.6364\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.6800 - accuracy: 0.5417 - binary_crossentropy: 0.6800 - precision: 0.7105 - recall: 0.1492 - auc: 0.6417\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.6757 - accuracy: 0.5292 - binary_crossentropy: 0.6757 - precision: 0.6322 - recall: 0.1519 - auc: 0.6696\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.6718 - accuracy: 0.5472 - binary_crossentropy: 0.6718 - precision: 0.6818 - recall: 0.1865 - auc: 0.6806\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.6714 - accuracy: 0.5743 - binary_crossentropy: 0.6714 - precision: 0.7581 - recall: 0.2251 - auc: 0.6839\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.6668 - accuracy: 0.5785 - binary_crossentropy: 0.6668 - precision: 0.7577 - recall: 0.2376 - auc: 0.7090\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.6611 - accuracy: 0.5771 - binary_crossentropy: 0.6611 - precision: 0.7273 - recall: 0.2541 - auc: 0.7318\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.6591 - accuracy: 0.6097 - binary_crossentropy: 0.6591 - precision: 0.7914 - recall: 0.3039 - auc: 0.7385\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.6552 - accuracy: 0.6125 - binary_crossentropy: 0.6552 - precision: 0.7943 - recall: 0.3094 - auc: 0.7586\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.6540 - accuracy: 0.6187 - binary_crossentropy: 0.6540 - precision: 0.7832 - recall: 0.3343 - auc: 0.7624\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.6500 - accuracy: 0.6354 - binary_crossentropy: 0.6500 - precision: 0.7988 - recall: 0.3674 - auc: 0.7767\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.6461 - accuracy: 0.6451 - binary_crossentropy: 0.6461 - precision: 0.8198 - recall: 0.3771 - auc: 0.7935\n",
      "Loss of Train ......................................\n",
      "[0.7217849493026733, 0.7174431681632996, 0.7118505835533142, 0.7053383588790894, 0.702491819858551, 0.6953483819961548, 0.6902702450752258, 0.6871526837348938, 0.6822673082351685, 0.6799606084823608, 0.6756964325904846, 0.6717976927757263, 0.6713963150978088, 0.666754424571991, 0.6611255407333374, 0.6590834259986877, 0.6552025079727173, 0.6539521217346191, 0.6500399112701416, 0.6460666656494141]\n",
      "Accuracy of Train ......................................\n",
      "[0.48750001192092896, 0.49513888359069824, 0.48819443583488464, 0.48819443583488464, 0.4958333373069763, 0.5041666626930237, 0.5145833492279053, 0.5159721970558167, 0.5263888835906982, 0.5416666865348816, 0.5291666388511658, 0.5472221970558167, 0.574305534362793, 0.5784721970558167, 0.5770833492279053, 0.6097221970558167, 0.612500011920929, 0.6187499761581421, 0.6354166865348816, 0.6451388597488403]\n",
      "Precision of Train ......................................\n",
      "[0.3541666567325592, 0.4794520437717438, 0.38596490025520325, 0.4197530746459961, 0.4878048896789551, 0.5520833134651184, 0.6086956262588501, 0.604651153087616, 0.6418918967247009, 0.7105262875556946, 0.6321839094161987, 0.6818181872367859, 0.7581395506858826, 0.757709264755249, 0.7272727489471436, 0.7913669347763062, 0.7943262457847595, 0.783171534538269, 0.7987987995147705, 0.8198198080062866]\n",
      "Recall of Train ......................................\n",
      "[0.02348066307604313, 0.048342540860176086, 0.03038674034178257, 0.04696132615208626, 0.05524861812591553, 0.0732044205069542, 0.09668508172035217, 0.1077348068356514, 0.13121546804904938, 0.14917127788066864, 0.1519336998462677, 0.1864640861749649, 0.2251381278038025, 0.23756906390190125, 0.2541436553001404, 0.3038673996925354, 0.3093922734260559, 0.3342541456222534, 0.3674033284187317, 0.3770718276500702]\n",
      "AUC of Train ......................................\n",
      "[0.479792982339859, 0.48511049151420593, 0.5105896592140198, 0.5376555323600769, 0.5466392040252686, 0.5818968415260315, 0.6024829745292664, 0.614296555519104, 0.636374831199646, 0.6416700482368469, 0.6695519089698792, 0.680592954158783, 0.6838743090629578, 0.7089734077453613, 0.7317654490470886, 0.7384766936302185, 0.7585902214050293, 0.7624000906944275, 0.7767041325569153, 0.7935429811477661]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.5492708265781403\n",
      " Loss:0.6802511572837829\n",
      " Precision:0.6394798412919045\n",
      " Recall:0.17548342756927013\n",
      " AUC:0.6470490634441376\n",
      "Score for fold 5: loss of 0.635708212852478; accuracy of 0.6472222208976746%\n",
      "[[175   9]\n",
      " [118  58]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1825.6684533 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:175,FN:118,TP:58,FP:9\n",
      "Test of epochs .................................\n",
      " Accuracy:0.6472222222222223\n",
      " Loss:0.635708212852478\n",
      " Precision:0.8656716417910447\n",
      " Recall:0.32954545454545453\n",
      " AUC:0.4634075395594167\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.6559375017881394 - Loss: 0.6578315883874893\n",
      "> Fold 1 - Precision: 0.6224618762731552\n",
      "> Fold 1 - Recall: 0.8044444441795349\n",
      "> Fold 1 - AUC: 0.723054975271225\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.6972222222222222 - Loss: 0.6376878619194031\n",
      "> Fold 1 - Precision: 0.6497890295358649\n",
      "> Fold 1 - Recall: 0.8555555555555555\n",
      "> Fold 1 - AUC: 0.8220867208672087\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.6561111122369766 - Loss: 0.6562513560056686\n",
      "> Fold 2 - Precision: 0.6526131421327591\n",
      "> Fold 2 - Recall: 0.691700679063797\n",
      "> Fold 2 - AUC: 0.7171807914972306\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.7527777777777778 - Loss: 0.6340036988258362\n",
      "> Fold 2 - Precision: 0.7021276595744681\n",
      "> Fold 2 - Recall: 0.8\n",
      "> Fold 2 - AUC: 0.8040697674418604\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.5164236083626748 - Loss: 0.6955712676048279\n",
      "> Fold 3 - Precision: 0.5109406158328056\n",
      "> Fold 3 - Recall: 0.523314605653286\n",
      "> Fold 3 - AUC: 0.5189645737409592\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.6388888888888888 - Loss: 0.6649588942527771\n",
      "> Fold 3 - Precision: 0.6510416666666666\n",
      "> Fold 3 - Recall: 0.6648936170212766\n",
      "> Fold 3 - AUC: 0.6449468085106382\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.5483333319425583 - Loss: 0.685334849357605\n",
      "> Fold 4 - Precision: 0.5312834486365319\n",
      "> Fold 4 - Recall: 0.7567700982093811\n",
      "> Fold 4 - AUC: 0.5850951433181762\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.6416666666666667 - Loss: 0.6620333194732666\n",
      "> Fold 4 - Precision: 0.6383928571428571\n",
      "> Fold 4 - Recall: 0.7486910994764397\n",
      "> Fold 4 - AUC: 0.6978749615029258\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.5492708265781403 - Loss: 0.6802511572837829\n",
      "> Fold 5 - Precision: 0.6394798412919045\n",
      "> Fold 5 - Recall: 0.17548342756927013\n",
      "> Fold 5 - AUC: 0.6470490634441376\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.6472222222222223 - Loss: 0.635708212852478\n",
      "> Fold 5 - Precision: 0.8656716417910447\n",
      "> Fold 5 - Recall: 0.32954545454545453\n",
      "> Fold 5 - AUC: 0.4634075395594167\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.5852152761816978 (+- 0.05901258779987517)\n",
      "> Loss: 0.6750480437278747 (+- 0.01551654138560965)\n",
      "> Precision: 0.5913557848334312 (+- 0.0585000214350812)\n",
      "> Recall: 0.5903426509350538 (+- 0.22821571243402788)\n",
      "> AUC: 0.6382689094543457 (+- 0.0781713849352246)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.6755555555555555 (+- 0.04410985164728712)\n",
      "> Loss: 0.6468783974647522 (+- 0.013649709580144564)\n",
      "> Precision: 0.7014045709421802 (+- 0.08503558753850697)\n",
      "> Recall: 0.6797371453197452 (+- 0.18600240106366325)\n",
      "> AUC: 0.6864771595764101 (+- 0.12948568249888373)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 604 FN SUM: 288 TP SUM: 612 FP SUM: 296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(Xception(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70452a6",
   "metadata": {},
   "source": [
    "# MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b412c9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 13s 154ms/step - loss: 0.8260 - accuracy: 0.5118 - binary_crossentropy: 0.8260 - precision: 0.5968 - recall: 0.0517 - auc: 0.5508\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.6953 - accuracy: 0.5701 - binary_crossentropy: 0.6953 - precision: 0.8288 - recall: 0.1692 - auc: 0.7141\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 7s 153ms/step - loss: 0.5996 - accuracy: 0.6611 - binary_crossentropy: 0.5996 - precision: 0.8955 - recall: 0.3594 - auc: 0.8204\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.5279 - accuracy: 0.7389 - binary_crossentropy: 0.5279 - precision: 0.9227 - recall: 0.5175 - auc: 0.8912\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.4708 - accuracy: 0.7882 - binary_crossentropy: 0.4708 - precision: 0.9271 - recall: 0.6224 - auc: 0.9306\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.4248 - accuracy: 0.8514 - binary_crossentropy: 0.4248 - precision: 0.9434 - recall: 0.7455 - auc: 0.9537\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.3853 - accuracy: 0.8854 - binary_crossentropy: 0.3853 - precision: 0.9599 - recall: 0.8028 - auc: 0.9694\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.3589 - accuracy: 0.9097 - binary_crossentropy: 0.3589 - precision: 0.9563 - recall: 0.8573 - auc: 0.9741\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.3325 - accuracy: 0.9319 - binary_crossentropy: 0.3325 - precision: 0.9625 - recall: 0.8979 - auc: 0.9813\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.3015 - accuracy: 0.9486 - binary_crossentropy: 0.3015 - precision: 0.9679 - recall: 0.9273 - auc: 0.9902\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.2871 - accuracy: 0.9438 - binary_crossentropy: 0.2871 - precision: 0.9608 - recall: 0.9245 - auc: 0.9898\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.2712 - accuracy: 0.9528 - binary_crossentropy: 0.2712 - precision: 0.9602 - recall: 0.9441 - auc: 0.9923\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 174ms/step - loss: 0.2586 - accuracy: 0.9535 - binary_crossentropy: 0.2586 - precision: 0.9655 - recall: 0.9399 - auc: 0.9924\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.2396 - accuracy: 0.9618 - binary_crossentropy: 0.2396 - precision: 0.9661 - recall: 0.9566 - auc: 0.9936\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.2299 - accuracy: 0.9681 - binary_crossentropy: 0.2299 - precision: 0.9678 - recall: 0.9678 - auc: 0.9950\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 180ms/step - loss: 0.2215 - accuracy: 0.9667 - binary_crossentropy: 0.2215 - precision: 0.9691 - recall: 0.9636 - auc: 0.9945\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 180ms/step - loss: 0.2138 - accuracy: 0.9694 - binary_crossentropy: 0.2138 - precision: 0.9732 - recall: 0.9650 - auc: 0.9951\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 176ms/step - loss: 0.2028 - accuracy: 0.9750 - binary_crossentropy: 0.2028 - precision: 0.9802 - recall: 0.9692 - auc: 0.9964\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 181ms/step - loss: 0.1904 - accuracy: 0.9736 - binary_crossentropy: 0.1904 - precision: 0.9748 - recall: 0.9720 - auc: 0.9969\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.1845 - accuracy: 0.9736 - binary_crossentropy: 0.1845 - precision: 0.9695 - recall: 0.9776 - auc: 0.9971\n",
      "Loss of Train ......................................\n",
      "[0.8260144591331482, 0.6953147649765015, 0.5996042490005493, 0.527911901473999, 0.4708169400691986, 0.42484772205352783, 0.3853265643119812, 0.3589293956756592, 0.3325381278991699, 0.3015470504760742, 0.2870732545852661, 0.2711920440196991, 0.25860387086868286, 0.23959822952747345, 0.22993794083595276, 0.2214670181274414, 0.21376369893550873, 0.20281736552715302, 0.190449059009552, 0.1844603717327118]\n",
      "Accuracy of Train ......................................\n",
      "[0.511805534362793, 0.5701388716697693, 0.6611111164093018, 0.7388888597488403, 0.7881944179534912, 0.8513888716697693, 0.8854166865348816, 0.9097222089767456, 0.9319444298744202, 0.9486111402511597, 0.9437500238418579, 0.9527778029441833, 0.9534721970558167, 0.9618055820465088, 0.9680555462837219, 0.9666666388511658, 0.9694444537162781, 0.9750000238418579, 0.9736111164093018, 0.9736111164093018]\n",
      "Precision of Train ......................................\n",
      "[0.5967742204666138, 0.8287671208381653, 0.895470380783081, 0.9226932525634766, 0.9270833134651184, 0.943362832069397, 0.9598662257194519, 0.9563182592391968, 0.9625187516212463, 0.9678832292556763, 0.9607558250427246, 0.9601706862449646, 0.9655172228813171, 0.9661017060279846, 0.9678321480751038, 0.9690576791763306, 0.9732016921043396, 0.9801980257034302, 0.9747545719146729, 0.9694868326187134]\n",
      "Recall of Train ......................................\n",
      "[0.05174825340509415, 0.16923077404499054, 0.35944056510925293, 0.5174825191497803, 0.6223776340484619, 0.7454545497894287, 0.8027971982955933, 0.8573426604270935, 0.8979020714759827, 0.9272727370262146, 0.9244755506515503, 0.9440559148788452, 0.9398601651191711, 0.9566433429718018, 0.9678321480751038, 0.9636363387107849, 0.9650349617004395, 0.9692307710647583, 0.9720279574394226, 0.977622389793396]\n",
      "AUC of Train ......................................\n",
      "[0.5508029460906982, 0.7141326069831848, 0.8204445838928223, 0.8912447094917297, 0.9306331872940063, 0.9537120461463928, 0.9694371819496155, 0.9740757346153259, 0.9812867641448975, 0.9902300238609314, 0.9898287653923035, 0.9923222064971924, 0.9924032092094421, 0.9935674071311951, 0.9949660897254944, 0.9944885969161987, 0.9951232671737671, 0.9964108467102051, 0.9968622922897339, 0.997123658657074]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8717708319425583\n",
      " Loss:0.3611107014119625\n",
      " Precision:0.9323906987905503\n",
      " Recall:0.7765734251588583\n",
      " AUC:0.9359548062086105\n",
      "Score for fold 1: loss of 0.4266618490219116; accuracy of 0.8444444537162781%\n",
      "[[166   9]\n",
      " [ 47 138]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 170.172026 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:166,FN:47,TP:138,FP:9\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8444444444444444\n",
      " Loss:0.4266618490219116\n",
      " Precision:0.9387755102040817\n",
      " Recall:0.745945945945946\n",
      " AUC:0.7626443344753204\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_1 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 159ms/step - loss: 0.7159 - accuracy: 0.5500 - binary_crossentropy: 0.7159 - precision: 0.6238 - recall: 0.2676 - auc: 0.5956\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.6441 - accuracy: 0.6340 - binary_crossentropy: 0.6441 - precision: 0.7450 - recall: 0.4152 - auc: 0.7090\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 8s 180ms/step - loss: 0.5777 - accuracy: 0.6951 - binary_crossentropy: 0.5777 - precision: 0.7918 - recall: 0.5352 - auc: 0.8019\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.5195 - accuracy: 0.7708 - binary_crossentropy: 0.5195 - precision: 0.8546 - recall: 0.6566 - auc: 0.8771\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 8s 182ms/step - loss: 0.4781 - accuracy: 0.8194 - binary_crossentropy: 0.4781 - precision: 0.8818 - recall: 0.7407 - auc: 0.9146\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 180ms/step - loss: 0.4381 - accuracy: 0.8625 - binary_crossentropy: 0.4381 - precision: 0.9060 - recall: 0.8110 - auc: 0.9439\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 8s 183ms/step - loss: 0.4163 - accuracy: 0.8750 - binary_crossentropy: 0.4163 - precision: 0.9073 - recall: 0.8372 - auc: 0.9571\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 180ms/step - loss: 0.3785 - accuracy: 0.9069 - binary_crossentropy: 0.3785 - precision: 0.9365 - recall: 0.8745 - auc: 0.9735\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 8s 187ms/step - loss: 0.3567 - accuracy: 0.9278 - binary_crossentropy: 0.3567 - precision: 0.9417 - recall: 0.9131 - auc: 0.9796\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 8s 185ms/step - loss: 0.3369 - accuracy: 0.9326 - binary_crossentropy: 0.3369 - precision: 0.9435 - recall: 0.9214 - auc: 0.9816\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 8s 185ms/step - loss: 0.3167 - accuracy: 0.9403 - binary_crossentropy: 0.3167 - precision: 0.9431 - recall: 0.9379 - auc: 0.9878\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 178ms/step - loss: 0.2907 - accuracy: 0.9500 - binary_crossentropy: 0.2907 - precision: 0.9466 - recall: 0.9545 - auc: 0.9930\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 180ms/step - loss: 0.2775 - accuracy: 0.9597 - binary_crossentropy: 0.2775 - precision: 0.9651 - recall: 0.9545 - auc: 0.9924\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 173ms/step - loss: 0.2742 - accuracy: 0.9521 - binary_crossentropy: 0.2742 - precision: 0.9530 - recall: 0.9517 - auc: 0.9918\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.2603 - accuracy: 0.9604 - binary_crossentropy: 0.2603 - precision: 0.9652 - recall: 0.9559 - auc: 0.9941\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 182ms/step - loss: 0.2412 - accuracy: 0.9701 - binary_crossentropy: 0.2412 - precision: 0.9736 - recall: 0.9669 - auc: 0.9963\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 185ms/step - loss: 0.2345 - accuracy: 0.9653 - binary_crossentropy: 0.2345 - precision: 0.9579 - recall: 0.9738 - auc: 0.9945\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 184ms/step - loss: 0.2131 - accuracy: 0.9750 - binary_crossentropy: 0.2131 - precision: 0.9713 - recall: 0.9793 - auc: 0.9982\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 174ms/step - loss: 0.2150 - accuracy: 0.9743 - binary_crossentropy: 0.2150 - precision: 0.9674 - recall: 0.9821 - auc: 0.9966\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 173ms/step - loss: 0.2062 - accuracy: 0.9729 - binary_crossentropy: 0.2062 - precision: 0.9725 - recall: 0.9738 - auc: 0.9973\n",
      "Loss of Train ......................................\n",
      "[0.71586012840271, 0.6441054940223694, 0.5777263045310974, 0.5194742679595947, 0.4780661165714264, 0.43811237812042236, 0.41629558801651, 0.37854063510894775, 0.356739342212677, 0.3368742763996124, 0.3167281150817871, 0.2906894087791443, 0.2774593234062195, 0.2741656005382538, 0.2603362798690796, 0.24120201170444489, 0.2344980239868164, 0.21306854486465454, 0.21495983004570007, 0.2062024027109146]\n",
      "Accuracy of Train ......................................\n",
      "[0.550000011920929, 0.6340277791023254, 0.6951388716697693, 0.7708333134651184, 0.8194444179534912, 0.862500011920929, 0.875, 0.9069444537162781, 0.9277777671813965, 0.9326388835906982, 0.9402777552604675, 0.949999988079071, 0.9597222208976746, 0.9520833492279053, 0.9604166746139526, 0.9701389074325562, 0.9652777910232544, 0.9750000238418579, 0.9743055701255798, 0.9729166626930237]\n",
      "Precision of Train ......................................\n",
      "[0.6237941980361938, 0.7450494766235352, 0.7918367385864258, 0.8545780777931213, 0.8817734122276306, 0.9060092568397522, 0.9073243737220764, 0.9364845156669617, 0.941678524017334, 0.9435028433799744, 0.9431345462799072, 0.9466484189033508, 0.965132474899292, 0.9530386924743652, 0.9651810526847839, 0.9736111164093018, 0.9579375982284546, 0.9712722301483154, 0.967391312122345, 0.9724518060684204]\n",
      "Recall of Train ......................................\n",
      "[0.26758620142936707, 0.41517242789268494, 0.5351724028587341, 0.656551718711853, 0.7406896352767944, 0.8110345005989075, 0.8372413516044617, 0.8744827508926392, 0.913103461265564, 0.9213793277740479, 0.9379310607910156, 0.9544827342033386, 0.9544827342033386, 0.951724112033844, 0.9558620452880859, 0.9668965339660645, 0.973793089389801, 0.9793103337287903, 0.9820689558982849, 0.973793089389801]\n",
      "AUC of Train ......................................\n",
      "[0.5956152081489563, 0.7090474963188171, 0.8019474148750305, 0.8771015405654907, 0.9146370887756348, 0.9438968300819397, 0.9571265578269958, 0.973466157913208, 0.9795601963996887, 0.9815769791603088, 0.9878418445587158, 0.9930117726325989, 0.9924108386039734, 0.991806149482727, 0.9941123723983765, 0.9963164329528809, 0.9945387244224548, 0.9981615543365479, 0.9966491460800171, 0.9973021745681763]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8797222226858139\n",
      " Loss:0.3695552036166191\n",
      " Precision:0.9073915332555771\n",
      " Recall:0.8301379233598709\n",
      " AUC:0.933806324005127\n",
      "Score for fold 2: loss of 0.35652458667755127; accuracy of 0.894444465637207%\n",
      "[[161  24]\n",
      " [ 14 161]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 338.6767333 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:161,FN:14,TP:161,FP:24\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8944444444444445\n",
      " Loss:0.35652458667755127\n",
      " Precision:0.8702702702702703\n",
      " Recall:0.92\n",
      " AUC:0.92\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 165ms/step - loss: 0.7161 - accuracy: 0.5333 - binary_crossentropy: 0.7161 - precision: 0.5392 - recall: 0.4583 - auc: 0.5480\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.6358 - accuracy: 0.6458 - binary_crossentropy: 0.6358 - precision: 0.6625 - recall: 0.5944 - auc: 0.6904\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 8s 176ms/step - loss: 0.5772 - accuracy: 0.7160 - binary_crossentropy: 0.5772 - precision: 0.7480 - recall: 0.6514 - auc: 0.7886\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 8s 181ms/step - loss: 0.5339 - accuracy: 0.7646 - binary_crossentropy: 0.5339 - precision: 0.7882 - recall: 0.7236 - auc: 0.8474\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.4869 - accuracy: 0.8215 - binary_crossentropy: 0.4869 - precision: 0.8440 - recall: 0.7889 - auc: 0.8985\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 176ms/step - loss: 0.4519 - accuracy: 0.8528 - binary_crossentropy: 0.4519 - precision: 0.8608 - recall: 0.8417 - auc: 0.9290\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.4294 - accuracy: 0.8701 - binary_crossentropy: 0.4294 - precision: 0.8891 - recall: 0.8458 - auc: 0.9426\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 179ms/step - loss: 0.4035 - accuracy: 0.8924 - binary_crossentropy: 0.4035 - precision: 0.8951 - recall: 0.8889 - auc: 0.9579\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 8s 180ms/step - loss: 0.3725 - accuracy: 0.9097 - binary_crossentropy: 0.3725 - precision: 0.9167 - recall: 0.9014 - auc: 0.9718\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.3502 - accuracy: 0.9208 - binary_crossentropy: 0.3502 - precision: 0.9232 - recall: 0.9181 - auc: 0.9781\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 8s 182ms/step - loss: 0.3336 - accuracy: 0.9250 - binary_crossentropy: 0.3336 - precision: 0.9203 - recall: 0.9306 - auc: 0.9808\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 185ms/step - loss: 0.3076 - accuracy: 0.9493 - binary_crossentropy: 0.3076 - precision: 0.9462 - recall: 0.9528 - auc: 0.9877\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.2907 - accuracy: 0.9465 - binary_crossentropy: 0.2907 - precision: 0.9386 - recall: 0.9556 - auc: 0.9904\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.2935 - accuracy: 0.9319 - binary_crossentropy: 0.2935 - precision: 0.9331 - recall: 0.9306 - auc: 0.9858\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 188ms/step - loss: 0.2745 - accuracy: 0.9507 - binary_crossentropy: 0.2745 - precision: 0.9526 - recall: 0.9486 - auc: 0.9908\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 183ms/step - loss: 0.2509 - accuracy: 0.9667 - binary_crossentropy: 0.2509 - precision: 0.9590 - recall: 0.9750 - auc: 0.9937\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.2419 - accuracy: 0.9632 - binary_crossentropy: 0.2419 - precision: 0.9587 - recall: 0.9681 - auc: 0.9941\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 181ms/step - loss: 0.2327 - accuracy: 0.9681 - binary_crossentropy: 0.2327 - precision: 0.9668 - recall: 0.9694 - auc: 0.9941\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 187ms/step - loss: 0.2243 - accuracy: 0.9708 - binary_crossentropy: 0.2243 - precision: 0.9657 - recall: 0.9764 - auc: 0.9955\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 184ms/step - loss: 0.2079 - accuracy: 0.9778 - binary_crossentropy: 0.2079 - precision: 0.9725 - recall: 0.9833 - auc: 0.9972\n",
      "Loss of Train ......................................\n",
      "[0.7160535454750061, 0.6357523202896118, 0.5772005915641785, 0.5338760018348694, 0.4868544638156891, 0.45192617177963257, 0.4294435381889343, 0.40346887707710266, 0.37248408794403076, 0.35022079944610596, 0.33363333344459534, 0.3076212704181671, 0.29067423939704895, 0.2934912443161011, 0.27445921301841736, 0.25090137124061584, 0.24192222952842712, 0.2326793521642685, 0.2242644876241684, 0.20786653459072113]\n",
      "Accuracy of Train ......................................\n",
      "[0.5333333611488342, 0.6458333134651184, 0.7159722447395325, 0.7645833492279053, 0.8215277791023254, 0.8527777791023254, 0.8701388835906982, 0.8923611044883728, 0.9097222089767456, 0.9208333492279053, 0.925000011920929, 0.949305534362793, 0.9465277791023254, 0.9319444298744202, 0.9506944417953491, 0.9666666388511658, 0.9631944298744202, 0.9680555462837219, 0.9708333611488342, 0.9777777791023254]\n",
      "Precision of Train ......................................\n",
      "[0.5392156839370728, 0.6625387072563171, 0.7480064034461975, 0.7881997227668762, 0.8439821600914001, 0.8607954382896423, 0.889051079750061, 0.8951048851013184, 0.9166666865348816, 0.923184335231781, 0.9203296899795532, 0.9462068676948547, 0.9386084675788879, 0.9331476092338562, 0.9525802135467529, 0.9590163826942444, 0.9587345123291016, 0.9667590260505676, 0.9656593203544617, 0.9725274443626404]\n",
      "Recall of Train ......................................\n",
      "[0.4583333432674408, 0.5944444537162781, 0.6513888835906982, 0.7236111164093018, 0.7888888716697693, 0.8416666388511658, 0.8458333611488342, 0.8888888955116272, 0.9013888835906982, 0.918055534362793, 0.9305555820465088, 0.9527778029441833, 0.9555555582046509, 0.9305555820465088, 0.9486111402511597, 0.9750000238418579, 0.9680555462837219, 0.9694444537162781, 0.9763888716697693, 0.9833333492279053]\n",
      "AUC of Train ......................................\n",
      "[0.5479803085327148, 0.6903887391090393, 0.7886275053024292, 0.84744793176651, 0.8984857797622681, 0.9290133118629456, 0.9426292777061462, 0.9579349756240845, 0.9718478918075562, 0.9781153798103333, 0.980819821357727, 0.9877064228057861, 0.9903703331947327, 0.9857686758041382, 0.9908478856086731, 0.9936988353729248, 0.9940904974937439, 0.9941146373748779, 0.9954803586006165, 0.9972019791603088]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8738541662693023\n",
      " Loss:0.3807396836578846\n",
      " Precision:0.8790157318115235\n",
      " Recall:0.8601388946175575\n",
      " AUC:0.9231285274028778\n",
      "Score for fold 3: loss of 0.5272302031517029; accuracy of 0.7166666388511658%\n",
      "[[169  11]\n",
      " [ 91  89]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 506.7753298 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:169,FN:91,TP:89,FP:11\n",
      "Test of epochs .................................\n",
      " Accuracy:0.7166666666666667\n",
      " Loss:0.5272302031517029\n",
      " Precision:0.89\n",
      " Recall:0.49444444444444446\n",
      " AUC:0.5722222222222222\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 11s 155ms/step - loss: 0.7342 - accuracy: 0.5000 - binary_crossentropy: 0.7342 - precision: 0.4927 - recall: 0.3324 - auc: 0.5177\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.6612 - accuracy: 0.5986 - binary_crossentropy: 0.6612 - precision: 0.6281 - recall: 0.4642 - auc: 0.6472\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 8s 178ms/step - loss: 0.6003 - accuracy: 0.6729 - binary_crossentropy: 0.6003 - precision: 0.7153 - recall: 0.5638 - auc: 0.7541\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 8s 180ms/step - loss: 0.5502 - accuracy: 0.7236 - binary_crossentropy: 0.5502 - precision: 0.7520 - recall: 0.6592 - auc: 0.8225\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 8s 178ms/step - loss: 0.5092 - accuracy: 0.7931 - binary_crossentropy: 0.5092 - precision: 0.8197 - recall: 0.7461 - auc: 0.8761\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 181ms/step - loss: 0.4738 - accuracy: 0.8368 - binary_crossentropy: 0.4738 - precision: 0.8654 - recall: 0.7938 - auc: 0.9098\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 8s 187ms/step - loss: 0.4419 - accuracy: 0.8576 - binary_crossentropy: 0.4419 - precision: 0.8746 - recall: 0.8317 - auc: 0.9355\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.4171 - accuracy: 0.8757 - binary_crossentropy: 0.4171 - precision: 0.8870 - recall: 0.8583 - auc: 0.9467\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 8s 175ms/step - loss: 0.3921 - accuracy: 0.8910 - binary_crossentropy: 0.3921 - precision: 0.8927 - recall: 0.8864 - auc: 0.9586\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 9s 192ms/step - loss: 0.3679 - accuracy: 0.9194 - binary_crossentropy: 0.3679 - precision: 0.9307 - recall: 0.9046 - auc: 0.9721\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 8s 178ms/step - loss: 0.3453 - accuracy: 0.9208 - binary_crossentropy: 0.3453 - precision: 0.9248 - recall: 0.9144 - auc: 0.9785\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 186ms/step - loss: 0.3295 - accuracy: 0.9319 - binary_crossentropy: 0.3295 - precision: 0.9325 - recall: 0.9299 - auc: 0.9798\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.3227 - accuracy: 0.9278 - binary_crossentropy: 0.3227 - precision: 0.9247 - recall: 0.9299 - auc: 0.9801\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 189ms/step - loss: 0.2974 - accuracy: 0.9431 - binary_crossentropy: 0.2974 - precision: 0.9463 - recall: 0.9383 - auc: 0.9874\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 178ms/step - loss: 0.2858 - accuracy: 0.9438 - binary_crossentropy: 0.2858 - precision: 0.9413 - recall: 0.9453 - auc: 0.9880\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.2665 - accuracy: 0.9590 - binary_crossentropy: 0.2665 - precision: 0.9529 - recall: 0.9649 - auc: 0.9918\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 9s 194ms/step - loss: 0.2627 - accuracy: 0.9569 - binary_crossentropy: 0.2627 - precision: 0.9502 - recall: 0.9635 - auc: 0.9899\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 187ms/step - loss: 0.2443 - accuracy: 0.9625 - binary_crossentropy: 0.2443 - precision: 0.9583 - recall: 0.9663 - auc: 0.9940\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 183ms/step - loss: 0.2400 - accuracy: 0.9653 - binary_crossentropy: 0.2400 - precision: 0.9649 - recall: 0.9649 - auc: 0.9945\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 180ms/step - loss: 0.2279 - accuracy: 0.9660 - binary_crossentropy: 0.2279 - precision: 0.9586 - recall: 0.9734 - auc: 0.9951\n",
      "Loss of Train ......................................\n",
      "[0.7342005968093872, 0.66117924451828, 0.6003246307373047, 0.5501917600631714, 0.509244978427887, 0.4738105833530426, 0.44190919399261475, 0.4171175956726074, 0.3921315371990204, 0.3678745627403259, 0.34525442123413086, 0.32946720719337463, 0.32267212867736816, 0.29740312695503235, 0.2857511639595032, 0.266535222530365, 0.26267144083976746, 0.24427437782287598, 0.24003881216049194, 0.2279309332370758]\n",
      "Accuracy of Train ......................................\n",
      "[0.5, 0.5986111164093018, 0.6729166507720947, 0.7236111164093018, 0.793055534362793, 0.8368055820465088, 0.8576388955116272, 0.8756944537162781, 0.8909721970558167, 0.9194444417953491, 0.9208333492279053, 0.9319444298744202, 0.9277777671813965, 0.9430555701255798, 0.9437500238418579, 0.9590277671813965, 0.956944465637207, 0.9624999761581421, 0.9652777910232544, 0.9659722447395325]\n",
      "Precision of Train ......................................\n",
      "[0.4927234947681427, 0.6280834674835205, 0.7153024673461914, 0.7519999742507935, 0.8197226524353027, 0.8654434084892273, 0.8746312856674194, 0.886956512928009, 0.8926553726196289, 0.9307359457015991, 0.9248226881027222, 0.9324894547462463, 0.9246861934661865, 0.9462517499923706, 0.9413408041000366, 0.9529085755348206, 0.9502074718475342, 0.9582753777503967, 0.9649369120597839, 0.958563506603241]\n",
      "Recall of Train ......................................\n",
      "[0.33239832520484924, 0.4642356336116791, 0.5638148784637451, 0.6591865420341492, 0.7461430430412292, 0.7938289046287537, 0.8316970467567444, 0.8583450317382812, 0.8863955140113831, 0.904628336429596, 0.9144459962844849, 0.9298737645149231, 0.9298737645149231, 0.9382889270782471, 0.9453015327453613, 0.9649369120597839, 0.9635343551635742, 0.9663394093513489, 0.9649369120597839, 0.9733520150184631]\n",
      "AUC of Train ......................................\n",
      "[0.5177408456802368, 0.647152304649353, 0.7541115880012512, 0.8225122094154358, 0.8761495351791382, 0.9098052978515625, 0.9354520440101624, 0.9466664791107178, 0.9585666656494141, 0.972089409828186, 0.9785107374191284, 0.9797810316085815, 0.9801389575004578, 0.9874342083930969, 0.9880177974700928, 0.9917815923690796, 0.9898948669433594, 0.9939953088760376, 0.9945278763771057, 0.9950834512710571]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8572916686534882\n",
      " Loss:0.39849917590618134\n",
      " Precision:0.8656368657946587\n",
      " Recall:0.8265778422355652\n",
      " AUC:0.9109706103801727\n",
      "Score for fold 4: loss of 0.43847987055778503; accuracy of 0.8305555582046509%\n",
      "[[141  32]\n",
      " [ 29 158]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 677.6803212 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:141,FN:29,TP:158,FP:32\n",
      "Test of epochs .................................\n",
      " Accuracy:0.8305555555555556\n",
      " Loss:0.43847987055778503\n",
      " Precision:0.8315789473684211\n",
      " Recall:0.8449197860962567\n",
      " AUC:0.8371657754010695\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 11s 164ms/step - loss: 0.6805 - accuracy: 0.6056 - binary_crossentropy: 0.6805 - precision: 0.7891 - recall: 0.2985 - auc: 0.6869\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.5985 - accuracy: 0.6812 - binary_crossentropy: 0.5985 - precision: 0.8526 - recall: 0.4457 - auc: 0.7933\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 8s 177ms/step - loss: 0.5354 - accuracy: 0.7486 - binary_crossentropy: 0.5354 - precision: 0.9101 - recall: 0.5571 - auc: 0.8639\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 8s 185ms/step - loss: 0.4855 - accuracy: 0.7986 - binary_crossentropy: 0.4855 - precision: 0.9084 - recall: 0.6685 - auc: 0.9026\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 8s 181ms/step - loss: 0.4521 - accuracy: 0.8340 - binary_crossentropy: 0.4521 - precision: 0.9251 - recall: 0.7304 - auc: 0.9292\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 179ms/step - loss: 0.4131 - accuracy: 0.8681 - binary_crossentropy: 0.4131 - precision: 0.9409 - recall: 0.7882 - auc: 0.9511\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 8s 179ms/step - loss: 0.3776 - accuracy: 0.9007 - binary_crossentropy: 0.3776 - precision: 0.9548 - recall: 0.8432 - auc: 0.9688\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 183ms/step - loss: 0.3613 - accuracy: 0.9083 - binary_crossentropy: 0.3613 - precision: 0.9501 - recall: 0.8638 - auc: 0.9721\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 8s 176ms/step - loss: 0.3377 - accuracy: 0.9187 - binary_crossentropy: 0.3377 - precision: 0.9499 - recall: 0.8858 - auc: 0.9778\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.3148 - accuracy: 0.9299 - binary_crossentropy: 0.3148 - precision: 0.9510 - recall: 0.9078 - auc: 0.9842\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 9s 195ms/step - loss: 0.3006 - accuracy: 0.9403 - binary_crossentropy: 0.3006 - precision: 0.9572 - recall: 0.9230 - auc: 0.9843\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 8s 180ms/step - loss: 0.2829 - accuracy: 0.9521 - binary_crossentropy: 0.2829 - precision: 0.9634 - recall: 0.9409 - auc: 0.9889\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 8s 176ms/step - loss: 0.2727 - accuracy: 0.9528 - binary_crossentropy: 0.2727 - precision: 0.9557 - recall: 0.9505 - auc: 0.9906\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 8s 183ms/step - loss: 0.2579 - accuracy: 0.9569 - binary_crossentropy: 0.2579 - precision: 0.9663 - recall: 0.9477 - auc: 0.9913\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 8s 186ms/step - loss: 0.2409 - accuracy: 0.9694 - binary_crossentropy: 0.2409 - precision: 0.9672 - recall: 0.9725 - auc: 0.9944\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 8s 185ms/step - loss: 0.2259 - accuracy: 0.9653 - binary_crossentropy: 0.2259 - precision: 0.9669 - recall: 0.9642 - auc: 0.9962\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 8s 183ms/step - loss: 0.2171 - accuracy: 0.9736 - binary_crossentropy: 0.2171 - precision: 0.9845 - recall: 0.9629 - auc: 0.9965\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 8s 173ms/step - loss: 0.2220 - accuracy: 0.9611 - binary_crossentropy: 0.2220 - precision: 0.9565 - recall: 0.9670 - auc: 0.9952\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 8s 185ms/step - loss: 0.2134 - accuracy: 0.9639 - binary_crossentropy: 0.2134 - precision: 0.9617 - recall: 0.9670 - auc: 0.9945\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 8s 186ms/step - loss: 0.2063 - accuracy: 0.9667 - binary_crossentropy: 0.2063 - precision: 0.9632 - recall: 0.9711 - auc: 0.9953\n",
      "Loss of Train ......................................\n",
      "[0.680460512638092, 0.5985028147697449, 0.5353963375091553, 0.48554307222366333, 0.4520736336708069, 0.4131179749965668, 0.3775777220726013, 0.36133337020874023, 0.3376677334308624, 0.314784437417984, 0.30058130621910095, 0.2829107940196991, 0.2726576328277588, 0.2578863501548767, 0.2408977895975113, 0.2259446680545807, 0.21708311140537262, 0.22202031314373016, 0.21338392794132233, 0.20626330375671387]\n",
      "Accuracy of Train ......................................\n",
      "[0.605555534362793, 0.6812499761581421, 0.7486110925674438, 0.7986111044883728, 0.8340277671813965, 0.8680555820465088, 0.9006944298744202, 0.9083333611488342, 0.918749988079071, 0.9298611283302307, 0.9402777552604675, 0.9520833492279053, 0.9527778029441833, 0.956944465637207, 0.9694444537162781, 0.9652777910232544, 0.9736111164093018, 0.9611111283302307, 0.9638888835906982, 0.9666666388511658]\n",
      "Precision of Train ......................................\n",
      "[0.7890909314155579, 0.8526315689086914, 0.9101123809814453, 0.9084112048149109, 0.9250870943069458, 0.9408866763114929, 0.954828679561615, 0.950075626373291, 0.9498525261878967, 0.9510086178779602, 0.9572039842605591, 0.9633802771568298, 0.9557399749755859, 0.9663394093513489, 0.9671682715415955, 0.9668965339660645, 0.9845288395881653, 0.956462562084198, 0.9616963267326355, 0.9631651043891907]\n",
      "Recall of Train ......................................\n",
      "[0.2984869182109833, 0.4456671178340912, 0.5570839047431946, 0.6685006618499756, 0.7303988933563232, 0.788170576095581, 0.8431912064552307, 0.8638239502906799, 0.8858321905136108, 0.9078404307365417, 0.9229711294174194, 0.9408528208732605, 0.9504814147949219, 0.9477304220199585, 0.9724896550178528, 0.9642366170883179, 0.9628610610961914, 0.9669876098632812, 0.9669876098632812, 0.9711141586303711]\n",
      "AUC of Train ......................................\n",
      "[0.6868646740913391, 0.7933002710342407, 0.8638567328453064, 0.9026219844818115, 0.9292120933532715, 0.9510592222213745, 0.968817412853241, 0.9721192121505737, 0.9778190851211548, 0.9841594099998474, 0.9843137264251709, 0.9889495372772217, 0.9906376004219055, 0.9912839531898499, 0.9943570494651794, 0.9961705803871155, 0.9965323805809021, 0.9952453970909119, 0.9945181608200073, 0.995320737361908]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8897916674613953\n",
      " Loss:0.34980434030294416\n",
      " Precision:0.938728329539299\n",
      " Recall:0.8277854174375534\n",
      " AUC:0.9478579610586166\n",
      "Score for fold 5: loss of 0.46286875009536743; accuracy of 0.7944444417953491%\n",
      "[[177  10]\n",
      " [ 64 109]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 847.8705719999999 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:177,FN:64,TP:109,FP:10\n",
      "Test of epochs .................................\n",
      " Accuracy:0.7944444444444444\n",
      " Loss:0.46286875009536743\n",
      " Precision:0.9159663865546218\n",
      " Recall:0.630057803468208\n",
      " AUC:0.6822488187465522\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.8717708319425583 - Loss: 0.3611107014119625\n",
      "> Fold 1 - Precision: 0.9323906987905503\n",
      "> Fold 1 - Recall: 0.7765734251588583\n",
      "> Fold 1 - AUC: 0.9359548062086105\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.8444444444444444 - Loss: 0.4266618490219116\n",
      "> Fold 1 - Precision: 0.9387755102040817\n",
      "> Fold 1 - Recall: 0.745945945945946\n",
      "> Fold 1 - AUC: 0.7626443344753204\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8797222226858139 - Loss: 0.3695552036166191\n",
      "> Fold 2 - Precision: 0.9073915332555771\n",
      "> Fold 2 - Recall: 0.8301379233598709\n",
      "> Fold 2 - AUC: 0.933806324005127\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8944444444444445 - Loss: 0.35652458667755127\n",
      "> Fold 2 - Precision: 0.8702702702702703\n",
      "> Fold 2 - Recall: 0.92\n",
      "> Fold 2 - AUC: 0.92\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.8738541662693023 - Loss: 0.3807396836578846\n",
      "> Fold 3 - Precision: 0.8790157318115235\n",
      "> Fold 3 - Recall: 0.8601388946175575\n",
      "> Fold 3 - AUC: 0.9231285274028778\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.7166666666666667 - Loss: 0.5272302031517029\n",
      "> Fold 3 - Precision: 0.89\n",
      "> Fold 3 - Recall: 0.49444444444444446\n",
      "> Fold 3 - AUC: 0.5722222222222222\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.8572916686534882 - Loss: 0.39849917590618134\n",
      "> Fold 4 - Precision: 0.8656368657946587\n",
      "> Fold 4 - Recall: 0.8265778422355652\n",
      "> Fold 4 - AUC: 0.9109706103801727\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.8305555555555556 - Loss: 0.43847987055778503\n",
      "> Fold 4 - Precision: 0.8315789473684211\n",
      "> Fold 4 - Recall: 0.8449197860962567\n",
      "> Fold 4 - AUC: 0.8371657754010695\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.8897916674613953 - Loss: 0.34980434030294416\n",
      "> Fold 5 - Precision: 0.938728329539299\n",
      "> Fold 5 - Recall: 0.8277854174375534\n",
      "> Fold 5 - AUC: 0.9478579610586166\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.7944444444444444 - Loss: 0.46286875009536743\n",
      "> Fold 5 - Precision: 0.9159663865546218\n",
      "> Fold 5 - Recall: 0.630057803468208\n",
      "> Fold 5 - AUC: 0.6822488187465522\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.8744861114025116 (+- 0.010631066421476557)\n",
      "> Loss: 0.3719418209791184 (+- 0.016707918078787787)\n",
      "> Precision: 0.9046326318383218 (+- 0.028696807334566112)\n",
      "> Recall: 0.8242427005618811 (+- 0.02688365282645684)\n",
      "> AUC: 0.930343645811081 (+- 0.012470757277118388)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.8161111111111111 (+- 0.05917123091419711)\n",
      "> Loss: 0.44235305190086366 (+- 0.05523181239278673)\n",
      "> Precision: 0.889318222879479 (+- 0.0370223207050884)\n",
      "> Recall: 0.7270735959909711 (+- 0.15165280981708573)\n",
      "> AUC: 0.7548562301690329 (+- 0.12061094276321932)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 814 FN SUM: 245 TP SUM: 655 FP SUM: 86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6396d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1920)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 44s 362ms/step - loss: 0.7540 - accuracy: 0.5292 - binary_crossentropy: 0.7540 - precision: 0.8052 - recall: 0.0855 - auc: 0.6341\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.6071 - accuracy: 0.6604 - binary_crossentropy: 0.6071 - precision: 0.9370 - recall: 0.3490 - auc: 0.8232\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.5192 - accuracy: 0.7757 - binary_crossentropy: 0.5192 - precision: 0.9408 - recall: 0.5917 - auc: 0.9150\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.4556 - accuracy: 0.8660 - binary_crossentropy: 0.4556 - precision: 0.9539 - recall: 0.7710 - auc: 0.9576\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.4099 - accuracy: 0.9257 - binary_crossentropy: 0.4099 - precision: 0.9682 - recall: 0.8814 - auc: 0.9779\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.3756 - accuracy: 0.9361 - binary_crossentropy: 0.3756 - precision: 0.9567 - recall: 0.9145 - auc: 0.9884\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.3524 - accuracy: 0.9465 - binary_crossentropy: 0.3524 - precision: 0.9551 - recall: 0.9379 - auc: 0.9888\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.3158 - accuracy: 0.9694 - binary_crossentropy: 0.3158 - precision: 0.9671 - recall: 0.9724 - auc: 0.9947\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.2913 - accuracy: 0.9708 - binary_crossentropy: 0.2913 - precision: 0.9684 - recall: 0.9738 - auc: 0.9962\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.2795 - accuracy: 0.9715 - binary_crossentropy: 0.2795 - precision: 0.9737 - recall: 0.9697 - auc: 0.9970\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2637 - accuracy: 0.9785 - binary_crossentropy: 0.2637 - precision: 0.9702 - recall: 0.9876 - auc: 0.9975\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.2392 - accuracy: 0.9861 - binary_crossentropy: 0.2392 - precision: 0.9809 - recall: 0.9917 - auc: 0.9993\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2275 - accuracy: 0.9847 - binary_crossentropy: 0.2275 - precision: 0.9718 - recall: 0.9986 - auc: 0.9984\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2194 - accuracy: 0.9882 - binary_crossentropy: 0.2194 - precision: 0.9849 - recall: 0.9917 - auc: 0.9989\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.2048 - accuracy: 0.9896 - binary_crossentropy: 0.2048 - precision: 0.9837 - recall: 0.9959 - auc: 0.9993\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2016 - accuracy: 0.9861 - binary_crossentropy: 0.2016 - precision: 0.9783 - recall: 0.9945 - auc: 0.9987\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1954 - accuracy: 0.9847 - binary_crossentropy: 0.1954 - precision: 0.9756 - recall: 0.9945 - auc: 0.9990\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.1831 - accuracy: 0.9889 - binary_crossentropy: 0.1831 - precision: 0.9797 - recall: 0.9986 - auc: 0.9996\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1731 - accuracy: 0.9868 - binary_crossentropy: 0.1731 - precision: 0.9809 - recall: 0.9931 - auc: 0.9992\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1630 - accuracy: 0.9917 - binary_crossentropy: 0.1630 - precision: 0.9864 - recall: 0.9972 - auc: 0.9995\n",
      "Loss of Train ......................................\n",
      "[0.7539603114128113, 0.6070559024810791, 0.5192296504974365, 0.45560422539711, 0.4098644256591797, 0.3755769431591034, 0.3524026572704315, 0.3158435523509979, 0.29126042127609253, 0.2794516086578369, 0.26368269324302673, 0.23924094438552856, 0.22745740413665771, 0.21940472722053528, 0.20484012365341187, 0.2015533596277237, 0.19536453485488892, 0.18308457732200623, 0.1730669140815735, 0.16304050385951996]\n",
      "Accuracy of Train ......................................\n",
      "[0.5291666388511658, 0.6604166626930237, 0.7756944298744202, 0.8659722208976746, 0.925694465637207, 0.9361110925674438, 0.9465277791023254, 0.9694444537162781, 0.9708333611488342, 0.9715277552604675, 0.9784722328186035, 0.9861111044883728, 0.9847221970558167, 0.988194465637207, 0.9895833134651184, 0.9861111044883728, 0.9847221970558167, 0.9888888597488403, 0.9868055582046509, 0.9916666746139526]\n",
      "Precision of Train ......................................\n",
      "[0.8051947951316833, 0.9370370507240295, 0.9407894611358643, 0.9539248943328857, 0.9681817889213562, 0.9567099809646606, 0.9550561904907227, 0.9670782089233398, 0.9684499502182007, 0.9736841917037964, 0.9701896905899048, 0.9809004068374634, 0.9718120694160461, 0.9849315285682678, 0.9836512207984924, 0.9782903790473938, 0.975642740726471, 0.9797022938728333, 0.9809264540672302, 0.9863574504852295]\n",
      "Recall of Train ......................................\n",
      "[0.08551724255084991, 0.34896552562713623, 0.591724157333374, 0.7710344791412354, 0.8813793063163757, 0.9144827723503113, 0.9379310607910156, 0.9724137783050537, 0.973793089389801, 0.9696551561355591, 0.9875862002372742, 0.9917241334915161, 0.9986206889152527, 0.9917241334915161, 0.9958620667457581, 0.9944827556610107, 0.9944827556610107, 0.9986206889152527, 0.9931034445762634, 0.9972413778305054]\n",
      "AUC of Train ......................................\n",
      "[0.634063184261322, 0.8232148885726929, 0.9150218963623047, 0.9576205015182495, 0.9779454469680786, 0.988391637802124, 0.9887648820877075, 0.9947441220283508, 0.9962469339370728, 0.9969558715820312, 0.9975143671035767, 0.9993431568145752, 0.9984200596809387, 0.9988821148872375, 0.9993228912353516, 0.9986833333969116, 0.9989612102508545, 0.9996315836906433, 0.9992061853408813, 0.9995465874671936]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9208333283662796\n",
      " Loss:0.32154927402734756\n",
      " Precision:0.9609255373477936\n",
      " Recall:0.8695172406733036\n",
      " AUC:0.9631240427494049\n",
      "Score for fold 1: loss of 0.22951041162014008; accuracy of 0.9444444179534912%\n",
      "[[165  20]\n",
      " [  0 175]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 432.1863919000002 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:165,FN:0,TP:175,FP:20\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9444444444444444\n",
      " Loss:0.22951041162014008\n",
      " Precision:0.8974358974358975\n",
      " Recall:1.0\n",
      " AUC:1.0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1921      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 34s 370ms/step - loss: 0.7571 - accuracy: 0.4847 - binary_crossentropy: 0.7571 - precision: 0.4505 - recall: 0.1389 - auc: 0.4759\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.6558 - accuracy: 0.5764 - binary_crossentropy: 0.6558 - precision: 0.6403 - recall: 0.3486 - auc: 0.6830\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.5755 - accuracy: 0.7215 - binary_crossentropy: 0.5755 - precision: 0.7884 - recall: 0.6056 - auc: 0.8318\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.5209 - accuracy: 0.8299 - binary_crossentropy: 0.5209 - precision: 0.8648 - recall: 0.7819 - auc: 0.9041\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.4707 - accuracy: 0.8708 - binary_crossentropy: 0.4707 - precision: 0.8836 - recall: 0.8542 - auc: 0.9470\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.4358 - accuracy: 0.9014 - binary_crossentropy: 0.4358 - precision: 0.9025 - recall: 0.9000 - auc: 0.9650\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.3948 - accuracy: 0.9333 - binary_crossentropy: 0.3948 - precision: 0.9194 - recall: 0.9500 - auc: 0.9818\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.3661 - accuracy: 0.9458 - binary_crossentropy: 0.3661 - precision: 0.9350 - recall: 0.9583 - auc: 0.9890\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.3394 - accuracy: 0.9556 - binary_crossentropy: 0.3394 - precision: 0.9432 - recall: 0.9694 - auc: 0.9919\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.3106 - accuracy: 0.9701 - binary_crossentropy: 0.3106 - precision: 0.9556 - recall: 0.9861 - auc: 0.9953\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2950 - accuracy: 0.9681 - binary_crossentropy: 0.2950 - precision: 0.9604 - recall: 0.9764 - auc: 0.9960\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2809 - accuracy: 0.9764 - binary_crossentropy: 0.2809 - precision: 0.9673 - recall: 0.9861 - auc: 0.9972\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2686 - accuracy: 0.9681 - binary_crossentropy: 0.2686 - precision: 0.9554 - recall: 0.9819 - auc: 0.9959\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2457 - accuracy: 0.9799 - binary_crossentropy: 0.2457 - precision: 0.9688 - recall: 0.9917 - auc: 0.9990\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2391 - accuracy: 0.9826 - binary_crossentropy: 0.2391 - precision: 0.9728 - recall: 0.9931 - auc: 0.9980\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2207 - accuracy: 0.9833 - binary_crossentropy: 0.2207 - precision: 0.9728 - recall: 0.9944 - auc: 0.9990\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2170 - accuracy: 0.9778 - binary_crossentropy: 0.2170 - precision: 0.9687 - recall: 0.9875 - auc: 0.9981\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2047 - accuracy: 0.9854 - binary_crossentropy: 0.2047 - precision: 0.9755 - recall: 0.9958 - auc: 0.9992\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.1935 - accuracy: 0.9882 - binary_crossentropy: 0.1935 - precision: 0.9822 - recall: 0.9944 - auc: 0.9995\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.1815 - accuracy: 0.9924 - binary_crossentropy: 0.1815 - precision: 0.9850 - recall: 1.0000 - auc: 0.9997\n",
      "Loss of Train ......................................\n",
      "[0.7570863366127014, 0.655834436416626, 0.575549304485321, 0.5208672285079956, 0.47070905566215515, 0.4357519745826721, 0.394834041595459, 0.36613526940345764, 0.33935773372650146, 0.31063660979270935, 0.2950482964515686, 0.2809394299983978, 0.26862409710884094, 0.24566304683685303, 0.23911356925964355, 0.22071075439453125, 0.2169569879770279, 0.20467804372310638, 0.1934920698404312, 0.1814575344324112]\n",
      "Accuracy of Train ......................................\n",
      "[0.48472222685813904, 0.5763888955116272, 0.7215277552604675, 0.8298611044883728, 0.8708333373069763, 0.9013888835906982, 0.9333333373069763, 0.9458333253860474, 0.9555555582046509, 0.9701389074325562, 0.9680555462837219, 0.9763888716697693, 0.9680555462837219, 0.9798611402511597, 0.9826388955116272, 0.9833333492279053, 0.9777777791023254, 0.9854166507720947, 0.988194465637207, 0.9923611283302307]\n",
      "Precision of Train ......................................\n",
      "[0.45045045018196106, 0.6403061151504517, 0.7884267568588257, 0.8648233413696289, 0.8836206793785095, 0.902506947517395, 0.9193548560142517, 0.934959352016449, 0.9432432651519775, 0.9555854797363281, 0.9603825211524963, 0.9673024415969849, 0.9554054141044617, 0.9687923789024353, 0.9727891087532043, 0.9728260636329651, 0.968664824962616, 0.9755101799964905, 0.9821673631668091, 0.9849520921707153]\n",
      "Recall of Train ......................................\n",
      "[0.1388888955116272, 0.34861111640930176, 0.605555534362793, 0.7819444537162781, 0.8541666865348816, 0.8999999761581421, 0.949999988079071, 0.9583333134651184, 0.9694444537162781, 0.9861111044883728, 0.9763888716697693, 0.9861111044883728, 0.9819444417953491, 0.9916666746139526, 0.9930555820465088, 0.9944444298744202, 0.987500011920929, 0.9958333373069763, 0.9944444298744202, 1.0]\n",
      "AUC of Train ......................................\n",
      "[0.47587960958480835, 0.6829890012741089, 0.83182293176651, 0.9041473865509033, 0.947039008140564, 0.9650472402572632, 0.9818180799484253, 0.9889737963676453, 0.9918528199195862, 0.9952979683876038, 0.9960185289382935, 0.9971798062324524, 0.9958690404891968, 0.9990432262420654, 0.9979851841926575, 0.9990142583847046, 0.9980594515800476, 0.9992071986198425, 0.9994511604309082, 0.9997202754020691]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.8995833352208138\n",
      " Loss:0.35867229104042053\n",
      " Precision:0.8996034815907479\n",
      " Recall:0.8697222203016282\n",
      " AUC:0.9373207986354828\n",
      "Score for fold 2: loss of 0.2085937112569809; accuracy of 0.9833333492279053%\n",
      "[[175   5]\n",
      " [  1 179]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 844.7499399999997 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:175,FN:1,TP:179,FP:5\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9833333333333333\n",
      " Loss:0.2085937112569809\n",
      " Precision:0.9728260869565217\n",
      " Recall:0.9944444444444445\n",
      " AUC:0.9943813131313131\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 34s 368ms/step - loss: 0.6994 - accuracy: 0.5403 - binary_crossentropy: 0.6994 - precision: 0.5477 - recall: 0.3729 - auc: 0.5637\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 18s 393ms/step - loss: 0.6135 - accuracy: 0.6778 - binary_crossentropy: 0.6135 - precision: 0.7103 - recall: 0.5819 - auc: 0.7476\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.5485 - accuracy: 0.7778 - binary_crossentropy: 0.5485 - precision: 0.8003 - recall: 0.7302 - auc: 0.8581\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.4942 - accuracy: 0.8389 - binary_crossentropy: 0.4942 - precision: 0.8439 - recall: 0.8249 - auc: 0.9226\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.4495 - accuracy: 0.8944 - binary_crossentropy: 0.4495 - precision: 0.9017 - recall: 0.8814 - auc: 0.9584\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.4072 - accuracy: 0.9215 - binary_crossentropy: 0.4072 - precision: 0.9161 - recall: 0.9251 - auc: 0.9777\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.3739 - accuracy: 0.9417 - binary_crossentropy: 0.3739 - precision: 0.9309 - recall: 0.9520 - auc: 0.9877\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.3435 - accuracy: 0.9597 - binary_crossentropy: 0.3435 - precision: 0.9464 - recall: 0.9732 - auc: 0.9932\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.3197 - accuracy: 0.9681 - binary_crossentropy: 0.3197 - precision: 0.9623 - recall: 0.9732 - auc: 0.9946\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.2984 - accuracy: 0.9722 - binary_crossentropy: 0.2984 - precision: 0.9613 - recall: 0.9831 - auc: 0.9954\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.2761 - accuracy: 0.9799 - binary_crossentropy: 0.2761 - precision: 0.9709 - recall: 0.9887 - auc: 0.9984\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.2624 - accuracy: 0.9799 - binary_crossentropy: 0.2624 - precision: 0.9735 - recall: 0.9859 - auc: 0.9978\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.2532 - accuracy: 0.9819 - binary_crossentropy: 0.2532 - precision: 0.9710 - recall: 0.9929 - auc: 0.9982\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.2324 - accuracy: 0.9861 - binary_crossentropy: 0.2324 - precision: 0.9791 - recall: 0.9929 - auc: 0.9992\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2256 - accuracy: 0.9833 - binary_crossentropy: 0.2256 - precision: 0.9750 - recall: 0.9915 - auc: 0.9987\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2130 - accuracy: 0.9882 - binary_crossentropy: 0.2130 - precision: 0.9819 - recall: 0.9944 - auc: 0.9992\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.2063 - accuracy: 0.9806 - binary_crossentropy: 0.2063 - precision: 0.9709 - recall: 0.9901 - auc: 0.9983\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1927 - accuracy: 0.9868 - binary_crossentropy: 0.1927 - precision: 0.9805 - recall: 0.9929 - auc: 0.9993\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.1843 - accuracy: 0.9847 - binary_crossentropy: 0.1843 - precision: 0.9804 - recall: 0.9887 - auc: 0.9994\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1710 - accuracy: 0.9931 - binary_crossentropy: 0.1710 - precision: 0.9888 - recall: 0.9972 - auc: 0.9997\n",
      "Loss of Train ......................................\n",
      "[0.6994255781173706, 0.613493800163269, 0.5485467314720154, 0.4941750764846802, 0.449526309967041, 0.4071950614452362, 0.37392136454582214, 0.3434881567955017, 0.3197227716445923, 0.2984253764152527, 0.2761290967464447, 0.2623685598373413, 0.25320929288864136, 0.23236916959285736, 0.2255631387233734, 0.213003471493721, 0.20632998645305634, 0.19271208345890045, 0.18434540927410126, 0.1710355281829834]\n",
      "Accuracy of Train ......................................\n",
      "[0.5402777791023254, 0.6777777671813965, 0.7777777910232544, 0.8388888835906982, 0.894444465637207, 0.9215278029441833, 0.9416666626930237, 0.9597222208976746, 0.9680555462837219, 0.9722222089767456, 0.9798611402511597, 0.9798611402511597, 0.9819444417953491, 0.9861111044883728, 0.9833333492279053, 0.988194465637207, 0.980555534362793, 0.9868055582046509, 0.9847221970558167, 0.9930555820465088]\n",
      "Precision of Train ......................................\n",
      "[0.5477178692817688, 0.7103448510169983, 0.8003095984458923, 0.8439306616783142, 0.9017341136932373, 0.9160839319229126, 0.9309391975402832, 0.9464285969734192, 0.9622905254364014, 0.9613259434700012, 0.9708737730979919, 0.973500669002533, 0.9709944725036621, 0.9791086316108704, 0.9750000238418579, 0.9818689227104187, 0.9709141254425049, 0.9804741740226746, 0.9803921580314636, 0.9887955188751221]\n",
      "Recall of Train ......................................\n",
      "[0.37288135290145874, 0.5819209218025208, 0.7302259802818298, 0.8248587846755981, 0.8813559412956238, 0.9251412153244019, 0.9519773721694946, 0.9731638431549072, 0.9731638431549072, 0.9830508232116699, 0.9887005686759949, 0.9858757257461548, 0.9929378628730774, 0.9929378628730774, 0.991525411605835, 0.994350254535675, 0.9901130199432373, 0.9929378628730774, 0.9887005686759949, 0.9971751570701599]\n",
      "AUC of Train ......................................\n",
      "[0.5637261867523193, 0.7476372718811035, 0.858106791973114, 0.9226019978523254, 0.9584298133850098, 0.9777309894561768, 0.9876905083656311, 0.9932369589805603, 0.9945654273033142, 0.9953797459602356, 0.9984418153762817, 0.9978417754173279, 0.9982315897941589, 0.9992455244064331, 0.9987303614616394, 0.999168336391449, 0.998295247554779, 0.9993073344230652, 0.9993699789047241, 0.9996951818466187]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9168402820825576\n",
      " Loss:0.33824929818511007\n",
      " Precision:0.9146513879299164\n",
      " Recall:0.9056497186422348\n",
      " AUC:0.9493716418743133\n",
      "Score for fold 3: loss of 0.2046387791633606; accuracy of 0.9833333492279053%\n",
      "[[162   6]\n",
      " [  0 192]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1256.1840491000003 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:162,FN:0,TP:192,FP:6\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9833333333333333\n",
      " Loss:0.2046387791633606\n",
      " Precision:0.9696969696969697\n",
      " Recall:1.0\n",
      " AUC:1.0\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 34s 367ms/step - loss: 0.6566 - accuracy: 0.6000 - binary_crossentropy: 0.6566 - precision: 0.6236 - recall: 0.5349 - auc: 0.6519\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.5847 - accuracy: 0.7236 - binary_crossentropy: 0.5847 - precision: 0.7511 - recall: 0.6813 - auc: 0.7968\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.5284 - accuracy: 0.7944 - binary_crossentropy: 0.5284 - precision: 0.7975 - recall: 0.7975 - auc: 0.8765\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.4801 - accuracy: 0.8521 - binary_crossentropy: 0.4801 - precision: 0.8597 - recall: 0.8468 - auc: 0.9297\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 421ms/step - loss: 0.4394 - accuracy: 0.8750 - binary_crossentropy: 0.4394 - precision: 0.8769 - recall: 0.8769 - auc: 0.9517\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.4016 - accuracy: 0.9069 - binary_crossentropy: 0.4016 - precision: 0.9028 - recall: 0.9152 - auc: 0.9705\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.3699 - accuracy: 0.9340 - binary_crossentropy: 0.3699 - precision: 0.9332 - recall: 0.9371 - auc: 0.9784\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.3495 - accuracy: 0.9285 - binary_crossentropy: 0.3495 - precision: 0.9232 - recall: 0.9371 - auc: 0.9821\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.3188 - accuracy: 0.9500 - binary_crossentropy: 0.3188 - precision: 0.9459 - recall: 0.9562 - auc: 0.9896\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2987 - accuracy: 0.9597 - binary_crossentropy: 0.2987 - precision: 0.9541 - recall: 0.9672 - auc: 0.9907\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2860 - accuracy: 0.9604 - binary_crossentropy: 0.2860 - precision: 0.9542 - recall: 0.9685 - auc: 0.9927\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2671 - accuracy: 0.9625 - binary_crossentropy: 0.2671 - precision: 0.9568 - recall: 0.9699 - auc: 0.9948\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2535 - accuracy: 0.9722 - binary_crossentropy: 0.2535 - precision: 0.9650 - recall: 0.9808 - auc: 0.9947\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2387 - accuracy: 0.9757 - binary_crossentropy: 0.2387 - precision: 0.9677 - recall: 0.9850 - auc: 0.9959\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2292 - accuracy: 0.9750 - binary_crossentropy: 0.2292 - precision: 0.9702 - recall: 0.9808 - auc: 0.9965\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.2166 - accuracy: 0.9757 - binary_crossentropy: 0.2166 - precision: 0.9703 - recall: 0.9822 - auc: 0.9969\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.2068 - accuracy: 0.9757 - binary_crossentropy: 0.2068 - precision: 0.9677 - recall: 0.9850 - auc: 0.9979\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.1978 - accuracy: 0.9806 - binary_crossentropy: 0.1978 - precision: 0.9756 - recall: 0.9863 - auc: 0.9980\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.1829 - accuracy: 0.9847 - binary_crossentropy: 0.1829 - precision: 0.9746 - recall: 0.9959 - auc: 0.9990\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.1894 - accuracy: 0.9771 - binary_crossentropy: 0.1894 - precision: 0.9678 - recall: 0.9877 - auc: 0.9974\n",
      "Loss of Train ......................................\n",
      "[0.6566205620765686, 0.5847256779670715, 0.5284342169761658, 0.48007452487945557, 0.4394240975379944, 0.40158945322036743, 0.3698941469192505, 0.3495054543018341, 0.31877270340919495, 0.298691064119339, 0.2860051691532135, 0.2670653164386749, 0.2534683644771576, 0.2386813759803772, 0.2291773408651352, 0.2165636420249939, 0.20680305361747742, 0.1977584809064865, 0.18294711410999298, 0.1893545389175415]\n",
      "Accuracy of Train ......................................\n",
      "[0.6000000238418579, 0.7236111164093018, 0.7944444417953491, 0.8520833253860474, 0.875, 0.9069444537162781, 0.9340277910232544, 0.9284722208976746, 0.949999988079071, 0.9597222208976746, 0.9604166746139526, 0.9624999761581421, 0.9722222089767456, 0.9756944179534912, 0.9750000238418579, 0.9756944179534912, 0.9756944179534912, 0.980555534362793, 0.9847221970558167, 0.9770833253860474]\n",
      "Precision of Train ......................................\n",
      "[0.6236044764518738, 0.7511312365531921, 0.797537624835968, 0.8597221970558167, 0.8768810033798218, 0.9028339982032776, 0.9332424998283386, 0.9231805801391602, 0.9458727836608887, 0.9541160464286804, 0.9541779160499573, 0.9568151235580444, 0.9650067090988159, 0.9677419066429138, 0.9702300429344177, 0.9702702760696411, 0.9677419066429138, 0.975642740726471, 0.9745649099349976, 0.9678283929824829]\n",
      "Recall of Train ......................................\n",
      "[0.5348837375640869, 0.6812585592269897, 0.797537624835968, 0.8467852473258972, 0.8768810033798218, 0.9151846766471863, 0.9370725154876709, 0.9370725154876709, 0.9562243223190308, 0.9671682715415955, 0.9685362577438354, 0.9699042439460754, 0.9808481335639954, 0.9849520921707153, 0.9808481335639954, 0.9822161197662354, 0.9849520921707153, 0.9863201379776001, 0.99589604139328, 0.9876881241798401]\n",
      "AUC of Train ......................................\n",
      "[0.6519026756286621, 0.796831488609314, 0.8764815330505371, 0.9296855330467224, 0.9517084956169128, 0.9704561233520508, 0.9784170389175415, 0.98213130235672, 0.989608883857727, 0.9907298684120178, 0.9927142858505249, 0.9948193430900574, 0.9946640133857727, 0.9958864450454712, 0.9965066909790039, 0.9968597888946533, 0.9978959560394287, 0.9980483055114746, 0.998952329158783, 0.9974231719970703]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9131944388151169\n",
      " Loss:0.33477781489491465\n",
      " Precision:0.9119071185588836\n",
      " Recall:0.9136114925146103\n",
      " AUC:0.9540861636400223\n",
      "Score for fold 4: loss of 0.19378666579723358; accuracy of 0.9833333492279053%\n",
      "[[187   4]\n",
      " [  2 167]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 1667.2646597000003 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:187,FN:2,TP:167,FP:4\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9833333333333333\n",
      " Loss:0.19378666579723358\n",
      " Precision:0.9766081871345029\n",
      " Recall:0.9881656804733728\n",
      " AUC:0.9887918349456811\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1920)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,323,905\n",
      "Trainable params: 18,094,849\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 34s 368ms/step - loss: 0.7403 - accuracy: 0.4951 - binary_crossentropy: 0.7403 - precision: 0.4812 - recall: 0.1969 - auc: 0.5130\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.6404 - accuracy: 0.6326 - binary_crossentropy: 0.6404 - precision: 0.7092 - recall: 0.4427 - auc: 0.7059\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.5689 - accuracy: 0.7437 - binary_crossentropy: 0.5689 - precision: 0.8071 - recall: 0.6369 - auc: 0.8330\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.5128 - accuracy: 0.8264 - binary_crossentropy: 0.5128 - precision: 0.8618 - recall: 0.7751 - auc: 0.9136\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.4654 - accuracy: 0.8736 - binary_crossentropy: 0.4654 - precision: 0.8926 - recall: 0.8478 - auc: 0.9531\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.4235 - accuracy: 0.9153 - binary_crossentropy: 0.4235 - precision: 0.9207 - recall: 0.9078 - auc: 0.9773\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.3917 - accuracy: 0.9361 - binary_crossentropy: 0.3917 - precision: 0.9345 - recall: 0.9372 - auc: 0.9859\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 422ms/step - loss: 0.3642 - accuracy: 0.9549 - binary_crossentropy: 0.3642 - precision: 0.9477 - recall: 0.9623 - auc: 0.9918\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.3414 - accuracy: 0.9597 - binary_crossentropy: 0.3414 - precision: 0.9507 - recall: 0.9693 - auc: 0.9939\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.3170 - accuracy: 0.9701 - binary_crossentropy: 0.3170 - precision: 0.9706 - recall: 0.9693 - auc: 0.9967\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2943 - accuracy: 0.9757 - binary_crossentropy: 0.2943 - precision: 0.9684 - recall: 0.9832 - auc: 0.9980\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.2814 - accuracy: 0.9799 - binary_crossentropy: 0.2814 - precision: 0.9661 - recall: 0.9944 - auc: 0.9982\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.2730 - accuracy: 0.9757 - binary_crossentropy: 0.2730 - precision: 0.9697 - recall: 0.9818 - auc: 0.9976\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.2498 - accuracy: 0.9861 - binary_crossentropy: 0.2498 - precision: 0.9807 - recall: 0.9916 - auc: 0.9990\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.2339 - accuracy: 0.9868 - binary_crossentropy: 0.2339 - precision: 0.9767 - recall: 0.9972 - auc: 0.9991\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.2197 - accuracy: 0.9889 - binary_crossentropy: 0.2197 - precision: 0.9808 - recall: 0.9972 - auc: 0.9995\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.2106 - accuracy: 0.9868 - binary_crossentropy: 0.2106 - precision: 0.9794 - recall: 0.9944 - auc: 0.9991\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.2032 - accuracy: 0.9882 - binary_crossentropy: 0.2032 - precision: 0.9821 - recall: 0.9944 - auc: 0.9993\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.1947 - accuracy: 0.9868 - binary_crossentropy: 0.1947 - precision: 0.9807 - recall: 0.9930 - auc: 0.9997\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.1873 - accuracy: 0.9903 - binary_crossentropy: 0.1873 - precision: 0.9848 - recall: 0.9958 - auc: 0.9996\n",
      "Loss of Train ......................................\n",
      "[0.7403450012207031, 0.6404415369033813, 0.5689135789871216, 0.5127673149108887, 0.4654485881328583, 0.42345893383026123, 0.3917304277420044, 0.36415722966194153, 0.3413551449775696, 0.31701546907424927, 0.2942853569984436, 0.2813664674758911, 0.27295416593551636, 0.2497645914554596, 0.23391447961330414, 0.2197362333536148, 0.2106168270111084, 0.2031586915254593, 0.1947217583656311, 0.18727615475654602]\n",
      "Accuracy of Train ......................................\n",
      "[0.49513888359069824, 0.6326388716697693, 0.7437499761581421, 0.8263888955116272, 0.8736110925674438, 0.9152777791023254, 0.9361110925674438, 0.9548611044883728, 0.9597222208976746, 0.9701389074325562, 0.9756944179534912, 0.9798611402511597, 0.9756944179534912, 0.9861111044883728, 0.9868055582046509, 0.9888888597488403, 0.9868055582046509, 0.988194465637207, 0.9868055582046509, 0.9902777671813965]\n",
      "Precision of Train ......................................\n",
      "[0.48122867941856384, 0.709172248840332, 0.8070796728134155, 0.861801266670227, 0.8926470875740051, 0.9206798672676086, 0.9345403909683228, 0.9477304220199585, 0.9506849050521851, 0.9706293940544128, 0.9683631658554077, 0.9660786986351013, 0.9696551561355591, 0.980663001537323, 0.9767441749572754, 0.9807692170143127, 0.9793672561645508, 0.9820689558982849, 0.9806896448135376, 0.9848066568374634]\n",
      "Recall of Train ......................................\n",
      "[0.19692736864089966, 0.4427374303340912, 0.6368715167045593, 0.7751396894454956, 0.8477653861045837, 0.9078212380409241, 0.9371508359909058, 0.9622905254364014, 0.9692737460136414, 0.9692737460136414, 0.9832402467727661, 0.994413435459137, 0.9818435907363892, 0.9916201233863831, 0.9972066879272461, 0.9972066879272461, 0.994413435459137, 0.994413435459137, 0.99301677942276, 0.9958100318908691]\n",
      "AUC of Train ......................................\n",
      "[0.5130086541175842, 0.7059062719345093, 0.8330416679382324, 0.9136055707931519, 0.9531206488609314, 0.9773150682449341, 0.9858763217926025, 0.9918294548988342, 0.9939002394676208, 0.9966849088668823, 0.9979908466339111, 0.9982368350028992, 0.9975828528404236, 0.9990296959877014, 0.9991328120231628, 0.9994550347328186, 0.9990528225898743, 0.9992969036102295, 0.9996586441993713, 0.9995929598808289]\n",
      "Train of epochs .................................\n",
      " Accuracy:0.9076388835906982\n",
      " Loss:0.35567139759659766\n",
      " Precision:0.9122699931263923\n",
      " Recall:0.8784217968583107\n",
      " AUC:0.9426659107208252\n",
      "Score for fold 5: loss of 0.2308908849954605; accuracy of 0.9888888597488403%\n",
      "[[174   2]\n",
      " [  2 182]]\n",
      "------------------------------------------------------------------------\n",
      "Time: 2083.5199319000003 Second\n",
      "------------------------------------------------------------------------\n",
      " TN:174,FN:2,TP:182,FP:2\n",
      "Test of epochs .................................\n",
      " Accuracy:0.9888888888888889\n",
      " Loss:0.2308908849954605\n",
      " Precision:0.9891304347826086\n",
      " Recall:0.9891304347826086\n",
      " AUC:0.9888833992094861\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9208333283662796 - Loss: 0.32154927402734756\n",
      "> Fold 1 - Precision: 0.9609255373477936\n",
      "> Fold 1 - Recall: 0.8695172406733036\n",
      "> Fold 1 - AUC: 0.9631240427494049\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 1 - Accuracy: 0.9444444444444444 - Loss: 0.22951041162014008\n",
      "> Fold 1 - Precision: 0.8974358974358975\n",
      "> Fold 1 - Recall: 1.0\n",
      "> Fold 1 - AUC: 1.0\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 2 - Accuracy: 0.8995833352208138 - Loss: 0.35867229104042053\n",
      "> Fold 2 - Precision: 0.8996034815907479\n",
      "> Fold 2 - Recall: 0.8697222203016282\n",
      "> Fold 2 - AUC: 0.9373207986354828\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 2 - Accuracy: 0.9833333333333333 - Loss: 0.2085937112569809\n",
      "> Fold 2 - Precision: 0.9728260869565217\n",
      "> Fold 2 - Recall: 0.9944444444444445\n",
      "> Fold 2 - AUC: 0.9943813131313131\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9168402820825576 - Loss: 0.33824929818511007\n",
      "> Fold 3 - Precision: 0.9146513879299164\n",
      "> Fold 3 - Recall: 0.9056497186422348\n",
      "> Fold 3 - AUC: 0.9493716418743133\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 3 - Accuracy: 0.9833333333333333 - Loss: 0.2046387791633606\n",
      "> Fold 3 - Precision: 0.9696969696969697\n",
      "> Fold 3 - Recall: 1.0\n",
      "> Fold 3 - AUC: 1.0\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9131944388151169 - Loss: 0.33477781489491465\n",
      "> Fold 4 - Precision: 0.9119071185588836\n",
      "> Fold 4 - Recall: 0.9136114925146103\n",
      "> Fold 4 - AUC: 0.9540861636400223\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 4 - Accuracy: 0.9833333333333333 - Loss: 0.19378666579723358\n",
      "> Fold 4 - Precision: 0.9766081871345029\n",
      "> Fold 4 - Recall: 0.9881656804733728\n",
      "> Fold 4 - AUC: 0.9887918349456811\n",
      "----------------------------------Train--------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9076388835906982 - Loss: 0.35567139759659766\n",
      "> Fold 5 - Precision: 0.9122699931263923\n",
      "> Fold 5 - Recall: 0.8784217968583107\n",
      "> Fold 5 - AUC: 0.9426659107208252\n",
      "----------------------------------Test---------------------------------------\n",
      "> Fold 5 - Accuracy: 0.9888888888888889 - Loss: 0.2308908849954605\n",
      "> Fold 5 - Precision: 0.9891304347826086\n",
      "> Fold 5 - Recall: 0.9891304347826086\n",
      "> Fold 5 - AUC: 0.9888833992094861\n",
      "----------------------------------Train--------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9116180536150933 (+- 0.007420865045501828)\n",
      "> Loss: 0.34178401514887813 (+- 0.013777511154820588)\n",
      "> Precision: 0.9198715037107468 (+- 0.02118815896346393)\n",
      "> Recall: 0.8873844937980175 (+- 0.018617188165815243)\n",
      "> AUC: 0.9493137115240098 (+- 0.008961340510781414)\n",
      "----------------------------------Test---------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9766666666666666 (+- 0.01625415426480866)\n",
      "> Loss: 0.21348409056663514 (+- 0.014491261815016858)\n",
      "> Precision: 0.9611395152013001 (+- 0.032529150906902754)\n",
      "> Recall: 0.9943481119400852 (+- 0.005086129589290052)\n",
      "> AUC: 0.994411309457296 (+- 0.004992075905639292)\n",
      "----------------------------------Combined Confusion Matrices--------------------------------------\n",
      "> TN SUM: 863 FN SUM: 5 TP SUM: 895 FP SUM: 37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "import seaborn as sns\n",
    "from time import perf_counter, sleep\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet152V2, MobileNetV2, DenseNet201\n",
    "from builtins import range, input\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_classes = 2\n",
    "no_epochs = 20\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "NEG = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - NEG' + '/*.*')\n",
    "POS = glob.glob('C:/Users/Wael Alhazmi/Desktop/Dataset/CT COLONOGRAPHY/Filters - POS' + '/*.*')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in NEG:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in POS:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, target_train, target_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Define Train_per-fold score containers\n",
    "Train_acc_per_fold = []\n",
    "Train_pre_per_fold = []\n",
    "Train_rec_per_fold = []\n",
    "Train_AUC_per_fold = []\n",
    "Train_Loss_per_fold = []\n",
    "\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "ACC_per_fold = []\n",
    "loss_per_fold = []\n",
    "Precision_per_fold = []\n",
    "Recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "TN = []\n",
    "FN = []\n",
    "TP = []\n",
    "FP = []\n",
    "TN_SUM = 0\n",
    "FN_SUM = 0\n",
    "TP_SUM = 0\n",
    "FP_SUM = 0\n",
    "\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "  # Define the model architecture\n",
    "\n",
    "\n",
    "  def create_model():\n",
    "      model = models.Sequential()\n",
    "      model.add(DenseNet201(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))\n",
    "      model.add(layers.GlobalAveragePooling2D())\n",
    "      model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "      return model\n",
    "\n",
    "\n",
    "  model_2 = create_model()\n",
    "  model_2.summary()\n",
    "    \n",
    " \n",
    "  # Compile the model\n",
    "  model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','binary_crossentropy',tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')])\n",
    "  \n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model_2.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity)\n",
    "\n",
    "  print(f'Loss of Train ......................................')\n",
    "  print(history.history['binary_crossentropy'])\n",
    "\n",
    "  print(f'Accuracy of Train ......................................')\n",
    "  print(history.history['accuracy'])\n",
    "\n",
    "  print(f'Precision of Train ......................................')\n",
    "  print(history.history['precision'])\n",
    "\n",
    "  print(f'Recall of Train ......................................')\n",
    "  print(history.history['recall'])\n",
    "\n",
    "  print(f'AUC of Train ......................................')\n",
    "  print(history.history['auc'])\n",
    "\n",
    "  print(f'Train of epochs .................................')\n",
    "    \n",
    "  ACC_Train = (np.sum(history.history['accuracy'])/20)\n",
    "  PRE_Train = (np.sum(history.history['precision'])/20)\n",
    "  REC_Train = (np.sum(history.history['recall'])/20)\n",
    "  AUC_Train = (np.sum(history.history['auc'])/20)\n",
    "  Loss_Train = (np.sum(history.history['binary_crossentropy'])/20)\n",
    "    \n",
    "  print(f' Accuracy:{ACC_Train}')\n",
    "  print(f' Loss:{Loss_Train}')\n",
    "  print(f' Precision:{PRE_Train}')\n",
    "  print(f' Recall:{REC_Train}')\n",
    "  print(f' AUC:{AUC_Train}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model_2.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  print(f'Score for fold {fold_no}: {model_2.metrics_names[0]} of {scores[0]}; {model_2.metrics_names[1]} of {scores[1]}%')\n",
    "  acc_per_fold.append(scores[1])\n",
    "  \n",
    "  loss_per_fold.append(scores[0])\n",
    "  \n",
    "  \n",
    "  import seaborn as sns\n",
    "  y_pred = model_2.predict(inputs[test])\n",
    "  y_pred = (y_pred > 0.5)\n",
    "\n",
    "  #y_pred = model_2.predict(inputs[test])\n",
    "  cm=confusion_matrix(targets[test],y_pred)\n",
    "  print(cm)\n",
    "    \n",
    "  end = timer()\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Time: {end - start} Second') # Time in seconds, e.g. 5.38091952400282\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "  TN = cm[0][0]\n",
    "  FN = cm[1][0]\n",
    "  TP = cm[1][1]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(f' TN:{TN},FN:{FN},TP:{TP},FP:{FP}')\n",
    "  TN_SUM += TN\n",
    "  FN_SUM += FN\n",
    "  TP_SUM += TP\n",
    "  FP_SUM += FP\n",
    "\n",
    "    \n",
    "  Accuracy = (TP + TN) /(TP + TN + FP + FN)\n",
    "  Precision = (TP) / (TP + FP)\n",
    "  Recall = (TP) / (TP + FN)\n",
    "  AUC = (0.5 * ( (TP / (TP + FN)) + (TN / (TN + FN)) ) )\n",
    "    \n",
    "    \n",
    "  print(f'Test of epochs .................................')\n",
    "  print(f' Accuracy:{Accuracy}')\n",
    "  print(f' Loss:{scores[0]}')\n",
    "  print(f' Precision:{Precision}')\n",
    "  print(f' Recall:{Recall}')  \n",
    "  print(f' AUC:{AUC}')\n",
    "\n",
    "\n",
    "  ACC_per_fold.append(Accuracy)\n",
    "  Precision_per_fold.append(Precision)\n",
    "  Recall_per_fold.append(Recall)\n",
    "  AUC_per_fold.append(AUC)\n",
    "    \n",
    "  Train_acc_per_fold.append(ACC_Train)\n",
    "  Train_pre_per_fold.append(PRE_Train)\n",
    "  Train_rec_per_fold.append(REC_Train)\n",
    "  Train_AUC_per_fold.append(AUC_Train)\n",
    "  Train_Loss_per_fold.append(Loss_Train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    \n",
    "  print('----------------------------------Train--------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {Train_acc_per_fold[i]} - Loss: {Train_Loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Train_pre_per_fold[i]}')  \n",
    "  print(f'> Fold {i+1} - Recall: {Train_rec_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {Train_AUC_per_fold[i]}')\n",
    "  print('----------------------------------Test---------------------------------------')\n",
    "  print(f'> Fold {i+1} - Accuracy: {ACC_per_fold[i]} - Loss: {loss_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Precision: {Precision_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - Recall: {Recall_per_fold[i]}')\n",
    "  print(f'> Fold {i+1} - AUC: {AUC_per_fold[i]}')\n",
    "\n",
    "    \n",
    "\n",
    "print('----------------------------------Train--------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(Train_acc_per_fold)} (+- {np.std(Train_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(Train_Loss_per_fold)} (+- {np.std(Train_Loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Train_pre_per_fold)} (+- {np.std(Train_pre_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Train_rec_per_fold)} (+- {np.std(Train_rec_per_fold)})')\n",
    "print(f'> AUC: {np.mean(Train_AUC_per_fold)} (+- {np.std(Train_AUC_per_fold)})')\n",
    "print('----------------------------------Test---------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(ACC_per_fold)} (+- {np.std(ACC_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print(f'> Precision: {np.mean(Precision_per_fold)} (+- {np.std(Precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(Recall_per_fold)} (+- {np.std(Recall_per_fold)})')\n",
    "print(f'> AUC: {np.mean(AUC_per_fold)} (+- {np.std(AUC_per_fold)})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------Combined Confusion Matrices--------------------------------------')\n",
    "print(f'> TN SUM: {TN_SUM} FN SUM: {FN_SUM} TP SUM: {TP_SUM} FP SUM: {FP_SUM}')\n",
    "\n",
    "\n",
    "\n",
    "# Your Confusion Matrix\n",
    "cm2 = np.array([[TN_SUM, FP_SUM],\n",
    "               [FN_SUM, TP_SUM]])\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm2.flatten()/np.sum(cm2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm2, annot=labels, fmt='', cmap='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a7ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
